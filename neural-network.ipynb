{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Used Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported modules.\n"
     ]
    }
   ],
   "source": [
    "#@title Import relevant modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Imported modules.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_images_features.csv\")\n",
    "train_df = train_df.reindex(np.random.permutation(train_df.index)) # shuffle the examples\n",
    "test_df = pd.read_csv(\"test_images_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_path</th>\n",
       "      <th>avg_r</th>\n",
       "      <th>avg_g</th>\n",
       "      <th>avg_b</th>\n",
       "      <th>avg_s</th>\n",
       "      <th>contrast</th>\n",
       "      <th>ASM</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>type_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>133</td>\n",
       "      <td>./dataset/foggy/foggy16.jpg</td>\n",
       "      <td>133.542199</td>\n",
       "      <td>125.497312</td>\n",
       "      <td>119.510716</td>\n",
       "      <td>0.238261</td>\n",
       "      <td>439.425723</td>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.253507</td>\n",
       "      <td>foggy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>118</td>\n",
       "      <td>./dataset/cloudy/cloudy18.jpg</td>\n",
       "      <td>119.124494</td>\n",
       "      <td>125.100528</td>\n",
       "      <td>132.871432</td>\n",
       "      <td>0.142987</td>\n",
       "      <td>7.347887</td>\n",
       "      <td>0.001703</td>\n",
       "      <td>0.626224</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>14</td>\n",
       "      <td>./dataset/sunrise/sunrise265.jpg</td>\n",
       "      <td>103.592768</td>\n",
       "      <td>72.881578</td>\n",
       "      <td>26.887916</td>\n",
       "      <td>0.753982</td>\n",
       "      <td>11.851490</td>\n",
       "      <td>0.002306</td>\n",
       "      <td>0.563971</td>\n",
       "      <td>sunrise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>219</td>\n",
       "      <td>./dataset/rainy/rain67.jpg</td>\n",
       "      <td>49.299053</td>\n",
       "      <td>74.302596</td>\n",
       "      <td>84.152962</td>\n",
       "      <td>0.452036</td>\n",
       "      <td>38.546264</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.338270</td>\n",
       "      <td>rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>260</td>\n",
       "      <td>./dataset/cloudy/cloudy295.jpg</td>\n",
       "      <td>110.631169</td>\n",
       "      <td>117.937555</td>\n",
       "      <td>126.946619</td>\n",
       "      <td>0.178174</td>\n",
       "      <td>69.415296</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.352108</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                          img_path       avg_r       avg_g  \\\n",
       "433   133       ./dataset/foggy/foggy16.jpg  133.542199  125.497312   \n",
       "118   118     ./dataset/cloudy/cloudy18.jpg  119.124494  125.100528   \n",
       "1164   14  ./dataset/sunrise/sunrise265.jpg  103.592768   72.881578   \n",
       "819   219        ./dataset/rainy/rain67.jpg   49.299053   74.302596   \n",
       "260   260    ./dataset/cloudy/cloudy295.jpg  110.631169  117.937555   \n",
       "\n",
       "           avg_b     avg_s    contrast       ASM  homogeneity type_label  \n",
       "433   119.510716  0.238261  439.425723  0.000259     0.253507      foggy  \n",
       "118   132.871432  0.142987    7.347887  0.001703     0.626224     cloudy  \n",
       "1164   26.887916  0.753982   11.851490  0.002306     0.563971    sunrise  \n",
       "819    84.152962  0.452036   38.546264  0.000768     0.338270      rainy  \n",
       "260   126.946619  0.178174   69.415296  0.000690     0.352108     cloudy  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_path</th>\n",
       "      <th>avg_r</th>\n",
       "      <th>avg_g</th>\n",
       "      <th>avg_b</th>\n",
       "      <th>avg_s</th>\n",
       "      <th>contrast</th>\n",
       "      <th>ASM</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>type_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>./dataset/alien_test/rain_1.jpg</td>\n",
       "      <td>89.380456</td>\n",
       "      <td>108.331348</td>\n",
       "      <td>92.704043</td>\n",
       "      <td>0.340140</td>\n",
       "      <td>104.245269</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.284216</td>\n",
       "      <td>rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>./dataset/alien_test/shine_1.jpg</td>\n",
       "      <td>84.179988</td>\n",
       "      <td>145.610668</td>\n",
       "      <td>202.758774</td>\n",
       "      <td>0.650524</td>\n",
       "      <td>25.325296</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.637173</td>\n",
       "      <td>shine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>./dataset/alien_test/foggy_5.jpg</td>\n",
       "      <td>111.901819</td>\n",
       "      <td>122.010252</td>\n",
       "      <td>123.489308</td>\n",
       "      <td>0.122873</td>\n",
       "      <td>11.677350</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.705304</td>\n",
       "      <td>foggy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>./dataset/alien_test/Cloud_4.jpg</td>\n",
       "      <td>88.340293</td>\n",
       "      <td>151.776627</td>\n",
       "      <td>193.868678</td>\n",
       "      <td>0.557622</td>\n",
       "      <td>17.755358</td>\n",
       "      <td>0.002650</td>\n",
       "      <td>0.506353</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>./dataset/alien_test/foggy_7.jpg</td>\n",
       "      <td>122.728178</td>\n",
       "      <td>73.513052</td>\n",
       "      <td>36.486659</td>\n",
       "      <td>0.714519</td>\n",
       "      <td>8.337532</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>0.732819</td>\n",
       "      <td>foggy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                          img_path       avg_r       avg_g       avg_b  \\\n",
       "0   0   ./dataset/alien_test/rain_1.jpg   89.380456  108.331348   92.704043   \n",
       "1   1  ./dataset/alien_test/shine_1.jpg   84.179988  145.610668  202.758774   \n",
       "2   2  ./dataset/alien_test/foggy_5.jpg  111.901819  122.010252  123.489308   \n",
       "3   3  ./dataset/alien_test/Cloud_4.jpg   88.340293  151.776627  193.868678   \n",
       "4   4  ./dataset/alien_test/foggy_7.jpg  122.728178   73.513052   36.486659   \n",
       "\n",
       "      avg_s    contrast       ASM  homogeneity type_label  \n",
       "0  0.340140  104.245269  0.001284     0.284216      rainy  \n",
       "1  0.650524   25.325296  0.003029     0.637173      shine  \n",
       "2  0.122873   11.677350  0.002500     0.705304      foggy  \n",
       "3  0.557622   17.755358  0.002650     0.506353     cloudy  \n",
       "4  0.714519    8.337532  0.003289     0.732819      foggy  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_df.head())\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Numeric Values to Their Z-Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized the values.\n"
     ]
    }
   ],
   "source": [
    "#@title Convert raw values to their Z-scores \n",
    "\n",
    "numeric_columns = [\"avg_r\", \"avg_g\", \"avg_b\", \"contrast\", \"ASM\", \"homogeneity\"]\n",
    "\n",
    "for col in numeric_columns:\n",
    "    # Calculate the Z-scores of each column in the training set:\n",
    "    train_df_mean = train_df[col].mean()\n",
    "    train_df_std = train_df[col].std()\n",
    "    train_df[col] = (train_df[col] - train_df_mean)/train_df_std\n",
    "\n",
    "    # Calculate the Z-scores of each column in the test set.\n",
    "    test_df[col] = (test_df[col] - train_df_mean)/train_df_std\n",
    "\n",
    "print(\"Normalized the values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_path</th>\n",
       "      <th>avg_r</th>\n",
       "      <th>avg_g</th>\n",
       "      <th>avg_b</th>\n",
       "      <th>avg_s</th>\n",
       "      <th>contrast</th>\n",
       "      <th>ASM</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>type_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>133</td>\n",
       "      <td>./dataset/foggy/foggy16.jpg</td>\n",
       "      <td>0.424440</td>\n",
       "      <td>0.205914</td>\n",
       "      <td>0.075944</td>\n",
       "      <td>0.238261</td>\n",
       "      <td>1.654876</td>\n",
       "      <td>-0.264480</td>\n",
       "      <td>-1.110720</td>\n",
       "      <td>foggy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>118</td>\n",
       "      <td>./dataset/cloudy/cloudy18.jpg</td>\n",
       "      <td>0.009686</td>\n",
       "      <td>0.195453</td>\n",
       "      <td>0.332458</td>\n",
       "      <td>0.142987</td>\n",
       "      <td>-0.551254</td>\n",
       "      <td>-0.180706</td>\n",
       "      <td>0.845894</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>14</td>\n",
       "      <td>./dataset/sunrise/sunrise265.jpg</td>\n",
       "      <td>-0.437116</td>\n",
       "      <td>-1.181374</td>\n",
       "      <td>-1.702330</td>\n",
       "      <td>0.753982</td>\n",
       "      <td>-0.528259</td>\n",
       "      <td>-0.145739</td>\n",
       "      <td>0.519089</td>\n",
       "      <td>sunrise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>219</td>\n",
       "      <td>./dataset/rainy/rain67.jpg</td>\n",
       "      <td>-1.998985</td>\n",
       "      <td>-1.143907</td>\n",
       "      <td>-0.602893</td>\n",
       "      <td>0.452036</td>\n",
       "      <td>-0.391959</td>\n",
       "      <td>-0.234940</td>\n",
       "      <td>-0.665750</td>\n",
       "      <td>rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>260</td>\n",
       "      <td>./dataset/cloudy/cloudy295.jpg</td>\n",
       "      <td>-0.234642</td>\n",
       "      <td>0.006591</td>\n",
       "      <td>0.218707</td>\n",
       "      <td>0.178174</td>\n",
       "      <td>-0.234346</td>\n",
       "      <td>-0.239484</td>\n",
       "      <td>-0.593105</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                          img_path     avg_r     avg_g     avg_b  \\\n",
       "433   133       ./dataset/foggy/foggy16.jpg  0.424440  0.205914  0.075944   \n",
       "118   118     ./dataset/cloudy/cloudy18.jpg  0.009686  0.195453  0.332458   \n",
       "1164   14  ./dataset/sunrise/sunrise265.jpg -0.437116 -1.181374 -1.702330   \n",
       "819   219        ./dataset/rainy/rain67.jpg -1.998985 -1.143907 -0.602893   \n",
       "260   260    ./dataset/cloudy/cloudy295.jpg -0.234642  0.006591  0.218707   \n",
       "\n",
       "         avg_s  contrast       ASM  homogeneity type_label  \n",
       "433   0.238261  1.654876 -0.264480    -1.110720      foggy  \n",
       "118   0.142987 -0.551254 -0.180706     0.845894     cloudy  \n",
       "1164  0.753982 -0.528259 -0.145739     0.519089    sunrise  \n",
       "819   0.452036 -0.391959 -0.234940    -0.665750      rainy  \n",
       "260   0.178174 -0.234346 -0.239484    -0.593105     cloudy  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_path</th>\n",
       "      <th>avg_r</th>\n",
       "      <th>avg_g</th>\n",
       "      <th>avg_b</th>\n",
       "      <th>avg_s</th>\n",
       "      <th>contrast</th>\n",
       "      <th>ASM</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>type_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>./dataset/alien_test/rain_1.jpg</td>\n",
       "      <td>-0.845962</td>\n",
       "      <td>-0.246691</td>\n",
       "      <td>-0.438720</td>\n",
       "      <td>0.340140</td>\n",
       "      <td>-0.056509</td>\n",
       "      <td>-0.205015</td>\n",
       "      <td>-0.949509</td>\n",
       "      <td>rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>./dataset/alien_test/shine_1.jpg</td>\n",
       "      <td>-0.995564</td>\n",
       "      <td>0.736231</td>\n",
       "      <td>1.674231</td>\n",
       "      <td>0.650524</td>\n",
       "      <td>-0.459464</td>\n",
       "      <td>-0.103800</td>\n",
       "      <td>0.903370</td>\n",
       "      <td>shine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>./dataset/alien_test/foggy_5.jpg</td>\n",
       "      <td>-0.198089</td>\n",
       "      <td>0.113973</td>\n",
       "      <td>0.152329</td>\n",
       "      <td>0.122873</td>\n",
       "      <td>-0.529148</td>\n",
       "      <td>-0.134466</td>\n",
       "      <td>1.261028</td>\n",
       "      <td>foggy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>./dataset/alien_test/Cloud_4.jpg</td>\n",
       "      <td>-0.875884</td>\n",
       "      <td>0.898806</td>\n",
       "      <td>1.503549</td>\n",
       "      <td>0.557622</td>\n",
       "      <td>-0.498115</td>\n",
       "      <td>-0.125769</td>\n",
       "      <td>0.216616</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>./dataset/alien_test/foggy_7.jpg</td>\n",
       "      <td>0.113353</td>\n",
       "      <td>-1.164724</td>\n",
       "      <td>-1.518043</td>\n",
       "      <td>0.714519</td>\n",
       "      <td>-0.546201</td>\n",
       "      <td>-0.088691</td>\n",
       "      <td>1.405474</td>\n",
       "      <td>foggy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                          img_path     avg_r     avg_g     avg_b  \\\n",
       "0   0   ./dataset/alien_test/rain_1.jpg -0.845962 -0.246691 -0.438720   \n",
       "1   1  ./dataset/alien_test/shine_1.jpg -0.995564  0.736231  1.674231   \n",
       "2   2  ./dataset/alien_test/foggy_5.jpg -0.198089  0.113973  0.152329   \n",
       "3   3  ./dataset/alien_test/Cloud_4.jpg -0.875884  0.898806  1.503549   \n",
       "4   4  ./dataset/alien_test/foggy_7.jpg  0.113353 -1.164724 -1.518043   \n",
       "\n",
       "      avg_s  contrast       ASM  homogeneity type_label  \n",
       "0  0.340140 -0.056509 -0.205015    -0.949509      rainy  \n",
       "1  0.650524 -0.459464 -0.103800     0.903370      shine  \n",
       "2  0.122873 -0.529148 -0.134466     1.261028      foggy  \n",
       "3  0.557622 -0.498115 -0.125769     0.216616     cloudy  \n",
       "4  0.714519 -0.546201 -0.088691     1.405474      foggy  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_df.head())\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Attribute Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>avg_r</th>\n",
       "      <th>avg_g</th>\n",
       "      <th>avg_b</th>\n",
       "      <th>avg_s</th>\n",
       "      <th>contrast</th>\n",
       "      <th>ASM</th>\n",
       "      <th>homogeneity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.010898</td>\n",
       "      <td>-0.114900</td>\n",
       "      <td>-0.137644</td>\n",
       "      <td>0.063076</td>\n",
       "      <td>-0.022180</td>\n",
       "      <td>0.025727</td>\n",
       "      <td>0.029405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_r</th>\n",
       "      <td>-0.010898</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.635598</td>\n",
       "      <td>0.270568</td>\n",
       "      <td>-0.050624</td>\n",
       "      <td>-0.049262</td>\n",
       "      <td>-0.069407</td>\n",
       "      <td>0.062067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_g</th>\n",
       "      <td>-0.114900</td>\n",
       "      <td>0.635598</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.874212</td>\n",
       "      <td>-0.324659</td>\n",
       "      <td>0.023166</td>\n",
       "      <td>-0.114200</td>\n",
       "      <td>-0.092685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_b</th>\n",
       "      <td>-0.137644</td>\n",
       "      <td>0.270568</td>\n",
       "      <td>0.874212</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.406487</td>\n",
       "      <td>0.024810</td>\n",
       "      <td>-0.099306</td>\n",
       "      <td>-0.097692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_s</th>\n",
       "      <td>0.063076</td>\n",
       "      <td>-0.050624</td>\n",
       "      <td>-0.324659</td>\n",
       "      <td>-0.406487</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.094517</td>\n",
       "      <td>-0.027932</td>\n",
       "      <td>0.148109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contrast</th>\n",
       "      <td>-0.022180</td>\n",
       "      <td>-0.049262</td>\n",
       "      <td>0.023166</td>\n",
       "      <td>0.024810</td>\n",
       "      <td>-0.094517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.095333</td>\n",
       "      <td>-0.578588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASM</th>\n",
       "      <td>0.025727</td>\n",
       "      <td>-0.069407</td>\n",
       "      <td>-0.114200</td>\n",
       "      <td>-0.099306</td>\n",
       "      <td>-0.027932</td>\n",
       "      <td>-0.095333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.305109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>homogeneity</th>\n",
       "      <td>0.029405</td>\n",
       "      <td>0.062067</td>\n",
       "      <td>-0.092685</td>\n",
       "      <td>-0.097692</td>\n",
       "      <td>0.148109</td>\n",
       "      <td>-0.578588</td>\n",
       "      <td>0.305109</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id     avg_r     avg_g     avg_b     avg_s  contrast  \\\n",
       "id           1.000000 -0.010898 -0.114900 -0.137644  0.063076 -0.022180   \n",
       "avg_r       -0.010898  1.000000  0.635598  0.270568 -0.050624 -0.049262   \n",
       "avg_g       -0.114900  0.635598  1.000000  0.874212 -0.324659  0.023166   \n",
       "avg_b       -0.137644  0.270568  0.874212  1.000000 -0.406487  0.024810   \n",
       "avg_s        0.063076 -0.050624 -0.324659 -0.406487  1.000000 -0.094517   \n",
       "contrast    -0.022180 -0.049262  0.023166  0.024810 -0.094517  1.000000   \n",
       "ASM          0.025727 -0.069407 -0.114200 -0.099306 -0.027932 -0.095333   \n",
       "homogeneity  0.029405  0.062067 -0.092685 -0.097692  0.148109 -0.578588   \n",
       "\n",
       "                  ASM  homogeneity  \n",
       "id           0.025727     0.029405  \n",
       "avg_r       -0.069407     0.062067  \n",
       "avg_g       -0.114200    -0.092685  \n",
       "avg_b       -0.099306    -0.097692  \n",
       "avg_s       -0.027932     0.148109  \n",
       "contrast    -0.095333    -0.578588  \n",
       "ASM          1.000000     0.305109  \n",
       "homogeneity  0.305109     1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Feature Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = [\"avg_r\", \"avg_g\", \"avg_b\", \"avg_s\", \"contrast\", \"ASM\", \"homogeneity\"]\n",
    "\n",
    "feature_columns = []\n",
    "for col in input_columns:\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.numeric_column(col)\n",
    "    )\n",
    "    \n",
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Function to Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined the plot_the_loss_curve function.\n"
     ]
    }
   ],
   "source": [
    "#@title Define the plotting function.\n",
    "\n",
    "def plot_the_scc_curve(epochs, scc, acc, val_acc):\n",
    "    \"\"\"Plot a curve of SCC vs. epoch.\"\"\"\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Sparse Categorical Crossentropy\")\n",
    "\n",
    "    plt.plot(epochs, scc, label=\"loss\")\n",
    "    plt.legend()\n",
    "    plt.ylim([scc.min()*0.95, scc.max() * 1.03])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "\n",
    "    plt.plot(epochs, acc, label=\"acc\")\n",
    "    plt.plot(epochs, val_acc, label=\"val acc\")\n",
    "    plt.legend()\n",
    "    plt.ylim([0, 1])\n",
    "    plt.show()  \n",
    "\n",
    "print(\"Defined the plot_the_loss_curve function.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Function to Create, Train, and Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined the create_model and train_model functions.\n"
     ]
    }
   ],
   "source": [
    "#@title Define functions to create and train a linear regression model\n",
    "def create_model(my_learning_rate, feature_layer):\n",
    "    \"\"\"Create and compile a multiclass classification neural network.\"\"\"\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Add the layer containing the feature columns to the model.\n",
    "    model.add(feature_layer)\n",
    "    \n",
    "    # Add hidden layer 1\n",
    "    model.add(tf.keras.layers.Dense(units=7, activation='relu'))\n",
    "    \n",
    "    # Add hidden layer 2\n",
    "    model.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "\n",
    "    # Classification layer\n",
    "    model.add(tf.keras.layers.Dense(units=5, activation='softmax'))\n",
    "\n",
    "    # Construct the layers into a model that TensorFlow can execute.\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\n",
    "                loss=\"sparse_categorical_crossentropy\",\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model           \n",
    "\n",
    "\n",
    "def train_model(model, x_train, y_train, x_val, y_val, epochs,\n",
    "                batch_size=None):\n",
    "    \"\"\"Train the model by feeding it data.\"\"\"\n",
    "\n",
    "    x_train = {name:np.array(value) for name, value in x_train.items()}\n",
    "    y_train = y_train.values\n",
    "    \n",
    "    x_val = {name:np.array(value) for name, value in x_val.items()}\n",
    "    y_val = y_val.values\n",
    "    \n",
    "    history = model.fit(x=x_train, y=y_train, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=True,\n",
    "                       validation_data=(x_val, y_val))\n",
    "\n",
    "    # To track the progression of training, gather a snapshot\n",
    "    # of the model's metrics at each epoch. \n",
    "    epochs = history.epoch\n",
    "    hist = pd.DataFrame(history.history)\n",
    "\n",
    "    return epochs, hist\n",
    "\n",
    "def predict(model, x_test):\n",
    "    x_test = {name:np.array(value) for name, value in x_test.items()}\n",
    "    \n",
    "    return model.predict(x_test)\n",
    "\n",
    "print(\"Defined the create_model and train_model functions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Label to Numeric Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create label encoder for \"type_label\"\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "enc.fit(train_df[\"type_label\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_path</th>\n",
       "      <th>avg_r</th>\n",
       "      <th>avg_g</th>\n",
       "      <th>avg_b</th>\n",
       "      <th>avg_s</th>\n",
       "      <th>contrast</th>\n",
       "      <th>ASM</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>type_label</th>\n",
       "      <th>type_label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>133</td>\n",
       "      <td>./dataset/foggy/foggy16.jpg</td>\n",
       "      <td>0.424440</td>\n",
       "      <td>0.205914</td>\n",
       "      <td>0.075944</td>\n",
       "      <td>0.238261</td>\n",
       "      <td>1.654876</td>\n",
       "      <td>-0.264480</td>\n",
       "      <td>-1.110720</td>\n",
       "      <td>foggy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>118</td>\n",
       "      <td>./dataset/cloudy/cloudy18.jpg</td>\n",
       "      <td>0.009686</td>\n",
       "      <td>0.195453</td>\n",
       "      <td>0.332458</td>\n",
       "      <td>0.142987</td>\n",
       "      <td>-0.551254</td>\n",
       "      <td>-0.180706</td>\n",
       "      <td>0.845894</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>14</td>\n",
       "      <td>./dataset/sunrise/sunrise265.jpg</td>\n",
       "      <td>-0.437116</td>\n",
       "      <td>-1.181374</td>\n",
       "      <td>-1.702330</td>\n",
       "      <td>0.753982</td>\n",
       "      <td>-0.528259</td>\n",
       "      <td>-0.145739</td>\n",
       "      <td>0.519089</td>\n",
       "      <td>sunrise</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>219</td>\n",
       "      <td>./dataset/rainy/rain67.jpg</td>\n",
       "      <td>-1.998985</td>\n",
       "      <td>-1.143907</td>\n",
       "      <td>-0.602893</td>\n",
       "      <td>0.452036</td>\n",
       "      <td>-0.391959</td>\n",
       "      <td>-0.234940</td>\n",
       "      <td>-0.665750</td>\n",
       "      <td>rainy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>260</td>\n",
       "      <td>./dataset/cloudy/cloudy295.jpg</td>\n",
       "      <td>-0.234642</td>\n",
       "      <td>0.006591</td>\n",
       "      <td>0.218707</td>\n",
       "      <td>0.178174</td>\n",
       "      <td>-0.234346</td>\n",
       "      <td>-0.239484</td>\n",
       "      <td>-0.593105</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                          img_path     avg_r     avg_g     avg_b  \\\n",
       "433   133       ./dataset/foggy/foggy16.jpg  0.424440  0.205914  0.075944   \n",
       "118   118     ./dataset/cloudy/cloudy18.jpg  0.009686  0.195453  0.332458   \n",
       "1164   14  ./dataset/sunrise/sunrise265.jpg -0.437116 -1.181374 -1.702330   \n",
       "819   219        ./dataset/rainy/rain67.jpg -1.998985 -1.143907 -0.602893   \n",
       "260   260    ./dataset/cloudy/cloudy295.jpg -0.234642  0.006591  0.218707   \n",
       "\n",
       "         avg_s  contrast       ASM  homogeneity type_label  type_label_encoded  \n",
       "433   0.238261  1.654876 -0.264480    -1.110720      foggy                   1  \n",
       "118   0.142987 -0.551254 -0.180706     0.845894     cloudy                   0  \n",
       "1164  0.753982 -0.528259 -0.145739     0.519089    sunrise                   4  \n",
       "819   0.452036 -0.391959 -0.234940    -0.665750      rainy                   2  \n",
       "260   0.178174 -0.234346 -0.239484    -0.593105     cloudy                   0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df[\"type_label_encoded\"] = enc.transform(train_df[\"type_label\"].values)\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train : validation = 0.7 : 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_path</th>\n",
       "      <th>avg_r</th>\n",
       "      <th>avg_g</th>\n",
       "      <th>avg_b</th>\n",
       "      <th>avg_s</th>\n",
       "      <th>contrast</th>\n",
       "      <th>ASM</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>type_label</th>\n",
       "      <th>type_label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>18</td>\n",
       "      <td>./dataset/foggy/foggy203.jpeg</td>\n",
       "      <td>0.885142</td>\n",
       "      <td>-0.180857</td>\n",
       "      <td>-1.402637</td>\n",
       "      <td>0.777857</td>\n",
       "      <td>-0.574699</td>\n",
       "      <td>-0.086508</td>\n",
       "      <td>2.059582</td>\n",
       "      <td>foggy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>22</td>\n",
       "      <td>./dataset/shine/shine123.jpg</td>\n",
       "      <td>-0.014989</td>\n",
       "      <td>0.725702</td>\n",
       "      <td>1.300468</td>\n",
       "      <td>0.384111</td>\n",
       "      <td>-0.421093</td>\n",
       "      <td>-0.180811</td>\n",
       "      <td>0.309604</td>\n",
       "      <td>shine</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>102</td>\n",
       "      <td>./dataset/foggy/foggy296.jpg</td>\n",
       "      <td>1.118350</td>\n",
       "      <td>1.003293</td>\n",
       "      <td>0.643415</td>\n",
       "      <td>0.065062</td>\n",
       "      <td>0.199370</td>\n",
       "      <td>0.707301</td>\n",
       "      <td>-0.241864</td>\n",
       "      <td>foggy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>50</td>\n",
       "      <td>./dataset/cloudy/cloudy124.jpg</td>\n",
       "      <td>-0.892185</td>\n",
       "      <td>0.216132</td>\n",
       "      <td>0.950410</td>\n",
       "      <td>0.472230</td>\n",
       "      <td>-0.497410</td>\n",
       "      <td>-0.200720</td>\n",
       "      <td>-0.306301</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>190</td>\n",
       "      <td>./dataset/foggy/foggy290.jpg</td>\n",
       "      <td>0.122061</td>\n",
       "      <td>0.160873</td>\n",
       "      <td>0.209122</td>\n",
       "      <td>0.058669</td>\n",
       "      <td>-0.534326</td>\n",
       "      <td>-0.133793</td>\n",
       "      <td>0.626999</td>\n",
       "      <td>foggy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                        img_path     avg_r     avg_g     avg_b  \\\n",
       "318   18   ./dataset/foggy/foggy203.jpeg  0.885142 -0.180857 -1.402637   \n",
       "922   22    ./dataset/shine/shine123.jpg -0.014989  0.725702  1.300468   \n",
       "402  102    ./dataset/foggy/foggy296.jpg  1.118350  1.003293  0.643415   \n",
       "50    50  ./dataset/cloudy/cloudy124.jpg -0.892185  0.216132  0.950410   \n",
       "490  190    ./dataset/foggy/foggy290.jpg  0.122061  0.160873  0.209122   \n",
       "\n",
       "        avg_s  contrast       ASM  homogeneity type_label  type_label_encoded  \n",
       "318  0.777857 -0.574699 -0.086508     2.059582      foggy                   1  \n",
       "922  0.384111 -0.421093 -0.180811     0.309604      shine                   3  \n",
       "402  0.065062  0.199370  0.707301    -0.241864      foggy                   1  \n",
       "50   0.472230 -0.497410 -0.200720    -0.306301     cloudy                   0  \n",
       "490  0.058669 -0.534326 -0.133793     0.626999      foggy                   1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_path</th>\n",
       "      <th>avg_r</th>\n",
       "      <th>avg_g</th>\n",
       "      <th>avg_b</th>\n",
       "      <th>avg_s</th>\n",
       "      <th>contrast</th>\n",
       "      <th>ASM</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>type_label</th>\n",
       "      <th>type_label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>118</td>\n",
       "      <td>./dataset/cloudy/cloudy18.jpg</td>\n",
       "      <td>0.009686</td>\n",
       "      <td>0.195453</td>\n",
       "      <td>0.332458</td>\n",
       "      <td>0.142987</td>\n",
       "      <td>-0.551254</td>\n",
       "      <td>-0.180706</td>\n",
       "      <td>0.845894</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>219</td>\n",
       "      <td>./dataset/rainy/rain67.jpg</td>\n",
       "      <td>-1.998985</td>\n",
       "      <td>-1.143907</td>\n",
       "      <td>-0.602893</td>\n",
       "      <td>0.452036</td>\n",
       "      <td>-0.391959</td>\n",
       "      <td>-0.234940</td>\n",
       "      <td>-0.665750</td>\n",
       "      <td>rainy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>./dataset/cloudy/cloudy67.jpg</td>\n",
       "      <td>-1.432441</td>\n",
       "      <td>-1.283895</td>\n",
       "      <td>-0.893946</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.536464</td>\n",
       "      <td>-0.100732</td>\n",
       "      <td>0.763811</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1323</th>\n",
       "      <td>173</td>\n",
       "      <td>./dataset/sunrise/sunrise104.jpg</td>\n",
       "      <td>-0.084941</td>\n",
       "      <td>-1.186933</td>\n",
       "      <td>-0.419711</td>\n",
       "      <td>0.324487</td>\n",
       "      <td>-0.561352</td>\n",
       "      <td>0.563687</td>\n",
       "      <td>1.429406</td>\n",
       "      <td>sunrise</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1147</th>\n",
       "      <td>247</td>\n",
       "      <td>./dataset/shine/shine30.jpg</td>\n",
       "      <td>0.079416</td>\n",
       "      <td>0.930357</td>\n",
       "      <td>1.635818</td>\n",
       "      <td>0.411460</td>\n",
       "      <td>-0.561104</td>\n",
       "      <td>-0.133272</td>\n",
       "      <td>1.030981</td>\n",
       "      <td>shine</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                          img_path     avg_r     avg_g     avg_b  \\\n",
       "118   118     ./dataset/cloudy/cloudy18.jpg  0.009686  0.195453  0.332458   \n",
       "819   219        ./dataset/rainy/rain67.jpg -1.998985 -1.143907 -0.602893   \n",
       "22     22     ./dataset/cloudy/cloudy67.jpg -1.432441 -1.283895 -0.893946   \n",
       "1323  173  ./dataset/sunrise/sunrise104.jpg -0.084941 -1.186933 -0.419711   \n",
       "1147  247       ./dataset/shine/shine30.jpg  0.079416  0.930357  1.635818   \n",
       "\n",
       "         avg_s  contrast       ASM  homogeneity type_label  type_label_encoded  \n",
       "118   0.142987 -0.551254 -0.180706     0.845894     cloudy                   0  \n",
       "819   0.452036 -0.391959 -0.234940    -0.665750      rainy                   2  \n",
       "22    0.000000 -0.536464 -0.100732     0.763811     cloudy                   0  \n",
       "1323  0.324487 -0.561352  0.563687     1.429406    sunrise                   4  \n",
       "1147  0.411460 -0.561104 -0.133272     1.030981      shine                   3  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split train dataset into train and validation\n",
    "train_set = train_df.sample(frac=0.7)\n",
    "val_set = train_df.drop(train_set.index)\n",
    "\n",
    "display(train_set.head())\n",
    "display(val_set.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1050 samples, validate on 450 samples\n",
      "Epoch 1/600\n",
      "1050/1050 [==============================] - 1s 686us/sample - loss: 1.6595 - accuracy: 0.2800 - val_loss: 1.6179 - val_accuracy: 0.3111\n",
      "Epoch 2/600\n",
      "1050/1050 [==============================] - 0s 146us/sample - loss: 1.5741 - accuracy: 0.3438 - val_loss: 1.5525 - val_accuracy: 0.3622\n",
      "Epoch 3/600\n",
      "1050/1050 [==============================] - 0s 110us/sample - loss: 1.5177 - accuracy: 0.4076 - val_loss: 1.5012 - val_accuracy: 0.4156\n",
      "Epoch 4/600\n",
      "1050/1050 [==============================] - 0s 113us/sample - loss: 1.4596 - accuracy: 0.4581 - val_loss: 1.4449 - val_accuracy: 0.4378\n",
      "Epoch 5/600\n",
      "1050/1050 [==============================] - 0s 120us/sample - loss: 1.3865 - accuracy: 0.4962 - val_loss: 1.3618 - val_accuracy: 0.4911\n",
      "Epoch 6/600\n",
      "1050/1050 [==============================] - 0s 131us/sample - loss: 1.2910 - accuracy: 0.5733 - val_loss: 1.2496 - val_accuracy: 0.5644\n",
      "Epoch 7/600\n",
      "1050/1050 [==============================] - 0s 155us/sample - loss: 1.1818 - accuracy: 0.6057 - val_loss: 1.1544 - val_accuracy: 0.5689\n",
      "Epoch 8/600\n",
      "1050/1050 [==============================] - 0s 132us/sample - loss: 1.0956 - accuracy: 0.6190 - val_loss: 1.0772 - val_accuracy: 0.6000\n",
      "Epoch 9/600\n",
      "1050/1050 [==============================] - 0s 122us/sample - loss: 1.0237 - accuracy: 0.6438 - val_loss: 1.0190 - val_accuracy: 0.6311\n",
      "Epoch 10/600\n",
      "1050/1050 [==============================] - 0s 112us/sample - loss: 0.9618 - accuracy: 0.6838 - val_loss: 0.9658 - val_accuracy: 0.6600\n",
      "Epoch 11/600\n",
      "1050/1050 [==============================] - 0s 132us/sample - loss: 0.9077 - accuracy: 0.6981 - val_loss: 0.9187 - val_accuracy: 0.6556\n",
      "Epoch 12/600\n",
      "1050/1050 [==============================] - 0s 118us/sample - loss: 0.8655 - accuracy: 0.7048 - val_loss: 0.8838 - val_accuracy: 0.6733\n",
      "Epoch 13/600\n",
      "1050/1050 [==============================] - 0s 131us/sample - loss: 0.8295 - accuracy: 0.7219 - val_loss: 0.8544 - val_accuracy: 0.6889\n",
      "Epoch 14/600\n",
      "1050/1050 [==============================] - 0s 143us/sample - loss: 0.8025 - accuracy: 0.7257 - val_loss: 0.8342 - val_accuracy: 0.6911\n",
      "Epoch 15/600\n",
      "1050/1050 [==============================] - 0s 129us/sample - loss: 0.7814 - accuracy: 0.7314 - val_loss: 0.8204 - val_accuracy: 0.6911\n",
      "Epoch 16/600\n",
      "1050/1050 [==============================] - 0s 226us/sample - loss: 0.7654 - accuracy: 0.7371 - val_loss: 0.8071 - val_accuracy: 0.6956\n",
      "Epoch 17/600\n",
      "1050/1050 [==============================] - 0s 202us/sample - loss: 0.7532 - accuracy: 0.7419 - val_loss: 0.7985 - val_accuracy: 0.7000\n",
      "Epoch 18/600\n",
      "1050/1050 [==============================] - 0s 284us/sample - loss: 0.7423 - accuracy: 0.7410 - val_loss: 0.7894 - val_accuracy: 0.7000\n",
      "Epoch 19/600\n",
      "1050/1050 [==============================] - 0s 285us/sample - loss: 0.7327 - accuracy: 0.7410 - val_loss: 0.7819 - val_accuracy: 0.6889\n",
      "Epoch 20/600\n",
      "1050/1050 [==============================] - 0s 239us/sample - loss: 0.7270 - accuracy: 0.7371 - val_loss: 0.7754 - val_accuracy: 0.6978\n",
      "Epoch 21/600\n",
      "1050/1050 [==============================] - 0s 274us/sample - loss: 0.7156 - accuracy: 0.7514 - val_loss: 0.7705 - val_accuracy: 0.7044\n",
      "Epoch 22/600\n",
      "1050/1050 [==============================] - 0s 320us/sample - loss: 0.7094 - accuracy: 0.7495 - val_loss: 0.7687 - val_accuracy: 0.7089\n",
      "Epoch 23/600\n",
      "1050/1050 [==============================] - 0s 379us/sample - loss: 0.7022 - accuracy: 0.7524 - val_loss: 0.7620 - val_accuracy: 0.7111\n",
      "Epoch 24/600\n",
      "1050/1050 [==============================] - 0s 265us/sample - loss: 0.6969 - accuracy: 0.7552 - val_loss: 0.7567 - val_accuracy: 0.7133\n",
      "Epoch 25/600\n",
      "1050/1050 [==============================] - 0s 311us/sample - loss: 0.6919 - accuracy: 0.7524 - val_loss: 0.7563 - val_accuracy: 0.7111\n",
      "Epoch 26/600\n",
      "1050/1050 [==============================] - 0s 227us/sample - loss: 0.6870 - accuracy: 0.7571 - val_loss: 0.7523 - val_accuracy: 0.7178\n",
      "Epoch 27/600\n",
      "1050/1050 [==============================] - 0s 291us/sample - loss: 0.6808 - accuracy: 0.7552 - val_loss: 0.7489 - val_accuracy: 0.7156\n",
      "Epoch 28/600\n",
      "1050/1050 [==============================] - 0s 229us/sample - loss: 0.6775 - accuracy: 0.7552 - val_loss: 0.7449 - val_accuracy: 0.7289\n",
      "Epoch 29/600\n",
      "1050/1050 [==============================] - 0s 255us/sample - loss: 0.6739 - accuracy: 0.7600 - val_loss: 0.7457 - val_accuracy: 0.7178\n",
      "Epoch 30/600\n",
      "1050/1050 [==============================] - 0s 280us/sample - loss: 0.6678 - accuracy: 0.7610 - val_loss: 0.7421 - val_accuracy: 0.7244\n",
      "Epoch 31/600\n",
      "1050/1050 [==============================] - 0s 342us/sample - loss: 0.6670 - accuracy: 0.7552 - val_loss: 0.7430 - val_accuracy: 0.7267\n",
      "Epoch 32/600\n",
      "1050/1050 [==============================] - 0s 254us/sample - loss: 0.6617 - accuracy: 0.7629 - val_loss: 0.7380 - val_accuracy: 0.7222\n",
      "Epoch 33/600\n",
      "1050/1050 [==============================] - 0s 298us/sample - loss: 0.6577 - accuracy: 0.7629 - val_loss: 0.7365 - val_accuracy: 0.7267\n",
      "Epoch 34/600\n",
      "1050/1050 [==============================] - 0s 303us/sample - loss: 0.6523 - accuracy: 0.7667 - val_loss: 0.7334 - val_accuracy: 0.7289\n",
      "Epoch 35/600\n",
      "1050/1050 [==============================] - 0s 335us/sample - loss: 0.6508 - accuracy: 0.7619 - val_loss: 0.7345 - val_accuracy: 0.7178\n",
      "Epoch 36/600\n",
      "1050/1050 [==============================] - 0s 234us/sample - loss: 0.6489 - accuracy: 0.7648 - val_loss: 0.7297 - val_accuracy: 0.7311\n",
      "Epoch 37/600\n",
      "1050/1050 [==============================] - 0s 266us/sample - loss: 0.6458 - accuracy: 0.7638 - val_loss: 0.7316 - val_accuracy: 0.7222\n",
      "Epoch 38/600\n",
      "1050/1050 [==============================] - 0s 342us/sample - loss: 0.6417 - accuracy: 0.7676 - val_loss: 0.7309 - val_accuracy: 0.7244\n",
      "Epoch 39/600\n",
      "1050/1050 [==============================] - 0s 277us/sample - loss: 0.6393 - accuracy: 0.7638 - val_loss: 0.7284 - val_accuracy: 0.7267\n",
      "Epoch 40/600\n",
      "1050/1050 [==============================] - 0s 252us/sample - loss: 0.6371 - accuracy: 0.7695 - val_loss: 0.7259 - val_accuracy: 0.7311\n",
      "Epoch 41/600\n",
      "1050/1050 [==============================] - 0s 309us/sample - loss: 0.6351 - accuracy: 0.7676 - val_loss: 0.7278 - val_accuracy: 0.7267\n",
      "Epoch 42/600\n",
      "1050/1050 [==============================] - 0s 249us/sample - loss: 0.6330 - accuracy: 0.7676 - val_loss: 0.7273 - val_accuracy: 0.7244\n",
      "Epoch 43/600\n",
      "1050/1050 [==============================] - 0s 260us/sample - loss: 0.6301 - accuracy: 0.7667 - val_loss: 0.7244 - val_accuracy: 0.7356\n",
      "Epoch 44/600\n",
      "1050/1050 [==============================] - 0s 239us/sample - loss: 0.6274 - accuracy: 0.7695 - val_loss: 0.7244 - val_accuracy: 0.7356\n",
      "Epoch 45/600\n",
      "1050/1050 [==============================] - 0s 274us/sample - loss: 0.6253 - accuracy: 0.7676 - val_loss: 0.7241 - val_accuracy: 0.7222\n",
      "Epoch 46/600\n",
      "1050/1050 [==============================] - 0s 213us/sample - loss: 0.6240 - accuracy: 0.7686 - val_loss: 0.7216 - val_accuracy: 0.7333\n",
      "Epoch 47/600\n",
      "1050/1050 [==============================] - 0s 195us/sample - loss: 0.6244 - accuracy: 0.7667 - val_loss: 0.7233 - val_accuracy: 0.7378\n",
      "Epoch 48/600\n",
      "1050/1050 [==============================] - 0s 244us/sample - loss: 0.6215 - accuracy: 0.7714 - val_loss: 0.7204 - val_accuracy: 0.7356\n",
      "Epoch 49/600\n",
      "1050/1050 [==============================] - 0s 236us/sample - loss: 0.6186 - accuracy: 0.7714 - val_loss: 0.7219 - val_accuracy: 0.7356\n",
      "Epoch 50/600\n",
      "1050/1050 [==============================] - 0s 254us/sample - loss: 0.6170 - accuracy: 0.7714 - val_loss: 0.7185 - val_accuracy: 0.7311\n",
      "Epoch 51/600\n",
      "1050/1050 [==============================] - 0s 253us/sample - loss: 0.6151 - accuracy: 0.7733 - val_loss: 0.7181 - val_accuracy: 0.7356\n",
      "Epoch 52/600\n",
      "1050/1050 [==============================] - 0s 290us/sample - loss: 0.6143 - accuracy: 0.7714 - val_loss: 0.7184 - val_accuracy: 0.7289\n",
      "Epoch 53/600\n",
      "1050/1050 [==============================] - 0s 229us/sample - loss: 0.6127 - accuracy: 0.7667 - val_loss: 0.7141 - val_accuracy: 0.7356\n",
      "Epoch 54/600\n",
      "1050/1050 [==============================] - 0s 228us/sample - loss: 0.6099 - accuracy: 0.7695 - val_loss: 0.7170 - val_accuracy: 0.7356\n",
      "Epoch 55/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 0s 206us/sample - loss: 0.6099 - accuracy: 0.7676 - val_loss: 0.7163 - val_accuracy: 0.7356\n",
      "Epoch 56/600\n",
      "1050/1050 [==============================] - 0s 252us/sample - loss: 0.6072 - accuracy: 0.7724 - val_loss: 0.7123 - val_accuracy: 0.7333\n",
      "Epoch 57/600\n",
      "1050/1050 [==============================] - 0s 253us/sample - loss: 0.6067 - accuracy: 0.7695 - val_loss: 0.7130 - val_accuracy: 0.7378\n",
      "Epoch 58/600\n",
      "1050/1050 [==============================] - 0s 213us/sample - loss: 0.6041 - accuracy: 0.7695 - val_loss: 0.7131 - val_accuracy: 0.7333\n",
      "Epoch 59/600\n",
      "1050/1050 [==============================] - 0s 209us/sample - loss: 0.6044 - accuracy: 0.7705 - val_loss: 0.7139 - val_accuracy: 0.7356\n",
      "Epoch 60/600\n",
      "1050/1050 [==============================] - 0s 343us/sample - loss: 0.6025 - accuracy: 0.7752 - val_loss: 0.7098 - val_accuracy: 0.7378\n",
      "Epoch 61/600\n",
      "1050/1050 [==============================] - 0s 253us/sample - loss: 0.6016 - accuracy: 0.7733 - val_loss: 0.7077 - val_accuracy: 0.7400\n",
      "Epoch 62/600\n",
      "1050/1050 [==============================] - 0s 308us/sample - loss: 0.5987 - accuracy: 0.7705 - val_loss: 0.7093 - val_accuracy: 0.7333\n",
      "Epoch 63/600\n",
      "1050/1050 [==============================] - 0s 261us/sample - loss: 0.5974 - accuracy: 0.7714 - val_loss: 0.7056 - val_accuracy: 0.7400\n",
      "Epoch 64/600\n",
      "1050/1050 [==============================] - 0s 279us/sample - loss: 0.5960 - accuracy: 0.7781 - val_loss: 0.7095 - val_accuracy: 0.7378\n",
      "Epoch 65/600\n",
      "1050/1050 [==============================] - 0s 356us/sample - loss: 0.5974 - accuracy: 0.7762 - val_loss: 0.7111 - val_accuracy: 0.7422\n",
      "Epoch 66/600\n",
      "1050/1050 [==============================] - 0s 268us/sample - loss: 0.5958 - accuracy: 0.7733 - val_loss: 0.7039 - val_accuracy: 0.7333\n",
      "Epoch 67/600\n",
      "1050/1050 [==============================] - 0s 318us/sample - loss: 0.5956 - accuracy: 0.7790 - val_loss: 0.7069 - val_accuracy: 0.7444\n",
      "Epoch 68/600\n",
      "1050/1050 [==============================] - 0s 284us/sample - loss: 0.5914 - accuracy: 0.7781 - val_loss: 0.7062 - val_accuracy: 0.7378\n",
      "Epoch 69/600\n",
      "1050/1050 [==============================] - 0s 289us/sample - loss: 0.5912 - accuracy: 0.7762 - val_loss: 0.7041 - val_accuracy: 0.7422\n",
      "Epoch 70/600\n",
      "1050/1050 [==============================] - 0s 333us/sample - loss: 0.5903 - accuracy: 0.7790 - val_loss: 0.7086 - val_accuracy: 0.7422\n",
      "Epoch 71/600\n",
      "1050/1050 [==============================] - 0s 289us/sample - loss: 0.5918 - accuracy: 0.7781 - val_loss: 0.7019 - val_accuracy: 0.7378\n",
      "Epoch 72/600\n",
      "1050/1050 [==============================] - 0s 324us/sample - loss: 0.5907 - accuracy: 0.7819 - val_loss: 0.7068 - val_accuracy: 0.7400\n",
      "Epoch 73/600\n",
      "1050/1050 [==============================] - 0s 331us/sample - loss: 0.5894 - accuracy: 0.7790 - val_loss: 0.7018 - val_accuracy: 0.7378\n",
      "Epoch 74/600\n",
      "1050/1050 [==============================] - 0s 223us/sample - loss: 0.5873 - accuracy: 0.7838 - val_loss: 0.7022 - val_accuracy: 0.7422\n",
      "Epoch 75/600\n",
      "1050/1050 [==============================] - 0s 241us/sample - loss: 0.5887 - accuracy: 0.7800 - val_loss: 0.7040 - val_accuracy: 0.7400\n",
      "Epoch 76/600\n",
      "1050/1050 [==============================] - 0s 309us/sample - loss: 0.5841 - accuracy: 0.7848 - val_loss: 0.6993 - val_accuracy: 0.7378\n",
      "Epoch 77/600\n",
      "1050/1050 [==============================] - 0s 341us/sample - loss: 0.5878 - accuracy: 0.7819 - val_loss: 0.7008 - val_accuracy: 0.7467\n",
      "Epoch 78/600\n",
      "1050/1050 [==============================] - 0s 342us/sample - loss: 0.5847 - accuracy: 0.7857 - val_loss: 0.7011 - val_accuracy: 0.7400\n",
      "Epoch 79/600\n",
      "1050/1050 [==============================] - 0s 262us/sample - loss: 0.5860 - accuracy: 0.7838 - val_loss: 0.7008 - val_accuracy: 0.7444\n",
      "Epoch 80/600\n",
      "1050/1050 [==============================] - 0s 281us/sample - loss: 0.5862 - accuracy: 0.7829 - val_loss: 0.6955 - val_accuracy: 0.7444\n",
      "Epoch 81/600\n",
      "1050/1050 [==============================] - 0s 230us/sample - loss: 0.5798 - accuracy: 0.7829 - val_loss: 0.7051 - val_accuracy: 0.7333\n",
      "Epoch 82/600\n",
      "1050/1050 [==============================] - 0s 267us/sample - loss: 0.5798 - accuracy: 0.7790 - val_loss: 0.6951 - val_accuracy: 0.7422\n",
      "Epoch 83/600\n",
      "1050/1050 [==============================] - 0s 267us/sample - loss: 0.5801 - accuracy: 0.7838 - val_loss: 0.6978 - val_accuracy: 0.7400\n",
      "Epoch 84/600\n",
      "1050/1050 [==============================] - 0s 309us/sample - loss: 0.5818 - accuracy: 0.7867 - val_loss: 0.6982 - val_accuracy: 0.7467\n",
      "Epoch 85/600\n",
      "1050/1050 [==============================] - 0s 290us/sample - loss: 0.5791 - accuracy: 0.7848 - val_loss: 0.6964 - val_accuracy: 0.7422\n",
      "Epoch 86/600\n",
      "1050/1050 [==============================] - 0s 310us/sample - loss: 0.5778 - accuracy: 0.7810 - val_loss: 0.6939 - val_accuracy: 0.7422\n",
      "Epoch 87/600\n",
      "1050/1050 [==============================] - 0s 341us/sample - loss: 0.5782 - accuracy: 0.7810 - val_loss: 0.6949 - val_accuracy: 0.7422\n",
      "Epoch 88/600\n",
      "1050/1050 [==============================] - 0s 316us/sample - loss: 0.5773 - accuracy: 0.7886 - val_loss: 0.6927 - val_accuracy: 0.7467\n",
      "Epoch 89/600\n",
      "1050/1050 [==============================] - 0s 314us/sample - loss: 0.5762 - accuracy: 0.7838 - val_loss: 0.6962 - val_accuracy: 0.7467\n",
      "Epoch 90/600\n",
      "1050/1050 [==============================] - 0s 331us/sample - loss: 0.5750 - accuracy: 0.7810 - val_loss: 0.6928 - val_accuracy: 0.7444\n",
      "Epoch 91/600\n",
      "1050/1050 [==============================] - 0s 346us/sample - loss: 0.5749 - accuracy: 0.7895 - val_loss: 0.6919 - val_accuracy: 0.7533\n",
      "Epoch 92/600\n",
      "1050/1050 [==============================] - 0s 327us/sample - loss: 0.5760 - accuracy: 0.7895 - val_loss: 0.6924 - val_accuracy: 0.7378\n",
      "Epoch 93/600\n",
      "1050/1050 [==============================] - 0s 349us/sample - loss: 0.5746 - accuracy: 0.7848 - val_loss: 0.6938 - val_accuracy: 0.7467\n",
      "Epoch 94/600\n",
      "1050/1050 [==============================] - 0s 313us/sample - loss: 0.5718 - accuracy: 0.7867 - val_loss: 0.6866 - val_accuracy: 0.7467\n",
      "Epoch 95/600\n",
      "1050/1050 [==============================] - 0s 298us/sample - loss: 0.5715 - accuracy: 0.7867 - val_loss: 0.6925 - val_accuracy: 0.7467\n",
      "Epoch 96/600\n",
      "1050/1050 [==============================] - 0s 330us/sample - loss: 0.5710 - accuracy: 0.7895 - val_loss: 0.6888 - val_accuracy: 0.7400\n",
      "Epoch 97/600\n",
      "1050/1050 [==============================] - 0s 245us/sample - loss: 0.5710 - accuracy: 0.7895 - val_loss: 0.6880 - val_accuracy: 0.7533\n",
      "Epoch 98/600\n",
      "1050/1050 [==============================] - 0s 279us/sample - loss: 0.5695 - accuracy: 0.7895 - val_loss: 0.6887 - val_accuracy: 0.7422\n",
      "Epoch 99/600\n",
      "1050/1050 [==============================] - 0s 279us/sample - loss: 0.5702 - accuracy: 0.7933 - val_loss: 0.6854 - val_accuracy: 0.7556\n",
      "Epoch 100/600\n",
      "1050/1050 [==============================] - 0s 370us/sample - loss: 0.5681 - accuracy: 0.7914 - val_loss: 0.6881 - val_accuracy: 0.7489\n",
      "Epoch 101/600\n",
      "1050/1050 [==============================] - 0s 343us/sample - loss: 0.5671 - accuracy: 0.7914 - val_loss: 0.6868 - val_accuracy: 0.7422\n",
      "Epoch 102/600\n",
      "1050/1050 [==============================] - 0s 259us/sample - loss: 0.5705 - accuracy: 0.7886 - val_loss: 0.6879 - val_accuracy: 0.7378\n",
      "Epoch 103/600\n",
      "1050/1050 [==============================] - 0s 294us/sample - loss: 0.5658 - accuracy: 0.7924 - val_loss: 0.6838 - val_accuracy: 0.7489\n",
      "Epoch 104/600\n",
      "1050/1050 [==============================] - 0s 324us/sample - loss: 0.5665 - accuracy: 0.7933 - val_loss: 0.6840 - val_accuracy: 0.7467\n",
      "Epoch 105/600\n",
      "1050/1050 [==============================] - 0s 234us/sample - loss: 0.5656 - accuracy: 0.7886 - val_loss: 0.6826 - val_accuracy: 0.7467\n",
      "Epoch 106/600\n",
      "1050/1050 [==============================] - 0s 308us/sample - loss: 0.5637 - accuracy: 0.7943 - val_loss: 0.6829 - val_accuracy: 0.7444\n",
      "Epoch 107/600\n",
      "1050/1050 [==============================] - 0s 292us/sample - loss: 0.5643 - accuracy: 0.7924 - val_loss: 0.6835 - val_accuracy: 0.7533\n",
      "Epoch 108/600\n",
      "1050/1050 [==============================] - 0s 394us/sample - loss: 0.5641 - accuracy: 0.7867 - val_loss: 0.6870 - val_accuracy: 0.7467\n",
      "Epoch 109/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 0s 314us/sample - loss: 0.5634 - accuracy: 0.7876 - val_loss: 0.6794 - val_accuracy: 0.7533\n",
      "Epoch 110/600\n",
      "1050/1050 [==============================] - 0s 310us/sample - loss: 0.5644 - accuracy: 0.7895 - val_loss: 0.6848 - val_accuracy: 0.7444\n",
      "Epoch 111/600\n",
      "1050/1050 [==============================] - 0s 318us/sample - loss: 0.5623 - accuracy: 0.7924 - val_loss: 0.6800 - val_accuracy: 0.7444\n",
      "Epoch 112/600\n",
      "1050/1050 [==============================] - 0s 369us/sample - loss: 0.5623 - accuracy: 0.7876 - val_loss: 0.6824 - val_accuracy: 0.7422\n",
      "Epoch 113/600\n",
      "1050/1050 [==============================] - 0s 344us/sample - loss: 0.5636 - accuracy: 0.7857 - val_loss: 0.6794 - val_accuracy: 0.7467\n",
      "Epoch 114/600\n",
      "1050/1050 [==============================] - 0s 317us/sample - loss: 0.5610 - accuracy: 0.7924 - val_loss: 0.6764 - val_accuracy: 0.7511\n",
      "Epoch 115/600\n",
      "1050/1050 [==============================] - 0s 334us/sample - loss: 0.5625 - accuracy: 0.7857 - val_loss: 0.6822 - val_accuracy: 0.7378\n",
      "Epoch 116/600\n",
      "1050/1050 [==============================] - 0s 208us/sample - loss: 0.5583 - accuracy: 0.7933 - val_loss: 0.6766 - val_accuracy: 0.7511\n",
      "Epoch 117/600\n",
      "1050/1050 [==============================] - 0s 326us/sample - loss: 0.5601 - accuracy: 0.7933 - val_loss: 0.6811 - val_accuracy: 0.7467\n",
      "Epoch 118/600\n",
      "1050/1050 [==============================] - 0s 316us/sample - loss: 0.5604 - accuracy: 0.7914 - val_loss: 0.6775 - val_accuracy: 0.7400\n",
      "Epoch 119/600\n",
      "1050/1050 [==============================] - 0s 266us/sample - loss: 0.5618 - accuracy: 0.7886 - val_loss: 0.6788 - val_accuracy: 0.7444\n",
      "Epoch 120/600\n",
      "1050/1050 [==============================] - 0s 257us/sample - loss: 0.5580 - accuracy: 0.7905 - val_loss: 0.6782 - val_accuracy: 0.7444\n",
      "Epoch 121/600\n",
      "1050/1050 [==============================] - 0s 412us/sample - loss: 0.5601 - accuracy: 0.7867 - val_loss: 0.6763 - val_accuracy: 0.7444\n",
      "Epoch 122/600\n",
      "1050/1050 [==============================] - 0s 406us/sample - loss: 0.5575 - accuracy: 0.7905 - val_loss: 0.6812 - val_accuracy: 0.7400\n",
      "Epoch 123/600\n",
      "1050/1050 [==============================] - 0s 266us/sample - loss: 0.5552 - accuracy: 0.7933 - val_loss: 0.6786 - val_accuracy: 0.7467\n",
      "Epoch 124/600\n",
      "1050/1050 [==============================] - 0s 228us/sample - loss: 0.5556 - accuracy: 0.7905 - val_loss: 0.6802 - val_accuracy: 0.7444\n",
      "Epoch 125/600\n",
      "1050/1050 [==============================] - 0s 301us/sample - loss: 0.5574 - accuracy: 0.7867 - val_loss: 0.6823 - val_accuracy: 0.7467\n",
      "Epoch 126/600\n",
      "1050/1050 [==============================] - 0s 363us/sample - loss: 0.5558 - accuracy: 0.7895 - val_loss: 0.6853 - val_accuracy: 0.7378\n",
      "Epoch 127/600\n",
      "1050/1050 [==============================] - 0s 329us/sample - loss: 0.5564 - accuracy: 0.7924 - val_loss: 0.6815 - val_accuracy: 0.7467\n",
      "Epoch 128/600\n",
      "1050/1050 [==============================] - 0s 371us/sample - loss: 0.5550 - accuracy: 0.7914 - val_loss: 0.6830 - val_accuracy: 0.7444\n",
      "Epoch 129/600\n",
      "1050/1050 [==============================] - 0s 433us/sample - loss: 0.5536 - accuracy: 0.7924 - val_loss: 0.6845 - val_accuracy: 0.7356\n",
      "Epoch 130/600\n",
      "1050/1050 [==============================] - 0s 363us/sample - loss: 0.5532 - accuracy: 0.7962 - val_loss: 0.6830 - val_accuracy: 0.7444\n",
      "Epoch 131/600\n",
      "1050/1050 [==============================] - 0s 276us/sample - loss: 0.5526 - accuracy: 0.7914 - val_loss: 0.6853 - val_accuracy: 0.7378\n",
      "Epoch 132/600\n",
      "1050/1050 [==============================] - 0s 365us/sample - loss: 0.5528 - accuracy: 0.7905 - val_loss: 0.6839 - val_accuracy: 0.7467\n",
      "Epoch 133/600\n",
      "1050/1050 [==============================] - 0s 216us/sample - loss: 0.5522 - accuracy: 0.7971 - val_loss: 0.6827 - val_accuracy: 0.7489\n",
      "Epoch 134/600\n",
      "1050/1050 [==============================] - 0s 323us/sample - loss: 0.5515 - accuracy: 0.7924 - val_loss: 0.6823 - val_accuracy: 0.7444\n",
      "Epoch 135/600\n",
      "1050/1050 [==============================] - 1s 529us/sample - loss: 0.5510 - accuracy: 0.7914 - val_loss: 0.6798 - val_accuracy: 0.7511\n",
      "Epoch 136/600\n",
      "1050/1050 [==============================] - 0s 372us/sample - loss: 0.5510 - accuracy: 0.7933 - val_loss: 0.6863 - val_accuracy: 0.7422\n",
      "Epoch 137/600\n",
      "1050/1050 [==============================] - 0s 369us/sample - loss: 0.5508 - accuracy: 0.7876 - val_loss: 0.6816 - val_accuracy: 0.7489\n",
      "Epoch 138/600\n",
      "1050/1050 [==============================] - 0s 365us/sample - loss: 0.5494 - accuracy: 0.7933 - val_loss: 0.6832 - val_accuracy: 0.7444\n",
      "Epoch 139/600\n",
      "1050/1050 [==============================] - 0s 257us/sample - loss: 0.5499 - accuracy: 0.7990 - val_loss: 0.6804 - val_accuracy: 0.7422\n",
      "Epoch 140/600\n",
      "1050/1050 [==============================] - 0s 299us/sample - loss: 0.5497 - accuracy: 0.7905 - val_loss: 0.6830 - val_accuracy: 0.7467\n",
      "Epoch 141/600\n",
      "1050/1050 [==============================] - 0s 378us/sample - loss: 0.5500 - accuracy: 0.7933 - val_loss: 0.6807 - val_accuracy: 0.7444\n",
      "Epoch 142/600\n",
      "1050/1050 [==============================] - 0s 448us/sample - loss: 0.5510 - accuracy: 0.7895 - val_loss: 0.6820 - val_accuracy: 0.7378\n",
      "Epoch 143/600\n",
      "1050/1050 [==============================] - 0s 269us/sample - loss: 0.5483 - accuracy: 0.7905 - val_loss: 0.6827 - val_accuracy: 0.7422\n",
      "Epoch 144/600\n",
      "1050/1050 [==============================] - 0s 224us/sample - loss: 0.5493 - accuracy: 0.7905 - val_loss: 0.6772 - val_accuracy: 0.7489\n",
      "Epoch 145/600\n",
      "1050/1050 [==============================] - 1s 523us/sample - loss: 0.5481 - accuracy: 0.7943 - val_loss: 0.6843 - val_accuracy: 0.7467\n",
      "Epoch 146/600\n",
      "1050/1050 [==============================] - 0s 330us/sample - loss: 0.5504 - accuracy: 0.7924 - val_loss: 0.6769 - val_accuracy: 0.7444\n",
      "Epoch 147/600\n",
      "1050/1050 [==============================] - 0s 304us/sample - loss: 0.5463 - accuracy: 0.7895 - val_loss: 0.6828 - val_accuracy: 0.7467\n",
      "Epoch 148/600\n",
      "1050/1050 [==============================] - 0s 290us/sample - loss: 0.5471 - accuracy: 0.7933 - val_loss: 0.6783 - val_accuracy: 0.7467\n",
      "Epoch 149/600\n",
      "1050/1050 [==============================] - 0s 351us/sample - loss: 0.5484 - accuracy: 0.7895 - val_loss: 0.6796 - val_accuracy: 0.7511\n",
      "Epoch 150/600\n",
      "1050/1050 [==============================] - 0s 367us/sample - loss: 0.5451 - accuracy: 0.7952 - val_loss: 0.6752 - val_accuracy: 0.7489\n",
      "Epoch 151/600\n",
      "1050/1050 [==============================] - 0s 338us/sample - loss: 0.5450 - accuracy: 0.7905 - val_loss: 0.6796 - val_accuracy: 0.7444\n",
      "Epoch 152/600\n",
      "1050/1050 [==============================] - 0s 328us/sample - loss: 0.5469 - accuracy: 0.7905 - val_loss: 0.6806 - val_accuracy: 0.7511\n",
      "Epoch 153/600\n",
      "1050/1050 [==============================] - 0s 337us/sample - loss: 0.5459 - accuracy: 0.7895 - val_loss: 0.6752 - val_accuracy: 0.7511\n",
      "Epoch 154/600\n",
      "1050/1050 [==============================] - 0s 290us/sample - loss: 0.5450 - accuracy: 0.7905 - val_loss: 0.6780 - val_accuracy: 0.7444\n",
      "Epoch 155/600\n",
      "1050/1050 [==============================] - 0s 296us/sample - loss: 0.5447 - accuracy: 0.7971 - val_loss: 0.6810 - val_accuracy: 0.7467\n",
      "Epoch 156/600\n",
      "1050/1050 [==============================] - 0s 373us/sample - loss: 0.5441 - accuracy: 0.7933 - val_loss: 0.6755 - val_accuracy: 0.7511\n",
      "Epoch 157/600\n",
      "1050/1050 [==============================] - 0s 354us/sample - loss: 0.5429 - accuracy: 0.7962 - val_loss: 0.6778 - val_accuracy: 0.7467\n",
      "Epoch 158/600\n",
      "1050/1050 [==============================] - 0s 376us/sample - loss: 0.5443 - accuracy: 0.7943 - val_loss: 0.6786 - val_accuracy: 0.7467\n",
      "Epoch 159/600\n",
      "1050/1050 [==============================] - 0s 461us/sample - loss: 0.5420 - accuracy: 0.7962 - val_loss: 0.6753 - val_accuracy: 0.7467\n",
      "Epoch 160/600\n",
      "1050/1050 [==============================] - 0s 398us/sample - loss: 0.5446 - accuracy: 0.7952 - val_loss: 0.6782 - val_accuracy: 0.7444\n",
      "Epoch 161/600\n",
      "1050/1050 [==============================] - 0s 386us/sample - loss: 0.5411 - accuracy: 0.7924 - val_loss: 0.6756 - val_accuracy: 0.7489\n",
      "Epoch 162/600\n",
      "1050/1050 [==============================] - 0s 441us/sample - loss: 0.5436 - accuracy: 0.7962 - val_loss: 0.6750 - val_accuracy: 0.7511\n",
      "Epoch 163/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 0s 449us/sample - loss: 0.5422 - accuracy: 0.7933 - val_loss: 0.6768 - val_accuracy: 0.7511\n",
      "Epoch 164/600\n",
      "1050/1050 [==============================] - 0s 340us/sample - loss: 0.5422 - accuracy: 0.7962 - val_loss: 0.6758 - val_accuracy: 0.7511\n",
      "Epoch 165/600\n",
      "1050/1050 [==============================] - 0s 309us/sample - loss: 0.5422 - accuracy: 0.7952 - val_loss: 0.6762 - val_accuracy: 0.7511\n",
      "Epoch 166/600\n",
      "1050/1050 [==============================] - 0s 247us/sample - loss: 0.5391 - accuracy: 0.7971 - val_loss: 0.6747 - val_accuracy: 0.7444\n",
      "Epoch 167/600\n",
      "1050/1050 [==============================] - 0s 419us/sample - loss: 0.5407 - accuracy: 0.7981 - val_loss: 0.6722 - val_accuracy: 0.7533\n",
      "Epoch 168/600\n",
      "1050/1050 [==============================] - 0s 309us/sample - loss: 0.5394 - accuracy: 0.7943 - val_loss: 0.6710 - val_accuracy: 0.7533\n",
      "Epoch 169/600\n",
      "1050/1050 [==============================] - 0s 407us/sample - loss: 0.5402 - accuracy: 0.7933 - val_loss: 0.6731 - val_accuracy: 0.7489\n",
      "Epoch 170/600\n",
      "1050/1050 [==============================] - 0s 230us/sample - loss: 0.5420 - accuracy: 0.8000 - val_loss: 0.6740 - val_accuracy: 0.7467\n",
      "Epoch 171/600\n",
      "1050/1050 [==============================] - 0s 315us/sample - loss: 0.5388 - accuracy: 0.7962 - val_loss: 0.6729 - val_accuracy: 0.7511\n",
      "Epoch 172/600\n",
      "1050/1050 [==============================] - 0s 363us/sample - loss: 0.5412 - accuracy: 0.7971 - val_loss: 0.6696 - val_accuracy: 0.7578\n",
      "Epoch 173/600\n",
      "1050/1050 [==============================] - 0s 423us/sample - loss: 0.5416 - accuracy: 0.7952 - val_loss: 0.6754 - val_accuracy: 0.7489\n",
      "Epoch 174/600\n",
      "1050/1050 [==============================] - 0s 412us/sample - loss: 0.5379 - accuracy: 0.7971 - val_loss: 0.6720 - val_accuracy: 0.7444\n",
      "Epoch 175/600\n",
      "1050/1050 [==============================] - 0s 432us/sample - loss: 0.5379 - accuracy: 0.8010 - val_loss: 0.6746 - val_accuracy: 0.7444\n",
      "Epoch 176/600\n",
      "1050/1050 [==============================] - 0s 468us/sample - loss: 0.5436 - accuracy: 0.7914 - val_loss: 0.6716 - val_accuracy: 0.7467\n",
      "Epoch 177/600\n",
      "1050/1050 [==============================] - 1s 487us/sample - loss: 0.5408 - accuracy: 0.8000 - val_loss: 0.6718 - val_accuracy: 0.7444\n",
      "Epoch 178/600\n",
      "1050/1050 [==============================] - 1s 537us/sample - loss: 0.5371 - accuracy: 0.7990 - val_loss: 0.6734 - val_accuracy: 0.7511\n",
      "Epoch 179/600\n",
      "1050/1050 [==============================] - 0s 333us/sample - loss: 0.5375 - accuracy: 0.7914 - val_loss: 0.6716 - val_accuracy: 0.7511\n",
      "Epoch 180/600\n",
      "1050/1050 [==============================] - 0s 397us/sample - loss: 0.5385 - accuracy: 0.7981 - val_loss: 0.6693 - val_accuracy: 0.7533\n",
      "Epoch 181/600\n",
      "1050/1050 [==============================] - 0s 316us/sample - loss: 0.5384 - accuracy: 0.7933 - val_loss: 0.6719 - val_accuracy: 0.7511\n",
      "Epoch 182/600\n",
      "1050/1050 [==============================] - 0s 371us/sample - loss: 0.5380 - accuracy: 0.7962 - val_loss: 0.6721 - val_accuracy: 0.7511\n",
      "Epoch 183/600\n",
      "1050/1050 [==============================] - 0s 359us/sample - loss: 0.5390 - accuracy: 0.7962 - val_loss: 0.6709 - val_accuracy: 0.7511\n",
      "Epoch 184/600\n",
      "1050/1050 [==============================] - 0s 321us/sample - loss: 0.5387 - accuracy: 0.7924 - val_loss: 0.6694 - val_accuracy: 0.7489\n",
      "Epoch 185/600\n",
      "1050/1050 [==============================] - 0s 394us/sample - loss: 0.5388 - accuracy: 0.7962 - val_loss: 0.6686 - val_accuracy: 0.7533\n",
      "Epoch 186/600\n",
      "1050/1050 [==============================] - 1s 482us/sample - loss: 0.5366 - accuracy: 0.7962 - val_loss: 0.6718 - val_accuracy: 0.7489\n",
      "Epoch 187/600\n",
      "1050/1050 [==============================] - 0s 410us/sample - loss: 0.5369 - accuracy: 0.7990 - val_loss: 0.6687 - val_accuracy: 0.7489\n",
      "Epoch 188/600\n",
      "1050/1050 [==============================] - 0s 338us/sample - loss: 0.5363 - accuracy: 0.7962 - val_loss: 0.6719 - val_accuracy: 0.7467\n",
      "Epoch 189/600\n",
      "1050/1050 [==============================] - 0s 337us/sample - loss: 0.5371 - accuracy: 0.7981 - val_loss: 0.6693 - val_accuracy: 0.7467\n",
      "Epoch 190/600\n",
      "1050/1050 [==============================] - 0s 398us/sample - loss: 0.5374 - accuracy: 0.8010 - val_loss: 0.6682 - val_accuracy: 0.7578\n",
      "Epoch 191/600\n",
      "1050/1050 [==============================] - 0s 309us/sample - loss: 0.5352 - accuracy: 0.7990 - val_loss: 0.6702 - val_accuracy: 0.7511\n",
      "Epoch 192/600\n",
      "1050/1050 [==============================] - 0s 300us/sample - loss: 0.5359 - accuracy: 0.7990 - val_loss: 0.6692 - val_accuracy: 0.7467\n",
      "Epoch 193/600\n",
      "1050/1050 [==============================] - 0s 226us/sample - loss: 0.5367 - accuracy: 0.8000 - val_loss: 0.6666 - val_accuracy: 0.7489\n",
      "Epoch 194/600\n",
      "1050/1050 [==============================] - 0s 308us/sample - loss: 0.5345 - accuracy: 0.7971 - val_loss: 0.6700 - val_accuracy: 0.7489\n",
      "Epoch 195/600\n",
      "1050/1050 [==============================] - 0s 314us/sample - loss: 0.5344 - accuracy: 0.7952 - val_loss: 0.6664 - val_accuracy: 0.7556\n",
      "Epoch 196/600\n",
      "1050/1050 [==============================] - 0s 297us/sample - loss: 0.5345 - accuracy: 0.7952 - val_loss: 0.6709 - val_accuracy: 0.7422\n",
      "Epoch 197/600\n",
      "1050/1050 [==============================] - 0s 229us/sample - loss: 0.5344 - accuracy: 0.8019 - val_loss: 0.6690 - val_accuracy: 0.7467\n",
      "Epoch 198/600\n",
      "1050/1050 [==============================] - 0s 238us/sample - loss: 0.5350 - accuracy: 0.7971 - val_loss: 0.6682 - val_accuracy: 0.7489\n",
      "Epoch 199/600\n",
      "1050/1050 [==============================] - 0s 324us/sample - loss: 0.5344 - accuracy: 0.8000 - val_loss: 0.6715 - val_accuracy: 0.7422\n",
      "Epoch 200/600\n",
      "1050/1050 [==============================] - 0s 298us/sample - loss: 0.5341 - accuracy: 0.8010 - val_loss: 0.6684 - val_accuracy: 0.7511\n",
      "Epoch 201/600\n",
      "1050/1050 [==============================] - 0s 286us/sample - loss: 0.5337 - accuracy: 0.7981 - val_loss: 0.6668 - val_accuracy: 0.7467\n",
      "Epoch 202/600\n",
      "1050/1050 [==============================] - 0s 295us/sample - loss: 0.5352 - accuracy: 0.7962 - val_loss: 0.6681 - val_accuracy: 0.7444\n",
      "Epoch 203/600\n",
      "1050/1050 [==============================] - 0s 281us/sample - loss: 0.5326 - accuracy: 0.7962 - val_loss: 0.6649 - val_accuracy: 0.7467\n",
      "Epoch 204/600\n",
      "1050/1050 [==============================] - 0s 343us/sample - loss: 0.5342 - accuracy: 0.8010 - val_loss: 0.6673 - val_accuracy: 0.7489\n",
      "Epoch 205/600\n",
      "1050/1050 [==============================] - 0s 312us/sample - loss: 0.5336 - accuracy: 0.7971 - val_loss: 0.6667 - val_accuracy: 0.7489\n",
      "Epoch 206/600\n",
      "1050/1050 [==============================] - 0s 307us/sample - loss: 0.5326 - accuracy: 0.7962 - val_loss: 0.6679 - val_accuracy: 0.7533\n",
      "Epoch 207/600\n",
      "1050/1050 [==============================] - 0s 429us/sample - loss: 0.5328 - accuracy: 0.7971 - val_loss: 0.6677 - val_accuracy: 0.7467\n",
      "Epoch 208/600\n",
      "1050/1050 [==============================] - 0s 273us/sample - loss: 0.5323 - accuracy: 0.8038 - val_loss: 0.6637 - val_accuracy: 0.7489\n",
      "Epoch 209/600\n",
      "1050/1050 [==============================] - 0s 306us/sample - loss: 0.5330 - accuracy: 0.8019 - val_loss: 0.6651 - val_accuracy: 0.7533\n",
      "Epoch 210/600\n",
      "1050/1050 [==============================] - 0s 266us/sample - loss: 0.5354 - accuracy: 0.7981 - val_loss: 0.6689 - val_accuracy: 0.7422\n",
      "Epoch 211/600\n",
      "1050/1050 [==============================] - 0s 306us/sample - loss: 0.5329 - accuracy: 0.7971 - val_loss: 0.6660 - val_accuracy: 0.7467\n",
      "Epoch 212/600\n",
      "1050/1050 [==============================] - 0s 356us/sample - loss: 0.5341 - accuracy: 0.8000 - val_loss: 0.6705 - val_accuracy: 0.7467\n",
      "Epoch 213/600\n",
      "1050/1050 [==============================] - 0s 324us/sample - loss: 0.5320 - accuracy: 0.7981 - val_loss: 0.6648 - val_accuracy: 0.7489\n",
      "Epoch 214/600\n",
      "1050/1050 [==============================] - 0s 307us/sample - loss: 0.5331 - accuracy: 0.8029 - val_loss: 0.6653 - val_accuracy: 0.7511\n",
      "Epoch 215/600\n",
      "1050/1050 [==============================] - 0s 340us/sample - loss: 0.5351 - accuracy: 0.7952 - val_loss: 0.6688 - val_accuracy: 0.7467\n",
      "Epoch 216/600\n",
      "1050/1050 [==============================] - 0s 244us/sample - loss: 0.5357 - accuracy: 0.7971 - val_loss: 0.6679 - val_accuracy: 0.7356\n",
      "Epoch 217/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 0s 293us/sample - loss: 0.5325 - accuracy: 0.7952 - val_loss: 0.6685 - val_accuracy: 0.7467\n",
      "Epoch 218/600\n",
      "1050/1050 [==============================] - 0s 345us/sample - loss: 0.5318 - accuracy: 0.8000 - val_loss: 0.6659 - val_accuracy: 0.7378\n",
      "Epoch 219/600\n",
      "1050/1050 [==============================] - 0s 305us/sample - loss: 0.5323 - accuracy: 0.8000 - val_loss: 0.6662 - val_accuracy: 0.7422\n",
      "Epoch 220/600\n",
      "1050/1050 [==============================] - 0s 244us/sample - loss: 0.5297 - accuracy: 0.8010 - val_loss: 0.6664 - val_accuracy: 0.7400\n",
      "Epoch 221/600\n",
      "1050/1050 [==============================] - 0s 275us/sample - loss: 0.5325 - accuracy: 0.7990 - val_loss: 0.6623 - val_accuracy: 0.7467\n",
      "Epoch 222/600\n",
      "1050/1050 [==============================] - 0s 318us/sample - loss: 0.5374 - accuracy: 0.7943 - val_loss: 0.6675 - val_accuracy: 0.7444\n",
      "Epoch 223/600\n",
      "1050/1050 [==============================] - 0s 232us/sample - loss: 0.5304 - accuracy: 0.8057 - val_loss: 0.6641 - val_accuracy: 0.7422\n",
      "Epoch 224/600\n",
      "1050/1050 [==============================] - 0s 336us/sample - loss: 0.5321 - accuracy: 0.7990 - val_loss: 0.6671 - val_accuracy: 0.7489\n",
      "Epoch 225/600\n",
      "1050/1050 [==============================] - 0s 248us/sample - loss: 0.5331 - accuracy: 0.8000 - val_loss: 0.6664 - val_accuracy: 0.7467\n",
      "Epoch 226/600\n",
      "1050/1050 [==============================] - 0s 374us/sample - loss: 0.5301 - accuracy: 0.8000 - val_loss: 0.6666 - val_accuracy: 0.7422\n",
      "Epoch 227/600\n",
      "1050/1050 [==============================] - 0s 360us/sample - loss: 0.5327 - accuracy: 0.7971 - val_loss: 0.6629 - val_accuracy: 0.7489\n",
      "Epoch 228/600\n",
      "1050/1050 [==============================] - 0s 363us/sample - loss: 0.5310 - accuracy: 0.8048 - val_loss: 0.6671 - val_accuracy: 0.7444\n",
      "Epoch 229/600\n",
      "1050/1050 [==============================] - 0s 278us/sample - loss: 0.5294 - accuracy: 0.8038 - val_loss: 0.6634 - val_accuracy: 0.7444\n",
      "Epoch 230/600\n",
      "1050/1050 [==============================] - 0s 350us/sample - loss: 0.5307 - accuracy: 0.7990 - val_loss: 0.6662 - val_accuracy: 0.7356\n",
      "Epoch 231/600\n",
      "1050/1050 [==============================] - 0s 295us/sample - loss: 0.5301 - accuracy: 0.8019 - val_loss: 0.6623 - val_accuracy: 0.7422\n",
      "Epoch 232/600\n",
      "1050/1050 [==============================] - 0s 229us/sample - loss: 0.5298 - accuracy: 0.8019 - val_loss: 0.6638 - val_accuracy: 0.7444\n",
      "Epoch 233/600\n",
      "1050/1050 [==============================] - 0s 323us/sample - loss: 0.5332 - accuracy: 0.7990 - val_loss: 0.6671 - val_accuracy: 0.7444\n",
      "Epoch 234/600\n",
      "1050/1050 [==============================] - 0s 193us/sample - loss: 0.5298 - accuracy: 0.8010 - val_loss: 0.6626 - val_accuracy: 0.7422\n",
      "Epoch 235/600\n",
      "1050/1050 [==============================] - 0s 331us/sample - loss: 0.5291 - accuracy: 0.8000 - val_loss: 0.6634 - val_accuracy: 0.7444\n",
      "Epoch 236/600\n",
      "1050/1050 [==============================] - 0s 446us/sample - loss: 0.5288 - accuracy: 0.7990 - val_loss: 0.6623 - val_accuracy: 0.7444\n",
      "Epoch 237/600\n",
      "1050/1050 [==============================] - 0s 296us/sample - loss: 0.5314 - accuracy: 0.7981 - val_loss: 0.6644 - val_accuracy: 0.7467\n",
      "Epoch 238/600\n",
      "1050/1050 [==============================] - 0s 304us/sample - loss: 0.5304 - accuracy: 0.7990 - val_loss: 0.6636 - val_accuracy: 0.7467\n",
      "Epoch 239/600\n",
      "1050/1050 [==============================] - 0s 272us/sample - loss: 0.5303 - accuracy: 0.7981 - val_loss: 0.6695 - val_accuracy: 0.7333\n",
      "Epoch 240/600\n",
      "1050/1050 [==============================] - 0s 275us/sample - loss: 0.5305 - accuracy: 0.8029 - val_loss: 0.6652 - val_accuracy: 0.7444\n",
      "Epoch 241/600\n",
      "1050/1050 [==============================] - 0s 263us/sample - loss: 0.5293 - accuracy: 0.8000 - val_loss: 0.6610 - val_accuracy: 0.7444\n",
      "Epoch 242/600\n",
      "1050/1050 [==============================] - 0s 319us/sample - loss: 0.5306 - accuracy: 0.8000 - val_loss: 0.6624 - val_accuracy: 0.7400\n",
      "Epoch 243/600\n",
      "1050/1050 [==============================] - 0s 361us/sample - loss: 0.5291 - accuracy: 0.8010 - val_loss: 0.6681 - val_accuracy: 0.7400\n",
      "Epoch 244/600\n",
      "1050/1050 [==============================] - 0s 350us/sample - loss: 0.5287 - accuracy: 0.8019 - val_loss: 0.6641 - val_accuracy: 0.7444\n",
      "Epoch 245/600\n",
      "1050/1050 [==============================] - 0s 278us/sample - loss: 0.5307 - accuracy: 0.8029 - val_loss: 0.6640 - val_accuracy: 0.7400\n",
      "Epoch 246/600\n",
      "1050/1050 [==============================] - 0s 281us/sample - loss: 0.5278 - accuracy: 0.8000 - val_loss: 0.6615 - val_accuracy: 0.7489\n",
      "Epoch 247/600\n",
      "1050/1050 [==============================] - 0s 346us/sample - loss: 0.5301 - accuracy: 0.8019 - val_loss: 0.6610 - val_accuracy: 0.7467\n",
      "Epoch 248/600\n",
      "1050/1050 [==============================] - 0s 304us/sample - loss: 0.5288 - accuracy: 0.8038 - val_loss: 0.6624 - val_accuracy: 0.7400\n",
      "Epoch 249/600\n",
      "1050/1050 [==============================] - 0s 296us/sample - loss: 0.5305 - accuracy: 0.8048 - val_loss: 0.6653 - val_accuracy: 0.7467\n",
      "Epoch 250/600\n",
      "1050/1050 [==============================] - 0s 250us/sample - loss: 0.5292 - accuracy: 0.8010 - val_loss: 0.6636 - val_accuracy: 0.7378\n",
      "Epoch 251/600\n",
      "1050/1050 [==============================] - 0s 258us/sample - loss: 0.5295 - accuracy: 0.8000 - val_loss: 0.6647 - val_accuracy: 0.7400\n",
      "Epoch 252/600\n",
      "1050/1050 [==============================] - 0s 380us/sample - loss: 0.5306 - accuracy: 0.7971 - val_loss: 0.6603 - val_accuracy: 0.7444\n",
      "Epoch 253/600\n",
      "1050/1050 [==============================] - 0s 411us/sample - loss: 0.5277 - accuracy: 0.8000 - val_loss: 0.6679 - val_accuracy: 0.7356\n",
      "Epoch 254/600\n",
      "1050/1050 [==============================] - 0s 309us/sample - loss: 0.5285 - accuracy: 0.7981 - val_loss: 0.6658 - val_accuracy: 0.7400\n",
      "Epoch 255/600\n",
      "1050/1050 [==============================] - 0s 222us/sample - loss: 0.5269 - accuracy: 0.7971 - val_loss: 0.6603 - val_accuracy: 0.7489\n",
      "Epoch 256/600\n",
      "1050/1050 [==============================] - 0s 269us/sample - loss: 0.5292 - accuracy: 0.8019 - val_loss: 0.6650 - val_accuracy: 0.7378\n",
      "Epoch 257/600\n",
      "1050/1050 [==============================] - 0s 246us/sample - loss: 0.5283 - accuracy: 0.8038 - val_loss: 0.6657 - val_accuracy: 0.7356\n",
      "Epoch 258/600\n",
      "1050/1050 [==============================] - 0s 408us/sample - loss: 0.5278 - accuracy: 0.8019 - val_loss: 0.6607 - val_accuracy: 0.7467\n",
      "Epoch 259/600\n",
      "1050/1050 [==============================] - 0s 377us/sample - loss: 0.5290 - accuracy: 0.7952 - val_loss: 0.6625 - val_accuracy: 0.7422\n",
      "Epoch 260/600\n",
      "1050/1050 [==============================] - 0s 367us/sample - loss: 0.5278 - accuracy: 0.8000 - val_loss: 0.6627 - val_accuracy: 0.7444\n",
      "Epoch 261/600\n",
      "1050/1050 [==============================] - 0s 356us/sample - loss: 0.5290 - accuracy: 0.8019 - val_loss: 0.6585 - val_accuracy: 0.7444\n",
      "Epoch 262/600\n",
      "1050/1050 [==============================] - 0s 308us/sample - loss: 0.5262 - accuracy: 0.8029 - val_loss: 0.6599 - val_accuracy: 0.7378\n",
      "Epoch 263/600\n",
      "1050/1050 [==============================] - 0s 308us/sample - loss: 0.5281 - accuracy: 0.7971 - val_loss: 0.6660 - val_accuracy: 0.7378\n",
      "Epoch 264/600\n",
      "1050/1050 [==============================] - 0s 212us/sample - loss: 0.5261 - accuracy: 0.8048 - val_loss: 0.6616 - val_accuracy: 0.7378\n",
      "Epoch 265/600\n",
      "1050/1050 [==============================] - 0s 336us/sample - loss: 0.5275 - accuracy: 0.8029 - val_loss: 0.6645 - val_accuracy: 0.7422\n",
      "Epoch 266/600\n",
      "1050/1050 [==============================] - 0s 333us/sample - loss: 0.5261 - accuracy: 0.8057 - val_loss: 0.6605 - val_accuracy: 0.7422\n",
      "Epoch 267/600\n",
      "1050/1050 [==============================] - 0s 278us/sample - loss: 0.5256 - accuracy: 0.8019 - val_loss: 0.6625 - val_accuracy: 0.7333\n",
      "Epoch 268/600\n",
      "1050/1050 [==============================] - 0s 276us/sample - loss: 0.5255 - accuracy: 0.8019 - val_loss: 0.6648 - val_accuracy: 0.7356\n",
      "Epoch 269/600\n",
      "1050/1050 [==============================] - 0s 274us/sample - loss: 0.5262 - accuracy: 0.7981 - val_loss: 0.6599 - val_accuracy: 0.7444\n",
      "Epoch 270/600\n",
      "1050/1050 [==============================] - 0s 317us/sample - loss: 0.5274 - accuracy: 0.7971 - val_loss: 0.6637 - val_accuracy: 0.7356\n",
      "Epoch 271/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 0s 346us/sample - loss: 0.5263 - accuracy: 0.7990 - val_loss: 0.6624 - val_accuracy: 0.7378\n",
      "Epoch 272/600\n",
      "1050/1050 [==============================] - 0s 286us/sample - loss: 0.5253 - accuracy: 0.8010 - val_loss: 0.6616 - val_accuracy: 0.7378\n",
      "Epoch 273/600\n",
      "1050/1050 [==============================] - 0s 271us/sample - loss: 0.5265 - accuracy: 0.7990 - val_loss: 0.6626 - val_accuracy: 0.7356\n",
      "Epoch 274/600\n",
      "1050/1050 [==============================] - 0s 245us/sample - loss: 0.5258 - accuracy: 0.8048 - val_loss: 0.6631 - val_accuracy: 0.7378\n",
      "Epoch 275/600\n",
      "1050/1050 [==============================] - 0s 276us/sample - loss: 0.5266 - accuracy: 0.7981 - val_loss: 0.6623 - val_accuracy: 0.7333\n",
      "Epoch 276/600\n",
      "1050/1050 [==============================] - 0s 230us/sample - loss: 0.5269 - accuracy: 0.8019 - val_loss: 0.6637 - val_accuracy: 0.7356\n",
      "Epoch 277/600\n",
      "1050/1050 [==============================] - 0s 235us/sample - loss: 0.5264 - accuracy: 0.8000 - val_loss: 0.6609 - val_accuracy: 0.7422\n",
      "Epoch 278/600\n",
      "1050/1050 [==============================] - 0s 228us/sample - loss: 0.5259 - accuracy: 0.8000 - val_loss: 0.6643 - val_accuracy: 0.7356\n",
      "Epoch 279/600\n",
      "1050/1050 [==============================] - 0s 219us/sample - loss: 0.5289 - accuracy: 0.8038 - val_loss: 0.6601 - val_accuracy: 0.7356\n",
      "Epoch 280/600\n",
      "1050/1050 [==============================] - 0s 284us/sample - loss: 0.5282 - accuracy: 0.8000 - val_loss: 0.6638 - val_accuracy: 0.7356\n",
      "Epoch 281/600\n",
      "1050/1050 [==============================] - 0s 234us/sample - loss: 0.5240 - accuracy: 0.8019 - val_loss: 0.6606 - val_accuracy: 0.7444\n",
      "Epoch 282/600\n",
      "1050/1050 [==============================] - 0s 287us/sample - loss: 0.5263 - accuracy: 0.7990 - val_loss: 0.6631 - val_accuracy: 0.7356\n",
      "Epoch 283/600\n",
      "1050/1050 [==============================] - 0s 309us/sample - loss: 0.5249 - accuracy: 0.8000 - val_loss: 0.6597 - val_accuracy: 0.7489\n",
      "Epoch 284/600\n",
      "1050/1050 [==============================] - 0s 276us/sample - loss: 0.5255 - accuracy: 0.8010 - val_loss: 0.6638 - val_accuracy: 0.7378\n",
      "Epoch 285/600\n",
      "1050/1050 [==============================] - 0s 268us/sample - loss: 0.5242 - accuracy: 0.8048 - val_loss: 0.6602 - val_accuracy: 0.7400\n",
      "Epoch 286/600\n",
      "1050/1050 [==============================] - 0s 256us/sample - loss: 0.5268 - accuracy: 0.8019 - val_loss: 0.6623 - val_accuracy: 0.7378\n",
      "Epoch 287/600\n",
      "1050/1050 [==============================] - 0s 236us/sample - loss: 0.5245 - accuracy: 0.8029 - val_loss: 0.6650 - val_accuracy: 0.7378\n",
      "Epoch 288/600\n",
      "1050/1050 [==============================] - 0s 264us/sample - loss: 0.5257 - accuracy: 0.8010 - val_loss: 0.6601 - val_accuracy: 0.7356\n",
      "Epoch 289/600\n",
      "1050/1050 [==============================] - 0s 258us/sample - loss: 0.5265 - accuracy: 0.8019 - val_loss: 0.6610 - val_accuracy: 0.7400\n",
      "Epoch 290/600\n",
      "1050/1050 [==============================] - 0s 252us/sample - loss: 0.5250 - accuracy: 0.8010 - val_loss: 0.6615 - val_accuracy: 0.7378\n",
      "Epoch 291/600\n",
      "1050/1050 [==============================] - 0s 235us/sample - loss: 0.5251 - accuracy: 0.8019 - val_loss: 0.6608 - val_accuracy: 0.7356\n",
      "Epoch 292/600\n",
      "1050/1050 [==============================] - 0s 226us/sample - loss: 0.5282 - accuracy: 0.7943 - val_loss: 0.6618 - val_accuracy: 0.7378\n",
      "Epoch 293/600\n",
      "1050/1050 [==============================] - 0s 243us/sample - loss: 0.5253 - accuracy: 0.7981 - val_loss: 0.6586 - val_accuracy: 0.7378\n",
      "Epoch 294/600\n",
      "1050/1050 [==============================] - 0s 237us/sample - loss: 0.5239 - accuracy: 0.8010 - val_loss: 0.6608 - val_accuracy: 0.7400\n",
      "Epoch 295/600\n",
      "1050/1050 [==============================] - 0s 242us/sample - loss: 0.5248 - accuracy: 0.8000 - val_loss: 0.6605 - val_accuracy: 0.7356\n",
      "Epoch 296/600\n",
      "1050/1050 [==============================] - 0s 293us/sample - loss: 0.5253 - accuracy: 0.8048 - val_loss: 0.6607 - val_accuracy: 0.7333\n",
      "Epoch 297/600\n",
      "1050/1050 [==============================] - 0s 237us/sample - loss: 0.5266 - accuracy: 0.8019 - val_loss: 0.6616 - val_accuracy: 0.7422\n",
      "Epoch 298/600\n",
      "1050/1050 [==============================] - 0s 265us/sample - loss: 0.5245 - accuracy: 0.7981 - val_loss: 0.6659 - val_accuracy: 0.7400\n",
      "Epoch 299/600\n",
      "1050/1050 [==============================] - 0s 325us/sample - loss: 0.5255 - accuracy: 0.8010 - val_loss: 0.6590 - val_accuracy: 0.7356\n",
      "Epoch 300/600\n",
      "1050/1050 [==============================] - 0s 289us/sample - loss: 0.5247 - accuracy: 0.8038 - val_loss: 0.6628 - val_accuracy: 0.7356\n",
      "Epoch 301/600\n",
      "1050/1050 [==============================] - 0s 259us/sample - loss: 0.5246 - accuracy: 0.7990 - val_loss: 0.6614 - val_accuracy: 0.7378\n",
      "Epoch 302/600\n",
      "1050/1050 [==============================] - 0s 352us/sample - loss: 0.5246 - accuracy: 0.8010 - val_loss: 0.6600 - val_accuracy: 0.7422\n",
      "Epoch 303/600\n",
      "1050/1050 [==============================] - 0s 295us/sample - loss: 0.5251 - accuracy: 0.8019 - val_loss: 0.6603 - val_accuracy: 0.7378\n",
      "Epoch 304/600\n",
      "1050/1050 [==============================] - 0s 309us/sample - loss: 0.5285 - accuracy: 0.7981 - val_loss: 0.6648 - val_accuracy: 0.7333\n",
      "Epoch 305/600\n",
      "1050/1050 [==============================] - 0s 408us/sample - loss: 0.5246 - accuracy: 0.8010 - val_loss: 0.6577 - val_accuracy: 0.7422\n",
      "Epoch 306/600\n",
      "1050/1050 [==============================] - 0s 299us/sample - loss: 0.5245 - accuracy: 0.8000 - val_loss: 0.6647 - val_accuracy: 0.7444\n",
      "Epoch 307/600\n",
      "1050/1050 [==============================] - 0s 381us/sample - loss: 0.5243 - accuracy: 0.7990 - val_loss: 0.6617 - val_accuracy: 0.7400\n",
      "Epoch 308/600\n",
      "1050/1050 [==============================] - 0s 320us/sample - loss: 0.5242 - accuracy: 0.8010 - val_loss: 0.6593 - val_accuracy: 0.7356\n",
      "Epoch 309/600\n",
      "1050/1050 [==============================] - 0s 288us/sample - loss: 0.5232 - accuracy: 0.8019 - val_loss: 0.6612 - val_accuracy: 0.7400\n",
      "Epoch 310/600\n",
      "1050/1050 [==============================] - 0s 264us/sample - loss: 0.5243 - accuracy: 0.8019 - val_loss: 0.6590 - val_accuracy: 0.7444\n",
      "Epoch 311/600\n",
      "1050/1050 [==============================] - 0s 305us/sample - loss: 0.5230 - accuracy: 0.8029 - val_loss: 0.6623 - val_accuracy: 0.7378\n",
      "Epoch 312/600\n",
      "1050/1050 [==============================] - 0s 275us/sample - loss: 0.5255 - accuracy: 0.7981 - val_loss: 0.6554 - val_accuracy: 0.7356\n",
      "Epoch 313/600\n",
      "1050/1050 [==============================] - 0s 199us/sample - loss: 0.5234 - accuracy: 0.8029 - val_loss: 0.6620 - val_accuracy: 0.7422\n",
      "Epoch 314/600\n",
      "1050/1050 [==============================] - 0s 281us/sample - loss: 0.5238 - accuracy: 0.8048 - val_loss: 0.6602 - val_accuracy: 0.7400\n",
      "Epoch 315/600\n",
      "1050/1050 [==============================] - 0s 254us/sample - loss: 0.5261 - accuracy: 0.7990 - val_loss: 0.6611 - val_accuracy: 0.7400\n",
      "Epoch 316/600\n",
      "1050/1050 [==============================] - 0s 240us/sample - loss: 0.5236 - accuracy: 0.8057 - val_loss: 0.6621 - val_accuracy: 0.7511\n",
      "Epoch 317/600\n",
      "1050/1050 [==============================] - 0s 257us/sample - loss: 0.5243 - accuracy: 0.7952 - val_loss: 0.6594 - val_accuracy: 0.7400\n",
      "Epoch 318/600\n",
      "1050/1050 [==============================] - 0s 273us/sample - loss: 0.5216 - accuracy: 0.8029 - val_loss: 0.6590 - val_accuracy: 0.7422\n",
      "Epoch 319/600\n",
      "1050/1050 [==============================] - 0s 241us/sample - loss: 0.5249 - accuracy: 0.8019 - val_loss: 0.6596 - val_accuracy: 0.7422\n",
      "Epoch 320/600\n",
      "1050/1050 [==============================] - 0s 208us/sample - loss: 0.5236 - accuracy: 0.8076 - val_loss: 0.6643 - val_accuracy: 0.7444\n",
      "Epoch 321/600\n",
      "1050/1050 [==============================] - 0s 238us/sample - loss: 0.5238 - accuracy: 0.8000 - val_loss: 0.6579 - val_accuracy: 0.7356\n",
      "Epoch 322/600\n",
      "1050/1050 [==============================] - 0s 310us/sample - loss: 0.5221 - accuracy: 0.8048 - val_loss: 0.6622 - val_accuracy: 0.7378\n",
      "Epoch 323/600\n",
      "1050/1050 [==============================] - 0s 305us/sample - loss: 0.5227 - accuracy: 0.8000 - val_loss: 0.6622 - val_accuracy: 0.7356\n",
      "Epoch 324/600\n",
      "1050/1050 [==============================] - 0s 273us/sample - loss: 0.5221 - accuracy: 0.8029 - val_loss: 0.6576 - val_accuracy: 0.7356\n",
      "Epoch 325/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 0s 282us/sample - loss: 0.5230 - accuracy: 0.8019 - val_loss: 0.6637 - val_accuracy: 0.7400\n",
      "Epoch 326/600\n",
      "1050/1050 [==============================] - 0s 297us/sample - loss: 0.5259 - accuracy: 0.7981 - val_loss: 0.6579 - val_accuracy: 0.7422\n",
      "Epoch 327/600\n",
      "1050/1050 [==============================] - 0s 253us/sample - loss: 0.5225 - accuracy: 0.8029 - val_loss: 0.6662 - val_accuracy: 0.7378\n",
      "Epoch 328/600\n",
      "1050/1050 [==============================] - 0s 275us/sample - loss: 0.5217 - accuracy: 0.8029 - val_loss: 0.6571 - val_accuracy: 0.7400\n",
      "Epoch 329/600\n",
      "1050/1050 [==============================] - 0s 227us/sample - loss: 0.5224 - accuracy: 0.7990 - val_loss: 0.6604 - val_accuracy: 0.7422\n",
      "Epoch 330/600\n",
      "1050/1050 [==============================] - 0s 259us/sample - loss: 0.5226 - accuracy: 0.8010 - val_loss: 0.6583 - val_accuracy: 0.7422\n",
      "Epoch 331/600\n",
      "1050/1050 [==============================] - 0s 281us/sample - loss: 0.5234 - accuracy: 0.8000 - val_loss: 0.6582 - val_accuracy: 0.7422\n",
      "Epoch 332/600\n",
      "1050/1050 [==============================] - 0s 260us/sample - loss: 0.5216 - accuracy: 0.8000 - val_loss: 0.6628 - val_accuracy: 0.7378\n",
      "Epoch 333/600\n",
      "1050/1050 [==============================] - 0s 207us/sample - loss: 0.5254 - accuracy: 0.8000 - val_loss: 0.6617 - val_accuracy: 0.7444\n",
      "Epoch 334/600\n",
      "1050/1050 [==============================] - 0s 353us/sample - loss: 0.5229 - accuracy: 0.7981 - val_loss: 0.6554 - val_accuracy: 0.7444\n",
      "Epoch 335/600\n",
      "1050/1050 [==============================] - 0s 236us/sample - loss: 0.5225 - accuracy: 0.8000 - val_loss: 0.6628 - val_accuracy: 0.7400\n",
      "Epoch 336/600\n",
      "1050/1050 [==============================] - 0s 195us/sample - loss: 0.5233 - accuracy: 0.8010 - val_loss: 0.6587 - val_accuracy: 0.7400\n",
      "Epoch 337/600\n",
      "1050/1050 [==============================] - 0s 233us/sample - loss: 0.5207 - accuracy: 0.8029 - val_loss: 0.6559 - val_accuracy: 0.7422\n",
      "Epoch 338/600\n",
      "1050/1050 [==============================] - 0s 239us/sample - loss: 0.5230 - accuracy: 0.8010 - val_loss: 0.6622 - val_accuracy: 0.7378\n",
      "Epoch 339/600\n",
      "1050/1050 [==============================] - 0s 249us/sample - loss: 0.5234 - accuracy: 0.8038 - val_loss: 0.6551 - val_accuracy: 0.7400\n",
      "Epoch 340/600\n",
      "1050/1050 [==============================] - 0s 286us/sample - loss: 0.5225 - accuracy: 0.8029 - val_loss: 0.6577 - val_accuracy: 0.7444\n",
      "Epoch 341/600\n",
      "1050/1050 [==============================] - 0s 274us/sample - loss: 0.5215 - accuracy: 0.8038 - val_loss: 0.6554 - val_accuracy: 0.7378\n",
      "Epoch 342/600\n",
      "1050/1050 [==============================] - 0s 327us/sample - loss: 0.5214 - accuracy: 0.8019 - val_loss: 0.6583 - val_accuracy: 0.7444\n",
      "Epoch 343/600\n",
      "1050/1050 [==============================] - 0s 279us/sample - loss: 0.5254 - accuracy: 0.7962 - val_loss: 0.6604 - val_accuracy: 0.7378\n",
      "Epoch 344/600\n",
      "1050/1050 [==============================] - 0s 369us/sample - loss: 0.5225 - accuracy: 0.8019 - val_loss: 0.6605 - val_accuracy: 0.7356\n",
      "Epoch 345/600\n",
      "1050/1050 [==============================] - 0s 372us/sample - loss: 0.5205 - accuracy: 0.8038 - val_loss: 0.6550 - val_accuracy: 0.7378\n",
      "Epoch 346/600\n",
      "1050/1050 [==============================] - 0s 299us/sample - loss: 0.5215 - accuracy: 0.8038 - val_loss: 0.6574 - val_accuracy: 0.7444\n",
      "Epoch 347/600\n",
      "1050/1050 [==============================] - 0s 306us/sample - loss: 0.5225 - accuracy: 0.8019 - val_loss: 0.6615 - val_accuracy: 0.7400\n",
      "Epoch 348/600\n",
      "1050/1050 [==============================] - 0s 358us/sample - loss: 0.5225 - accuracy: 0.8010 - val_loss: 0.6574 - val_accuracy: 0.7467\n",
      "Epoch 349/600\n",
      "1050/1050 [==============================] - 0s 258us/sample - loss: 0.5211 - accuracy: 0.7990 - val_loss: 0.6615 - val_accuracy: 0.7400\n",
      "Epoch 350/600\n",
      "1050/1050 [==============================] - 0s 226us/sample - loss: 0.5219 - accuracy: 0.8019 - val_loss: 0.6590 - val_accuracy: 0.7400\n",
      "Epoch 351/600\n",
      "1050/1050 [==============================] - 0s 265us/sample - loss: 0.5211 - accuracy: 0.7981 - val_loss: 0.6628 - val_accuracy: 0.7400\n",
      "Epoch 352/600\n",
      "1050/1050 [==============================] - 0s 259us/sample - loss: 0.5210 - accuracy: 0.8029 - val_loss: 0.6541 - val_accuracy: 0.7444\n",
      "Epoch 353/600\n",
      "1050/1050 [==============================] - 0s 287us/sample - loss: 0.5209 - accuracy: 0.8010 - val_loss: 0.6558 - val_accuracy: 0.7467\n",
      "Epoch 354/600\n",
      "1050/1050 [==============================] - 0s 234us/sample - loss: 0.5203 - accuracy: 0.8029 - val_loss: 0.6575 - val_accuracy: 0.7378\n",
      "Epoch 355/600\n",
      "1050/1050 [==============================] - 0s 239us/sample - loss: 0.5234 - accuracy: 0.7990 - val_loss: 0.6594 - val_accuracy: 0.7489\n",
      "Epoch 356/600\n",
      "1050/1050 [==============================] - 0s 252us/sample - loss: 0.5225 - accuracy: 0.8057 - val_loss: 0.6592 - val_accuracy: 0.7378\n",
      "Epoch 357/600\n",
      "1050/1050 [==============================] - 0s 282us/sample - loss: 0.5234 - accuracy: 0.8010 - val_loss: 0.6581 - val_accuracy: 0.7511\n",
      "Epoch 358/600\n",
      "1050/1050 [==============================] - 0s 253us/sample - loss: 0.5222 - accuracy: 0.8029 - val_loss: 0.6545 - val_accuracy: 0.7444\n",
      "Epoch 359/600\n",
      "1050/1050 [==============================] - 0s 247us/sample - loss: 0.5221 - accuracy: 0.7981 - val_loss: 0.6592 - val_accuracy: 0.7400\n",
      "Epoch 360/600\n",
      "1050/1050 [==============================] - 0s 278us/sample - loss: 0.5219 - accuracy: 0.8019 - val_loss: 0.6630 - val_accuracy: 0.7422\n",
      "Epoch 361/600\n",
      "1050/1050 [==============================] - 0s 330us/sample - loss: 0.5212 - accuracy: 0.7981 - val_loss: 0.6570 - val_accuracy: 0.7444\n",
      "Epoch 362/600\n",
      "1050/1050 [==============================] - 0s 293us/sample - loss: 0.5225 - accuracy: 0.8048 - val_loss: 0.6580 - val_accuracy: 0.7467\n",
      "Epoch 363/600\n",
      "1050/1050 [==============================] - 0s 211us/sample - loss: 0.5191 - accuracy: 0.8048 - val_loss: 0.6562 - val_accuracy: 0.7400\n",
      "Epoch 364/600\n",
      "1050/1050 [==============================] - 0s 235us/sample - loss: 0.5206 - accuracy: 0.8010 - val_loss: 0.6563 - val_accuracy: 0.7422\n",
      "Epoch 365/600\n",
      "1050/1050 [==============================] - 0s 259us/sample - loss: 0.5212 - accuracy: 0.8010 - val_loss: 0.6608 - val_accuracy: 0.7467\n",
      "Epoch 366/600\n",
      "1050/1050 [==============================] - 0s 234us/sample - loss: 0.5212 - accuracy: 0.8000 - val_loss: 0.6557 - val_accuracy: 0.7467\n",
      "Epoch 367/600\n",
      "1050/1050 [==============================] - 0s 239us/sample - loss: 0.5228 - accuracy: 0.8000 - val_loss: 0.6562 - val_accuracy: 0.7422\n",
      "Epoch 368/600\n",
      "1050/1050 [==============================] - 0s 265us/sample - loss: 0.5206 - accuracy: 0.8019 - val_loss: 0.6582 - val_accuracy: 0.7422\n",
      "Epoch 369/600\n",
      "1050/1050 [==============================] - 0s 273us/sample - loss: 0.5182 - accuracy: 0.8038 - val_loss: 0.6540 - val_accuracy: 0.7467\n",
      "Epoch 370/600\n",
      "1050/1050 [==============================] - 0s 252us/sample - loss: 0.5207 - accuracy: 0.8019 - val_loss: 0.6577 - val_accuracy: 0.7378\n",
      "Epoch 371/600\n",
      "1050/1050 [==============================] - 0s 280us/sample - loss: 0.5201 - accuracy: 0.8038 - val_loss: 0.6538 - val_accuracy: 0.7533\n",
      "Epoch 372/600\n",
      "1050/1050 [==============================] - 0s 303us/sample - loss: 0.5200 - accuracy: 0.8019 - val_loss: 0.6583 - val_accuracy: 0.7489\n",
      "Epoch 373/600\n",
      "1050/1050 [==============================] - 0s 294us/sample - loss: 0.5197 - accuracy: 0.8010 - val_loss: 0.6585 - val_accuracy: 0.7444\n",
      "Epoch 374/600\n",
      "1050/1050 [==============================] - 0s 279us/sample - loss: 0.5203 - accuracy: 0.8029 - val_loss: 0.6580 - val_accuracy: 0.7422\n",
      "Epoch 375/600\n",
      "1050/1050 [==============================] - 0s 235us/sample - loss: 0.5187 - accuracy: 0.7981 - val_loss: 0.6586 - val_accuracy: 0.7444\n",
      "Epoch 376/600\n",
      "1050/1050 [==============================] - 0s 247us/sample - loss: 0.5217 - accuracy: 0.7990 - val_loss: 0.6584 - val_accuracy: 0.7444\n",
      "Epoch 377/600\n",
      "1050/1050 [==============================] - 0s 275us/sample - loss: 0.5204 - accuracy: 0.8010 - val_loss: 0.6529 - val_accuracy: 0.7489\n",
      "Epoch 378/600\n",
      "1050/1050 [==============================] - 0s 245us/sample - loss: 0.5196 - accuracy: 0.8029 - val_loss: 0.6540 - val_accuracy: 0.7422\n",
      "Epoch 379/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 0s 316us/sample - loss: 0.5201 - accuracy: 0.8029 - val_loss: 0.6536 - val_accuracy: 0.7467\n",
      "Epoch 380/600\n",
      "1050/1050 [==============================] - 0s 236us/sample - loss: 0.5199 - accuracy: 0.8000 - val_loss: 0.6552 - val_accuracy: 0.7444\n",
      "Epoch 381/600\n",
      "1050/1050 [==============================] - 0s 247us/sample - loss: 0.5223 - accuracy: 0.8010 - val_loss: 0.6575 - val_accuracy: 0.7400\n",
      "Epoch 382/600\n",
      "1050/1050 [==============================] - 0s 209us/sample - loss: 0.5233 - accuracy: 0.8000 - val_loss: 0.6556 - val_accuracy: 0.7422\n",
      "Epoch 383/600\n",
      "1050/1050 [==============================] - 0s 256us/sample - loss: 0.5179 - accuracy: 0.8048 - val_loss: 0.6558 - val_accuracy: 0.7444\n",
      "Epoch 384/600\n",
      "1050/1050 [==============================] - 0s 223us/sample - loss: 0.5189 - accuracy: 0.8019 - val_loss: 0.6551 - val_accuracy: 0.7422\n",
      "Epoch 385/600\n",
      "1050/1050 [==============================] - 0s 221us/sample - loss: 0.5207 - accuracy: 0.8038 - val_loss: 0.6542 - val_accuracy: 0.7511\n",
      "Epoch 386/600\n",
      "1050/1050 [==============================] - 0s 240us/sample - loss: 0.5218 - accuracy: 0.8029 - val_loss: 0.6599 - val_accuracy: 0.7467\n",
      "Epoch 387/600\n",
      "1050/1050 [==============================] - 0s 240us/sample - loss: 0.5217 - accuracy: 0.8010 - val_loss: 0.6535 - val_accuracy: 0.7467\n",
      "Epoch 388/600\n",
      "1050/1050 [==============================] - 0s 251us/sample - loss: 0.5205 - accuracy: 0.7990 - val_loss: 0.6563 - val_accuracy: 0.7422\n",
      "Epoch 389/600\n",
      "1050/1050 [==============================] - 0s 216us/sample - loss: 0.5194 - accuracy: 0.8019 - val_loss: 0.6562 - val_accuracy: 0.7378\n",
      "Epoch 390/600\n",
      "1050/1050 [==============================] - 0s 236us/sample - loss: 0.5200 - accuracy: 0.8010 - val_loss: 0.6547 - val_accuracy: 0.7467\n",
      "Epoch 391/600\n",
      "1050/1050 [==============================] - 0s 279us/sample - loss: 0.5182 - accuracy: 0.8057 - val_loss: 0.6537 - val_accuracy: 0.7400\n",
      "Epoch 392/600\n",
      "1050/1050 [==============================] - 0s 323us/sample - loss: 0.5181 - accuracy: 0.8029 - val_loss: 0.6536 - val_accuracy: 0.7511\n",
      "Epoch 393/600\n",
      "1050/1050 [==============================] - 0s 262us/sample - loss: 0.5197 - accuracy: 0.7971 - val_loss: 0.6560 - val_accuracy: 0.7511\n",
      "Epoch 394/600\n",
      "1050/1050 [==============================] - 0s 228us/sample - loss: 0.5216 - accuracy: 0.8010 - val_loss: 0.6516 - val_accuracy: 0.7444\n",
      "Epoch 395/600\n",
      "1050/1050 [==============================] - 0s 227us/sample - loss: 0.5213 - accuracy: 0.8010 - val_loss: 0.6540 - val_accuracy: 0.7578\n",
      "Epoch 396/600\n",
      "1050/1050 [==============================] - 0s 239us/sample - loss: 0.5202 - accuracy: 0.7990 - val_loss: 0.6528 - val_accuracy: 0.7400\n",
      "Epoch 397/600\n",
      "1050/1050 [==============================] - 0s 217us/sample - loss: 0.5191 - accuracy: 0.7971 - val_loss: 0.6544 - val_accuracy: 0.7489\n",
      "Epoch 398/600\n",
      "1050/1050 [==============================] - 0s 244us/sample - loss: 0.5201 - accuracy: 0.8038 - val_loss: 0.6569 - val_accuracy: 0.7422\n",
      "Epoch 399/600\n",
      "1050/1050 [==============================] - 0s 284us/sample - loss: 0.5191 - accuracy: 0.7971 - val_loss: 0.6531 - val_accuracy: 0.7578\n",
      "Epoch 400/600\n",
      "1050/1050 [==============================] - 0s 237us/sample - loss: 0.5184 - accuracy: 0.8029 - val_loss: 0.6579 - val_accuracy: 0.7378\n",
      "Epoch 401/600\n",
      "1050/1050 [==============================] - 0s 269us/sample - loss: 0.5180 - accuracy: 0.8019 - val_loss: 0.6509 - val_accuracy: 0.7489\n",
      "Epoch 402/600\n",
      "1050/1050 [==============================] - 0s 223us/sample - loss: 0.5181 - accuracy: 0.8029 - val_loss: 0.6556 - val_accuracy: 0.7489\n",
      "Epoch 403/600\n",
      "1050/1050 [==============================] - 0s 258us/sample - loss: 0.5182 - accuracy: 0.8010 - val_loss: 0.6512 - val_accuracy: 0.7444\n",
      "Epoch 404/600\n",
      "1050/1050 [==============================] - 0s 229us/sample - loss: 0.5194 - accuracy: 0.8067 - val_loss: 0.6573 - val_accuracy: 0.7489\n",
      "Epoch 405/600\n",
      "1050/1050 [==============================] - 0s 275us/sample - loss: 0.5189 - accuracy: 0.8029 - val_loss: 0.6540 - val_accuracy: 0.7489\n",
      "Epoch 406/600\n",
      "1050/1050 [==============================] - 0s 322us/sample - loss: 0.5193 - accuracy: 0.8038 - val_loss: 0.6546 - val_accuracy: 0.7422\n",
      "Epoch 407/600\n",
      "1050/1050 [==============================] - 0s 228us/sample - loss: 0.5171 - accuracy: 0.8010 - val_loss: 0.6526 - val_accuracy: 0.7533\n",
      "Epoch 408/600\n",
      "1050/1050 [==============================] - 0s 198us/sample - loss: 0.5197 - accuracy: 0.8038 - val_loss: 0.6571 - val_accuracy: 0.7422\n",
      "Epoch 409/600\n",
      "1050/1050 [==============================] - 0s 298us/sample - loss: 0.5188 - accuracy: 0.8000 - val_loss: 0.6528 - val_accuracy: 0.7400\n",
      "Epoch 410/600\n",
      "1050/1050 [==============================] - 0s 232us/sample - loss: 0.5197 - accuracy: 0.8029 - val_loss: 0.6588 - val_accuracy: 0.7511\n",
      "Epoch 411/600\n",
      "1050/1050 [==============================] - 0s 239us/sample - loss: 0.5184 - accuracy: 0.8019 - val_loss: 0.6484 - val_accuracy: 0.7467\n",
      "Epoch 412/600\n",
      "1050/1050 [==============================] - 0s 254us/sample - loss: 0.5186 - accuracy: 0.8000 - val_loss: 0.6551 - val_accuracy: 0.7422\n",
      "Epoch 413/600\n",
      "1050/1050 [==============================] - 0s 214us/sample - loss: 0.5212 - accuracy: 0.8010 - val_loss: 0.6486 - val_accuracy: 0.7511\n",
      "Epoch 414/600\n",
      "1050/1050 [==============================] - 0s 209us/sample - loss: 0.5176 - accuracy: 0.8038 - val_loss: 0.6506 - val_accuracy: 0.7444\n",
      "Epoch 415/600\n",
      "1050/1050 [==============================] - 0s 281us/sample - loss: 0.5172 - accuracy: 0.8048 - val_loss: 0.6535 - val_accuracy: 0.7489\n",
      "Epoch 416/600\n",
      "1050/1050 [==============================] - 0s 300us/sample - loss: 0.5197 - accuracy: 0.8029 - val_loss: 0.6511 - val_accuracy: 0.7511\n",
      "Epoch 417/600\n",
      "1050/1050 [==============================] - 0s 232us/sample - loss: 0.5190 - accuracy: 0.8029 - val_loss: 0.6542 - val_accuracy: 0.7489\n",
      "Epoch 418/600\n",
      "1050/1050 [==============================] - 0s 265us/sample - loss: 0.5177 - accuracy: 0.8019 - val_loss: 0.6499 - val_accuracy: 0.7511\n",
      "Epoch 419/600\n",
      "1050/1050 [==============================] - 0s 194us/sample - loss: 0.5204 - accuracy: 0.8038 - val_loss: 0.6559 - val_accuracy: 0.7400\n",
      "Epoch 420/600\n",
      "1050/1050 [==============================] - 0s 195us/sample - loss: 0.5170 - accuracy: 0.8029 - val_loss: 0.6501 - val_accuracy: 0.7578\n",
      "Epoch 421/600\n",
      "1050/1050 [==============================] - 0s 241us/sample - loss: 0.5192 - accuracy: 0.8010 - val_loss: 0.6548 - val_accuracy: 0.7422\n",
      "Epoch 422/600\n",
      "1050/1050 [==============================] - 0s 297us/sample - loss: 0.5169 - accuracy: 0.8019 - val_loss: 0.6506 - val_accuracy: 0.7511\n",
      "Epoch 423/600\n",
      "1050/1050 [==============================] - 0s 273us/sample - loss: 0.5200 - accuracy: 0.8019 - val_loss: 0.6533 - val_accuracy: 0.7467\n",
      "Epoch 424/600\n",
      "1050/1050 [==============================] - 0s 211us/sample - loss: 0.5178 - accuracy: 0.8048 - val_loss: 0.6545 - val_accuracy: 0.7489\n",
      "Epoch 425/600\n",
      "1050/1050 [==============================] - 0s 297us/sample - loss: 0.5173 - accuracy: 0.8038 - val_loss: 0.6480 - val_accuracy: 0.7533\n",
      "Epoch 426/600\n",
      "1050/1050 [==============================] - 0s 195us/sample - loss: 0.5165 - accuracy: 0.8048 - val_loss: 0.6591 - val_accuracy: 0.7556\n",
      "Epoch 427/600\n",
      "1050/1050 [==============================] - 0s 235us/sample - loss: 0.5164 - accuracy: 0.8048 - val_loss: 0.6520 - val_accuracy: 0.7467\n",
      "Epoch 428/600\n",
      "1050/1050 [==============================] - 0s 236us/sample - loss: 0.5172 - accuracy: 0.8048 - val_loss: 0.6519 - val_accuracy: 0.7444\n",
      "Epoch 429/600\n",
      "1050/1050 [==============================] - 0s 289us/sample - loss: 0.5160 - accuracy: 0.8019 - val_loss: 0.6479 - val_accuracy: 0.7511\n",
      "Epoch 430/600\n",
      "1050/1050 [==============================] - 0s 241us/sample - loss: 0.5160 - accuracy: 0.8038 - val_loss: 0.6529 - val_accuracy: 0.7444\n",
      "Epoch 431/600\n",
      "1050/1050 [==============================] - 0s 242us/sample - loss: 0.5178 - accuracy: 0.8038 - val_loss: 0.6507 - val_accuracy: 0.7533\n",
      "Epoch 432/600\n",
      "1050/1050 [==============================] - 0s 276us/sample - loss: 0.5176 - accuracy: 0.8019 - val_loss: 0.6513 - val_accuracy: 0.7556\n",
      "Epoch 433/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 0s 267us/sample - loss: 0.5160 - accuracy: 0.8038 - val_loss: 0.6524 - val_accuracy: 0.7444\n",
      "Epoch 434/600\n",
      "1050/1050 [==============================] - 0s 273us/sample - loss: 0.5183 - accuracy: 0.8019 - val_loss: 0.6515 - val_accuracy: 0.7644\n",
      "Epoch 435/600\n",
      "1050/1050 [==============================] - 0s 232us/sample - loss: 0.5173 - accuracy: 0.8019 - val_loss: 0.6538 - val_accuracy: 0.7378\n",
      "Epoch 436/600\n",
      "1050/1050 [==============================] - 0s 236us/sample - loss: 0.5236 - accuracy: 0.7933 - val_loss: 0.6483 - val_accuracy: 0.7556\n",
      "Epoch 437/600\n",
      "1050/1050 [==============================] - 0s 265us/sample - loss: 0.5211 - accuracy: 0.7981 - val_loss: 0.6529 - val_accuracy: 0.7444\n",
      "Epoch 438/600\n",
      "1050/1050 [==============================] - 0s 294us/sample - loss: 0.5206 - accuracy: 0.7990 - val_loss: 0.6504 - val_accuracy: 0.7556\n",
      "Epoch 439/600\n",
      "1050/1050 [==============================] - 0s 256us/sample - loss: 0.5172 - accuracy: 0.8000 - val_loss: 0.6531 - val_accuracy: 0.7511\n",
      "Epoch 440/600\n",
      "1050/1050 [==============================] - 0s 291us/sample - loss: 0.5172 - accuracy: 0.8048 - val_loss: 0.6489 - val_accuracy: 0.7467\n",
      "Epoch 441/600\n",
      "1050/1050 [==============================] - 0s 275us/sample - loss: 0.5180 - accuracy: 0.8000 - val_loss: 0.6530 - val_accuracy: 0.7533\n",
      "Epoch 442/600\n",
      "1050/1050 [==============================] - 0s 233us/sample - loss: 0.5142 - accuracy: 0.8048 - val_loss: 0.6503 - val_accuracy: 0.7422\n",
      "Epoch 443/600\n",
      "1050/1050 [==============================] - 0s 267us/sample - loss: 0.5161 - accuracy: 0.8057 - val_loss: 0.6510 - val_accuracy: 0.7556\n",
      "Epoch 444/600\n",
      "1050/1050 [==============================] - 0s 272us/sample - loss: 0.5166 - accuracy: 0.8076 - val_loss: 0.6481 - val_accuracy: 0.7400\n",
      "Epoch 445/600\n",
      "1050/1050 [==============================] - 0s 315us/sample - loss: 0.5166 - accuracy: 0.8019 - val_loss: 0.6523 - val_accuracy: 0.7533\n",
      "Epoch 446/600\n",
      "1050/1050 [==============================] - 0s 325us/sample - loss: 0.5160 - accuracy: 0.8029 - val_loss: 0.6505 - val_accuracy: 0.7422\n",
      "Epoch 447/600\n",
      "1050/1050 [==============================] - 0s 231us/sample - loss: 0.5169 - accuracy: 0.8010 - val_loss: 0.6494 - val_accuracy: 0.7489\n",
      "Epoch 448/600\n",
      "1050/1050 [==============================] - 0s 279us/sample - loss: 0.5164 - accuracy: 0.8067 - val_loss: 0.6545 - val_accuracy: 0.7511\n",
      "Epoch 449/600\n",
      "1050/1050 [==============================] - 0s 236us/sample - loss: 0.5180 - accuracy: 0.8029 - val_loss: 0.6478 - val_accuracy: 0.7533\n",
      "Epoch 450/600\n",
      "1050/1050 [==============================] - 0s 288us/sample - loss: 0.5153 - accuracy: 0.8038 - val_loss: 0.6508 - val_accuracy: 0.7489\n",
      "Epoch 451/600\n",
      "1050/1050 [==============================] - 0s 370us/sample - loss: 0.5169 - accuracy: 0.8029 - val_loss: 0.6502 - val_accuracy: 0.7467\n",
      "Epoch 452/600\n",
      "1050/1050 [==============================] - 0s 329us/sample - loss: 0.5160 - accuracy: 0.8019 - val_loss: 0.6481 - val_accuracy: 0.7578\n",
      "Epoch 453/600\n",
      "1050/1050 [==============================] - 0s 255us/sample - loss: 0.5151 - accuracy: 0.8038 - val_loss: 0.6530 - val_accuracy: 0.7400\n",
      "Epoch 454/600\n",
      "1050/1050 [==============================] - 0s 272us/sample - loss: 0.5167 - accuracy: 0.7971 - val_loss: 0.6499 - val_accuracy: 0.7533\n",
      "Epoch 455/600\n",
      "1050/1050 [==============================] - 0s 217us/sample - loss: 0.5171 - accuracy: 0.8029 - val_loss: 0.6510 - val_accuracy: 0.7400\n",
      "Epoch 456/600\n",
      "1050/1050 [==============================] - 0s 245us/sample - loss: 0.5141 - accuracy: 0.8029 - val_loss: 0.6468 - val_accuracy: 0.7533\n",
      "Epoch 457/600\n",
      "1050/1050 [==============================] - 0s 232us/sample - loss: 0.5165 - accuracy: 0.8048 - val_loss: 0.6513 - val_accuracy: 0.7556\n",
      "Epoch 458/600\n",
      "1050/1050 [==============================] - 0s 219us/sample - loss: 0.5155 - accuracy: 0.8038 - val_loss: 0.6485 - val_accuracy: 0.7489\n",
      "Epoch 459/600\n",
      "1050/1050 [==============================] - 0s 272us/sample - loss: 0.5191 - accuracy: 0.8019 - val_loss: 0.6490 - val_accuracy: 0.7489\n",
      "Epoch 460/600\n",
      "1050/1050 [==============================] - 0s 238us/sample - loss: 0.5154 - accuracy: 0.8067 - val_loss: 0.6487 - val_accuracy: 0.7467\n",
      "Epoch 461/600\n",
      "1050/1050 [==============================] - 0s 339us/sample - loss: 0.5172 - accuracy: 0.8029 - val_loss: 0.6484 - val_accuracy: 0.7600\n",
      "Epoch 462/600\n",
      "1050/1050 [==============================] - 0s 239us/sample - loss: 0.5146 - accuracy: 0.8029 - val_loss: 0.6522 - val_accuracy: 0.7467\n",
      "Epoch 463/600\n",
      "1050/1050 [==============================] - 0s 264us/sample - loss: 0.5160 - accuracy: 0.8019 - val_loss: 0.6473 - val_accuracy: 0.7489\n",
      "Epoch 464/600\n",
      "1050/1050 [==============================] - 0s 280us/sample - loss: 0.5166 - accuracy: 0.8038 - val_loss: 0.6496 - val_accuracy: 0.7533\n",
      "Epoch 465/600\n",
      "1050/1050 [==============================] - 0s 236us/sample - loss: 0.5154 - accuracy: 0.8029 - val_loss: 0.6551 - val_accuracy: 0.7444\n",
      "Epoch 466/600\n",
      "1050/1050 [==============================] - 0s 215us/sample - loss: 0.5151 - accuracy: 0.8000 - val_loss: 0.6459 - val_accuracy: 0.7556\n",
      "Epoch 467/600\n",
      "1050/1050 [==============================] - 0s 195us/sample - loss: 0.5159 - accuracy: 0.8019 - val_loss: 0.6500 - val_accuracy: 0.7533\n",
      "Epoch 468/600\n",
      "1050/1050 [==============================] - 0s 270us/sample - loss: 0.5163 - accuracy: 0.8010 - val_loss: 0.6452 - val_accuracy: 0.7600\n",
      "Epoch 469/600\n",
      "1050/1050 [==============================] - 0s 332us/sample - loss: 0.5152 - accuracy: 0.8029 - val_loss: 0.6495 - val_accuracy: 0.7444\n",
      "Epoch 470/600\n",
      "1050/1050 [==============================] - 0s 290us/sample - loss: 0.5149 - accuracy: 0.8057 - val_loss: 0.6458 - val_accuracy: 0.7533\n",
      "Epoch 471/600\n",
      "1050/1050 [==============================] - 0s 219us/sample - loss: 0.5158 - accuracy: 0.8057 - val_loss: 0.6483 - val_accuracy: 0.7444\n",
      "Epoch 472/600\n",
      "1050/1050 [==============================] - 0s 351us/sample - loss: 0.5167 - accuracy: 0.8000 - val_loss: 0.6467 - val_accuracy: 0.7511\n",
      "Epoch 473/600\n",
      "1050/1050 [==============================] - 0s 394us/sample - loss: 0.5165 - accuracy: 0.8048 - val_loss: 0.6451 - val_accuracy: 0.7511\n",
      "Epoch 474/600\n",
      "1050/1050 [==============================] - 0s 246us/sample - loss: 0.5143 - accuracy: 0.8019 - val_loss: 0.6503 - val_accuracy: 0.7467\n",
      "Epoch 475/600\n",
      "1050/1050 [==============================] - 0s 346us/sample - loss: 0.5171 - accuracy: 0.8048 - val_loss: 0.6495 - val_accuracy: 0.7511\n",
      "Epoch 476/600\n",
      "1050/1050 [==============================] - 0s 377us/sample - loss: 0.5154 - accuracy: 0.8019 - val_loss: 0.6428 - val_accuracy: 0.7489\n",
      "Epoch 477/600\n",
      "1050/1050 [==============================] - 0s 295us/sample - loss: 0.5176 - accuracy: 0.8019 - val_loss: 0.6509 - val_accuracy: 0.7489\n",
      "Epoch 478/600\n",
      "1050/1050 [==============================] - 0s 368us/sample - loss: 0.5183 - accuracy: 0.7962 - val_loss: 0.6424 - val_accuracy: 0.7511\n",
      "Epoch 479/600\n",
      "1050/1050 [==============================] - 0s 281us/sample - loss: 0.5157 - accuracy: 0.8000 - val_loss: 0.6483 - val_accuracy: 0.7489\n",
      "Epoch 480/600\n",
      "1050/1050 [==============================] - 0s 234us/sample - loss: 0.5185 - accuracy: 0.8010 - val_loss: 0.6480 - val_accuracy: 0.7467\n",
      "Epoch 481/600\n",
      "1050/1050 [==============================] - 0s 279us/sample - loss: 0.5158 - accuracy: 0.7981 - val_loss: 0.6431 - val_accuracy: 0.7578\n",
      "Epoch 482/600\n",
      "1050/1050 [==============================] - 0s 293us/sample - loss: 0.5140 - accuracy: 0.8019 - val_loss: 0.6450 - val_accuracy: 0.7533\n",
      "Epoch 483/600\n",
      "1050/1050 [==============================] - 0s 363us/sample - loss: 0.5150 - accuracy: 0.8038 - val_loss: 0.6455 - val_accuracy: 0.7600\n",
      "Epoch 484/600\n",
      "1050/1050 [==============================] - 0s 286us/sample - loss: 0.5176 - accuracy: 0.8029 - val_loss: 0.6494 - val_accuracy: 0.7422\n",
      "Epoch 485/600\n",
      "1050/1050 [==============================] - 0s 231us/sample - loss: 0.5155 - accuracy: 0.8057 - val_loss: 0.6489 - val_accuracy: 0.7533\n",
      "Epoch 486/600\n",
      "1050/1050 [==============================] - 0s 236us/sample - loss: 0.5148 - accuracy: 0.8048 - val_loss: 0.6448 - val_accuracy: 0.7467\n",
      "Epoch 487/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 0s 300us/sample - loss: 0.5144 - accuracy: 0.8019 - val_loss: 0.6471 - val_accuracy: 0.7511\n",
      "Epoch 488/600\n",
      "1050/1050 [==============================] - 0s 275us/sample - loss: 0.5152 - accuracy: 0.8019 - val_loss: 0.6418 - val_accuracy: 0.7556\n",
      "Epoch 489/600\n",
      "1050/1050 [==============================] - 0s 345us/sample - loss: 0.5157 - accuracy: 0.8010 - val_loss: 0.6480 - val_accuracy: 0.7533\n",
      "Epoch 490/600\n",
      "1050/1050 [==============================] - 0s 320us/sample - loss: 0.5168 - accuracy: 0.8048 - val_loss: 0.6413 - val_accuracy: 0.7644\n",
      "Epoch 491/600\n",
      "1050/1050 [==============================] - 0s 281us/sample - loss: 0.5152 - accuracy: 0.8029 - val_loss: 0.6422 - val_accuracy: 0.7556\n",
      "Epoch 492/600\n",
      "1050/1050 [==============================] - 0s 329us/sample - loss: 0.5131 - accuracy: 0.8029 - val_loss: 0.6456 - val_accuracy: 0.7444\n",
      "Epoch 493/600\n",
      "1050/1050 [==============================] - 0s 303us/sample - loss: 0.5139 - accuracy: 0.8019 - val_loss: 0.6445 - val_accuracy: 0.7511\n",
      "Epoch 494/600\n",
      "1050/1050 [==============================] - 0s 282us/sample - loss: 0.5153 - accuracy: 0.8057 - val_loss: 0.6403 - val_accuracy: 0.7578\n",
      "Epoch 495/600\n",
      "1050/1050 [==============================] - 0s 273us/sample - loss: 0.5158 - accuracy: 0.8010 - val_loss: 0.6441 - val_accuracy: 0.7533\n",
      "Epoch 496/600\n",
      "1050/1050 [==============================] - 0s 317us/sample - loss: 0.5165 - accuracy: 0.7943 - val_loss: 0.6444 - val_accuracy: 0.7467\n",
      "Epoch 497/600\n",
      "1050/1050 [==============================] - 0s 251us/sample - loss: 0.5142 - accuracy: 0.8010 - val_loss: 0.6421 - val_accuracy: 0.7511\n",
      "Epoch 498/600\n",
      "1050/1050 [==============================] - 0s 231us/sample - loss: 0.5137 - accuracy: 0.8029 - val_loss: 0.6406 - val_accuracy: 0.7578\n",
      "Epoch 499/600\n",
      "1050/1050 [==============================] - 0s 281us/sample - loss: 0.5142 - accuracy: 0.8010 - val_loss: 0.6439 - val_accuracy: 0.7578\n",
      "Epoch 500/600\n",
      "1050/1050 [==============================] - 0s 265us/sample - loss: 0.5154 - accuracy: 0.8000 - val_loss: 0.6434 - val_accuracy: 0.7622\n",
      "Epoch 501/600\n",
      "1050/1050 [==============================] - 0s 286us/sample - loss: 0.5155 - accuracy: 0.7990 - val_loss: 0.6400 - val_accuracy: 0.7467\n",
      "Epoch 502/600\n",
      "1050/1050 [==============================] - 0s 317us/sample - loss: 0.5160 - accuracy: 0.7990 - val_loss: 0.6436 - val_accuracy: 0.7600\n",
      "Epoch 503/600\n",
      "1050/1050 [==============================] - 0s 238us/sample - loss: 0.5142 - accuracy: 0.8010 - val_loss: 0.6419 - val_accuracy: 0.7511\n",
      "Epoch 504/600\n",
      "1050/1050 [==============================] - 0s 230us/sample - loss: 0.5146 - accuracy: 0.8000 - val_loss: 0.6411 - val_accuracy: 0.7578\n",
      "Epoch 505/600\n",
      "1050/1050 [==============================] - 0s 207us/sample - loss: 0.5170 - accuracy: 0.8029 - val_loss: 0.6434 - val_accuracy: 0.7467\n",
      "Epoch 506/600\n",
      "1050/1050 [==============================] - 0s 262us/sample - loss: 0.5132 - accuracy: 0.8048 - val_loss: 0.6437 - val_accuracy: 0.7489\n",
      "Epoch 507/600\n",
      "1050/1050 [==============================] - 0s 286us/sample - loss: 0.5132 - accuracy: 0.8029 - val_loss: 0.6405 - val_accuracy: 0.7489\n",
      "Epoch 508/600\n",
      "1050/1050 [==============================] - 0s 233us/sample - loss: 0.5153 - accuracy: 0.8057 - val_loss: 0.6377 - val_accuracy: 0.7622\n",
      "Epoch 509/600\n",
      "1050/1050 [==============================] - 0s 258us/sample - loss: 0.5160 - accuracy: 0.8038 - val_loss: 0.6434 - val_accuracy: 0.7556\n",
      "Epoch 510/600\n",
      "1050/1050 [==============================] - 0s 316us/sample - loss: 0.5124 - accuracy: 0.8029 - val_loss: 0.6439 - val_accuracy: 0.7578\n",
      "Epoch 511/600\n",
      "1050/1050 [==============================] - 0s 347us/sample - loss: 0.5133 - accuracy: 0.8048 - val_loss: 0.6398 - val_accuracy: 0.7578\n",
      "Epoch 512/600\n",
      "1050/1050 [==============================] - 0s 269us/sample - loss: 0.5141 - accuracy: 0.8010 - val_loss: 0.6424 - val_accuracy: 0.7600\n",
      "Epoch 513/600\n",
      "1050/1050 [==============================] - 0s 238us/sample - loss: 0.5140 - accuracy: 0.8057 - val_loss: 0.6388 - val_accuracy: 0.7556\n",
      "Epoch 514/600\n",
      "1050/1050 [==============================] - 0s 276us/sample - loss: 0.5143 - accuracy: 0.8019 - val_loss: 0.6427 - val_accuracy: 0.7489\n",
      "Epoch 515/600\n",
      "1050/1050 [==============================] - 0s 257us/sample - loss: 0.5117 - accuracy: 0.8057 - val_loss: 0.6423 - val_accuracy: 0.7622\n",
      "Epoch 516/600\n",
      "1050/1050 [==============================] - 0s 241us/sample - loss: 0.5143 - accuracy: 0.8057 - val_loss: 0.6401 - val_accuracy: 0.7578\n",
      "Epoch 517/600\n",
      "1050/1050 [==============================] - 0s 235us/sample - loss: 0.5130 - accuracy: 0.8057 - val_loss: 0.6359 - val_accuracy: 0.7556\n",
      "Epoch 518/600\n",
      "1050/1050 [==============================] - 0s 291us/sample - loss: 0.5130 - accuracy: 0.7962 - val_loss: 0.6448 - val_accuracy: 0.7489\n",
      "Epoch 519/600\n",
      "1050/1050 [==============================] - 0s 236us/sample - loss: 0.5143 - accuracy: 0.8029 - val_loss: 0.6360 - val_accuracy: 0.7622\n",
      "Epoch 520/600\n",
      "1050/1050 [==============================] - 0s 249us/sample - loss: 0.5139 - accuracy: 0.7952 - val_loss: 0.6441 - val_accuracy: 0.7489\n",
      "Epoch 521/600\n",
      "1050/1050 [==============================] - 0s 228us/sample - loss: 0.5139 - accuracy: 0.8000 - val_loss: 0.6420 - val_accuracy: 0.7578\n",
      "Epoch 522/600\n",
      "1050/1050 [==============================] - 0s 208us/sample - loss: 0.5123 - accuracy: 0.8057 - val_loss: 0.6351 - val_accuracy: 0.7578\n",
      "Epoch 523/600\n",
      "1050/1050 [==============================] - 0s 368us/sample - loss: 0.5132 - accuracy: 0.8086 - val_loss: 0.6395 - val_accuracy: 0.7600\n",
      "Epoch 524/600\n",
      "1050/1050 [==============================] - 0s 270us/sample - loss: 0.5125 - accuracy: 0.8010 - val_loss: 0.6370 - val_accuracy: 0.7511\n",
      "Epoch 525/600\n",
      "1050/1050 [==============================] - 0s 220us/sample - loss: 0.5120 - accuracy: 0.8038 - val_loss: 0.6393 - val_accuracy: 0.7622\n",
      "Epoch 526/600\n",
      "1050/1050 [==============================] - 0s 215us/sample - loss: 0.5145 - accuracy: 0.8086 - val_loss: 0.6438 - val_accuracy: 0.7578\n",
      "Epoch 527/600\n",
      "1050/1050 [==============================] - 0s 256us/sample - loss: 0.5121 - accuracy: 0.8019 - val_loss: 0.6405 - val_accuracy: 0.7444\n",
      "Epoch 528/600\n",
      "1050/1050 [==============================] - 0s 280us/sample - loss: 0.5141 - accuracy: 0.8019 - val_loss: 0.6428 - val_accuracy: 0.7533\n",
      "Epoch 529/600\n",
      "1050/1050 [==============================] - 0s 312us/sample - loss: 0.5135 - accuracy: 0.8086 - val_loss: 0.6394 - val_accuracy: 0.7622\n",
      "Epoch 530/600\n",
      "1050/1050 [==============================] - 0s 283us/sample - loss: 0.5113 - accuracy: 0.8105 - val_loss: 0.6389 - val_accuracy: 0.7578\n",
      "Epoch 531/600\n",
      "1050/1050 [==============================] - 0s 215us/sample - loss: 0.5129 - accuracy: 0.8029 - val_loss: 0.6397 - val_accuracy: 0.7533\n",
      "Epoch 532/600\n",
      "1050/1050 [==============================] - 0s 223us/sample - loss: 0.5133 - accuracy: 0.8010 - val_loss: 0.6417 - val_accuracy: 0.7667\n",
      "Epoch 533/600\n",
      "1050/1050 [==============================] - 0s 318us/sample - loss: 0.5150 - accuracy: 0.8067 - val_loss: 0.6376 - val_accuracy: 0.7489\n",
      "Epoch 534/600\n",
      "1050/1050 [==============================] - 0s 215us/sample - loss: 0.5145 - accuracy: 0.8048 - val_loss: 0.6381 - val_accuracy: 0.7644\n",
      "Epoch 535/600\n",
      "1050/1050 [==============================] - 0s 247us/sample - loss: 0.5136 - accuracy: 0.8019 - val_loss: 0.6405 - val_accuracy: 0.7533\n",
      "Epoch 536/600\n",
      "1050/1050 [==============================] - 0s 223us/sample - loss: 0.5164 - accuracy: 0.8010 - val_loss: 0.6351 - val_accuracy: 0.7667\n",
      "Epoch 537/600\n",
      "1050/1050 [==============================] - 0s 232us/sample - loss: 0.5119 - accuracy: 0.8057 - val_loss: 0.6403 - val_accuracy: 0.7489\n",
      "Epoch 538/600\n",
      "1050/1050 [==============================] - 0s 272us/sample - loss: 0.5116 - accuracy: 0.8057 - val_loss: 0.6380 - val_accuracy: 0.7600\n",
      "Epoch 539/600\n",
      "1050/1050 [==============================] - 0s 300us/sample - loss: 0.5131 - accuracy: 0.8067 - val_loss: 0.6367 - val_accuracy: 0.7533\n",
      "Epoch 540/600\n",
      "1050/1050 [==============================] - 0s 236us/sample - loss: 0.5129 - accuracy: 0.8057 - val_loss: 0.6419 - val_accuracy: 0.7622\n",
      "Epoch 541/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 0s 243us/sample - loss: 0.5112 - accuracy: 0.8029 - val_loss: 0.6348 - val_accuracy: 0.7600\n",
      "Epoch 542/600\n",
      "1050/1050 [==============================] - 0s 236us/sample - loss: 0.5128 - accuracy: 0.8038 - val_loss: 0.6391 - val_accuracy: 0.7600\n",
      "Epoch 543/600\n",
      "1050/1050 [==============================] - 0s 200us/sample - loss: 0.5121 - accuracy: 0.8019 - val_loss: 0.6350 - val_accuracy: 0.7622\n",
      "Epoch 544/600\n",
      "1050/1050 [==============================] - 0s 261us/sample - loss: 0.5147 - accuracy: 0.8076 - val_loss: 0.6397 - val_accuracy: 0.7644\n",
      "Epoch 545/600\n",
      "1050/1050 [==============================] - 0s 296us/sample - loss: 0.5141 - accuracy: 0.8038 - val_loss: 0.6379 - val_accuracy: 0.7511\n",
      "Epoch 546/600\n",
      "1050/1050 [==============================] - 0s 231us/sample - loss: 0.5124 - accuracy: 0.8019 - val_loss: 0.6376 - val_accuracy: 0.7622\n",
      "Epoch 547/600\n",
      "1050/1050 [==============================] - 0s 253us/sample - loss: 0.5099 - accuracy: 0.8029 - val_loss: 0.6366 - val_accuracy: 0.7556\n",
      "Epoch 548/600\n",
      "1050/1050 [==============================] - 0s 312us/sample - loss: 0.5104 - accuracy: 0.8048 - val_loss: 0.6381 - val_accuracy: 0.7622\n",
      "Epoch 549/600\n",
      "1050/1050 [==============================] - 0s 269us/sample - loss: 0.5119 - accuracy: 0.8076 - val_loss: 0.6342 - val_accuracy: 0.7556\n",
      "Epoch 550/600\n",
      "1050/1050 [==============================] - 0s 317us/sample - loss: 0.5139 - accuracy: 0.8038 - val_loss: 0.6401 - val_accuracy: 0.7578\n",
      "Epoch 551/600\n",
      "1050/1050 [==============================] - 0s 293us/sample - loss: 0.5129 - accuracy: 0.8057 - val_loss: 0.6320 - val_accuracy: 0.7711\n",
      "Epoch 552/600\n",
      "1050/1050 [==============================] - 0s 262us/sample - loss: 0.5143 - accuracy: 0.8038 - val_loss: 0.6508 - val_accuracy: 0.7467\n",
      "Epoch 553/600\n",
      "1050/1050 [==============================] - 0s 220us/sample - loss: 0.5134 - accuracy: 0.8057 - val_loss: 0.6346 - val_accuracy: 0.7689\n",
      "Epoch 554/600\n",
      "1050/1050 [==============================] - 0s 272us/sample - loss: 0.5129 - accuracy: 0.8057 - val_loss: 0.6360 - val_accuracy: 0.7667\n",
      "Epoch 555/600\n",
      "1050/1050 [==============================] - 0s 252us/sample - loss: 0.5105 - accuracy: 0.8086 - val_loss: 0.6424 - val_accuracy: 0.7556\n",
      "Epoch 556/600\n",
      "1050/1050 [==============================] - 0s 293us/sample - loss: 0.5134 - accuracy: 0.8067 - val_loss: 0.6386 - val_accuracy: 0.7600\n",
      "Epoch 557/600\n",
      "1050/1050 [==============================] - 0s 291us/sample - loss: 0.5151 - accuracy: 0.8038 - val_loss: 0.6347 - val_accuracy: 0.7556\n",
      "Epoch 558/600\n",
      "1050/1050 [==============================] - 0s 268us/sample - loss: 0.5127 - accuracy: 0.8029 - val_loss: 0.6403 - val_accuracy: 0.7622\n",
      "Epoch 559/600\n",
      "1050/1050 [==============================] - 0s 241us/sample - loss: 0.5118 - accuracy: 0.8057 - val_loss: 0.6389 - val_accuracy: 0.7578\n",
      "Epoch 560/600\n",
      "1050/1050 [==============================] - 0s 296us/sample - loss: 0.5106 - accuracy: 0.8124 - val_loss: 0.6386 - val_accuracy: 0.7600\n",
      "Epoch 561/600\n",
      "1050/1050 [==============================] - 0s 279us/sample - loss: 0.5139 - accuracy: 0.8086 - val_loss: 0.6370 - val_accuracy: 0.7533\n",
      "Epoch 562/600\n",
      "1050/1050 [==============================] - 0s 262us/sample - loss: 0.5112 - accuracy: 0.8076 - val_loss: 0.6400 - val_accuracy: 0.7644\n",
      "Epoch 563/600\n",
      "1050/1050 [==============================] - 0s 302us/sample - loss: 0.5110 - accuracy: 0.8076 - val_loss: 0.6360 - val_accuracy: 0.7533\n",
      "Epoch 564/600\n",
      "1050/1050 [==============================] - 0s 288us/sample - loss: 0.5123 - accuracy: 0.7990 - val_loss: 0.6353 - val_accuracy: 0.7644\n",
      "Epoch 565/600\n",
      "1050/1050 [==============================] - 0s 271us/sample - loss: 0.5124 - accuracy: 0.7990 - val_loss: 0.6371 - val_accuracy: 0.7689\n",
      "Epoch 566/600\n",
      "1050/1050 [==============================] - 0s 246us/sample - loss: 0.5151 - accuracy: 0.8000 - val_loss: 0.6358 - val_accuracy: 0.7533\n",
      "Epoch 567/600\n",
      "1050/1050 [==============================] - 0s 279us/sample - loss: 0.5121 - accuracy: 0.8029 - val_loss: 0.6391 - val_accuracy: 0.7622\n",
      "Epoch 568/600\n",
      "1050/1050 [==============================] - 0s 293us/sample - loss: 0.5119 - accuracy: 0.8067 - val_loss: 0.6325 - val_accuracy: 0.7600\n",
      "Epoch 569/600\n",
      "1050/1050 [==============================] - 0s 249us/sample - loss: 0.5130 - accuracy: 0.8048 - val_loss: 0.6407 - val_accuracy: 0.7667\n",
      "Epoch 570/600\n",
      "1050/1050 [==============================] - 0s 275us/sample - loss: 0.5125 - accuracy: 0.8095 - val_loss: 0.6313 - val_accuracy: 0.7644\n",
      "Epoch 571/600\n",
      "1050/1050 [==============================] - 0s 210us/sample - loss: 0.5107 - accuracy: 0.8057 - val_loss: 0.6379 - val_accuracy: 0.7533\n",
      "Epoch 572/600\n",
      "1050/1050 [==============================] - 0s 288us/sample - loss: 0.5123 - accuracy: 0.8076 - val_loss: 0.6324 - val_accuracy: 0.7644\n",
      "Epoch 573/600\n",
      "1050/1050 [==============================] - 0s 292us/sample - loss: 0.5121 - accuracy: 0.8010 - val_loss: 0.6412 - val_accuracy: 0.7467\n",
      "Epoch 574/600\n",
      "1050/1050 [==============================] - 0s 353us/sample - loss: 0.5129 - accuracy: 0.8038 - val_loss: 0.6334 - val_accuracy: 0.7689\n",
      "Epoch 575/600\n",
      "1050/1050 [==============================] - 0s 308us/sample - loss: 0.5118 - accuracy: 0.8067 - val_loss: 0.6379 - val_accuracy: 0.7578\n",
      "Epoch 576/600\n",
      "1050/1050 [==============================] - 0s 332us/sample - loss: 0.5101 - accuracy: 0.8057 - val_loss: 0.6354 - val_accuracy: 0.7600\n",
      "Epoch 577/600\n",
      "1050/1050 [==============================] - 0s 347us/sample - loss: 0.5116 - accuracy: 0.8095 - val_loss: 0.6341 - val_accuracy: 0.7667\n",
      "Epoch 578/600\n",
      "1050/1050 [==============================] - 0s 273us/sample - loss: 0.5112 - accuracy: 0.8095 - val_loss: 0.6347 - val_accuracy: 0.7622\n",
      "Epoch 579/600\n",
      "1050/1050 [==============================] - 0s 266us/sample - loss: 0.5153 - accuracy: 0.8000 - val_loss: 0.6392 - val_accuracy: 0.7578\n",
      "Epoch 580/600\n",
      "1050/1050 [==============================] - 0s 333us/sample - loss: 0.5141 - accuracy: 0.8095 - val_loss: 0.6284 - val_accuracy: 0.7711\n",
      "Epoch 581/600\n",
      "1050/1050 [==============================] - 0s 212us/sample - loss: 0.5104 - accuracy: 0.8038 - val_loss: 0.6498 - val_accuracy: 0.7489\n",
      "Epoch 582/600\n",
      "1050/1050 [==============================] - 0s 277us/sample - loss: 0.5105 - accuracy: 0.8105 - val_loss: 0.6347 - val_accuracy: 0.7667\n",
      "Epoch 583/600\n",
      "1050/1050 [==============================] - 0s 279us/sample - loss: 0.5120 - accuracy: 0.8019 - val_loss: 0.6418 - val_accuracy: 0.7533\n",
      "Epoch 584/600\n",
      "1050/1050 [==============================] - 0s 281us/sample - loss: 0.5096 - accuracy: 0.8086 - val_loss: 0.6303 - val_accuracy: 0.7644\n",
      "Epoch 585/600\n",
      "1050/1050 [==============================] - 0s 248us/sample - loss: 0.5120 - accuracy: 0.8057 - val_loss: 0.6363 - val_accuracy: 0.7600\n",
      "Epoch 586/600\n",
      "1050/1050 [==============================] - 0s 251us/sample - loss: 0.5095 - accuracy: 0.8086 - val_loss: 0.6369 - val_accuracy: 0.7644\n",
      "Epoch 587/600\n",
      "1050/1050 [==============================] - 0s 266us/sample - loss: 0.5106 - accuracy: 0.8105 - val_loss: 0.6369 - val_accuracy: 0.7644\n",
      "Epoch 588/600\n",
      "1050/1050 [==============================] - 0s 241us/sample - loss: 0.5089 - accuracy: 0.8095 - val_loss: 0.6381 - val_accuracy: 0.7578\n",
      "Epoch 589/600\n",
      "1050/1050 [==============================] - 0s 359us/sample - loss: 0.5103 - accuracy: 0.8048 - val_loss: 0.6380 - val_accuracy: 0.7622\n",
      "Epoch 590/600\n",
      "1050/1050 [==============================] - 0s 226us/sample - loss: 0.5104 - accuracy: 0.8076 - val_loss: 0.6338 - val_accuracy: 0.7600\n",
      "Epoch 591/600\n",
      "1050/1050 [==============================] - 0s 240us/sample - loss: 0.5136 - accuracy: 0.8000 - val_loss: 0.6360 - val_accuracy: 0.7622\n",
      "Epoch 592/600\n",
      "1050/1050 [==============================] - 0s 297us/sample - loss: 0.5151 - accuracy: 0.8076 - val_loss: 0.6402 - val_accuracy: 0.7622\n",
      "Epoch 593/600\n",
      "1050/1050 [==============================] - 0s 288us/sample - loss: 0.5117 - accuracy: 0.8067 - val_loss: 0.6373 - val_accuracy: 0.7533\n",
      "Epoch 594/600\n",
      "1050/1050 [==============================] - 0s 252us/sample - loss: 0.5118 - accuracy: 0.8010 - val_loss: 0.6379 - val_accuracy: 0.7644\n",
      "Epoch 595/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 0s 278us/sample - loss: 0.5137 - accuracy: 0.8057 - val_loss: 0.6384 - val_accuracy: 0.7600\n",
      "Epoch 596/600\n",
      "1050/1050 [==============================] - 0s 192us/sample - loss: 0.5097 - accuracy: 0.8067 - val_loss: 0.6368 - val_accuracy: 0.7556\n",
      "Epoch 597/600\n",
      "1050/1050 [==============================] - 0s 254us/sample - loss: 0.5094 - accuracy: 0.8086 - val_loss: 0.6342 - val_accuracy: 0.7756\n",
      "Epoch 598/600\n",
      "1050/1050 [==============================] - 0s 255us/sample - loss: 0.5098 - accuracy: 0.8057 - val_loss: 0.6402 - val_accuracy: 0.7644\n",
      "Epoch 599/600\n",
      "1050/1050 [==============================] - 0s 215us/sample - loss: 0.5108 - accuracy: 0.8057 - val_loss: 0.6323 - val_accuracy: 0.7711\n",
      "Epoch 600/600\n",
      "1050/1050 [==============================] - 0s 209us/sample - loss: 0.5114 - accuracy: 0.8048 - val_loss: 0.6423 - val_accuracy: 0.7511\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.659456</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>1.617948</td>\n",
       "      <td>0.311111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.574141</td>\n",
       "      <td>0.343810</td>\n",
       "      <td>1.552468</td>\n",
       "      <td>0.362222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.517697</td>\n",
       "      <td>0.407619</td>\n",
       "      <td>1.501152</td>\n",
       "      <td>0.415556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.459614</td>\n",
       "      <td>0.458095</td>\n",
       "      <td>1.444891</td>\n",
       "      <td>0.437778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.386524</td>\n",
       "      <td>0.496190</td>\n",
       "      <td>1.361843</td>\n",
       "      <td>0.491111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>0.509663</td>\n",
       "      <td>0.806667</td>\n",
       "      <td>0.636793</td>\n",
       "      <td>0.755556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>0.509438</td>\n",
       "      <td>0.808571</td>\n",
       "      <td>0.634155</td>\n",
       "      <td>0.775556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>0.509794</td>\n",
       "      <td>0.805714</td>\n",
       "      <td>0.640250</td>\n",
       "      <td>0.764444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>0.510807</td>\n",
       "      <td>0.805714</td>\n",
       "      <td>0.632274</td>\n",
       "      <td>0.771111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>0.511404</td>\n",
       "      <td>0.804762</td>\n",
       "      <td>0.642331</td>\n",
       "      <td>0.751111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy\n",
       "0    1.659456  0.280000  1.617948      0.311111\n",
       "1    1.574141  0.343810  1.552468      0.362222\n",
       "2    1.517697  0.407619  1.501152      0.415556\n",
       "3    1.459614  0.458095  1.444891      0.437778\n",
       "4    1.386524  0.496190  1.361843      0.491111\n",
       "..        ...       ...       ...           ...\n",
       "595  0.509663  0.806667  0.636793      0.755556\n",
       "596  0.509438  0.808571  0.634155      0.775556\n",
       "597  0.509794  0.805714  0.640250      0.764444\n",
       "598  0.510807  0.805714  0.632274      0.771111\n",
       "599  0.511404  0.804762  0.642331      0.751111\n",
       "\n",
       "[600 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.003\n",
    "epochs = 600\n",
    "batch_size = round(train_df.shape[0] * 0.05)\n",
    "validation_split = 0.2\n",
    "\n",
    "# Establish the model's topography.\n",
    "my_model = create_model(learning_rate, feature_layer)\n",
    "\n",
    "x_train = train_set\n",
    "y_train = train_set[\"type_label_encoded\"]\n",
    "x_val = val_set\n",
    "y_val = val_set[\"type_label_encoded\"]\n",
    "\n",
    "epochs, hist = train_model(my_model, x_train, y_train, x_val, y_val, \n",
    "                           epochs, batch_size)\n",
    "\n",
    "# Plot a graph of the metric vs. Sparse Categorical Crossentropy\n",
    "display(hist)\n",
    "plot_the_scc_curve(epochs, hist[\"loss\"], hist[\"accuracy\"], hist[\"val_accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test The Model Using Test Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./dataset/alien_test/rain_1.jpg</td>\n",
       "      <td>rainy</td>\n",
       "      <td>rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./dataset/alien_test/shine_1.jpg</td>\n",
       "      <td>shine</td>\n",
       "      <td>shine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./dataset/alien_test/foggy_5.jpg</td>\n",
       "      <td>foggy</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./dataset/alien_test/Cloud_4.jpg</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>shine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./dataset/alien_test/foggy_7.jpg</td>\n",
       "      <td>foggy</td>\n",
       "      <td>sunrise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>./dataset/alien_test/sunrise_5.jpg</td>\n",
       "      <td>sunrise</td>\n",
       "      <td>sunrise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>./dataset/alien_test/foggy_3.jpg</td>\n",
       "      <td>foggy</td>\n",
       "      <td>sunrise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>./dataset/alien_test/shine_3.jpg</td>\n",
       "      <td>shine</td>\n",
       "      <td>shine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>./dataset/alien_test/foggy_10.jpg</td>\n",
       "      <td>foggy</td>\n",
       "      <td>foggy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>./dataset/alien_test/foggy_1.jpg</td>\n",
       "      <td>foggy</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>./dataset/alien_test/foggy_8.jpg</td>\n",
       "      <td>foggy</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>./dataset/alien_test/foggy_6.jpg</td>\n",
       "      <td>foggy</td>\n",
       "      <td>foggy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>./dataset/alien_test/rain_2.png</td>\n",
       "      <td>rainy</td>\n",
       "      <td>rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>./dataset/alien_test/sunrise_1.jpg</td>\n",
       "      <td>sunrise</td>\n",
       "      <td>sunrise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>./dataset/alien_test/Cloud_3.jpeg</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>shine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>./dataset/alien_test/sunrise_7.jpg</td>\n",
       "      <td>sunrise</td>\n",
       "      <td>sunrise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>./dataset/alien_test/foggy_4.jpg</td>\n",
       "      <td>foggy</td>\n",
       "      <td>foggy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>./dataset/alien_test/Cloud_1.png</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>./dataset/alien_test/sunrise_3.jpg</td>\n",
       "      <td>sunrise</td>\n",
       "      <td>sunrise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>./dataset/alien_test/rain_6.jpg</td>\n",
       "      <td>rainy</td>\n",
       "      <td>rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>./dataset/alien_test/rain_4.jpg</td>\n",
       "      <td>rainy</td>\n",
       "      <td>rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>./dataset/alien_test/sunrise_2.jpg</td>\n",
       "      <td>sunrise</td>\n",
       "      <td>sunrise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>./dataset/alien_test/Cloud_2.jpg</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>./dataset/alien_test/rain_5.jpg</td>\n",
       "      <td>rainy</td>\n",
       "      <td>rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>./dataset/alien_test/sunrise_4.jpg</td>\n",
       "      <td>sunrise</td>\n",
       "      <td>sunrise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>./dataset/alien_test/foggy_9.jpg</td>\n",
       "      <td>foggy</td>\n",
       "      <td>foggy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>./dataset/alien_test/sunrise_6.jpg</td>\n",
       "      <td>sunrise</td>\n",
       "      <td>sunrise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>./dataset/alien_test/foggy_2.jpg</td>\n",
       "      <td>foggy</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>./dataset/alien_test/shine_2.jpg</td>\n",
       "      <td>shine</td>\n",
       "      <td>shine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>./dataset/alien_test/rain_3.jpg</td>\n",
       "      <td>rainy</td>\n",
       "      <td>rainy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              img_path actual_label predicted_label\n",
       "0      ./dataset/alien_test/rain_1.jpg        rainy           rainy\n",
       "1     ./dataset/alien_test/shine_1.jpg        shine           shine\n",
       "2     ./dataset/alien_test/foggy_5.jpg        foggy          cloudy\n",
       "3     ./dataset/alien_test/Cloud_4.jpg       cloudy           shine\n",
       "4     ./dataset/alien_test/foggy_7.jpg        foggy         sunrise\n",
       "5   ./dataset/alien_test/sunrise_5.jpg      sunrise         sunrise\n",
       "6     ./dataset/alien_test/foggy_3.jpg        foggy         sunrise\n",
       "7     ./dataset/alien_test/shine_3.jpg        shine           shine\n",
       "8    ./dataset/alien_test/foggy_10.jpg        foggy           foggy\n",
       "9     ./dataset/alien_test/foggy_1.jpg        foggy          cloudy\n",
       "10    ./dataset/alien_test/foggy_8.jpg        foggy          cloudy\n",
       "11    ./dataset/alien_test/foggy_6.jpg        foggy           foggy\n",
       "12     ./dataset/alien_test/rain_2.png        rainy           rainy\n",
       "13  ./dataset/alien_test/sunrise_1.jpg      sunrise         sunrise\n",
       "14   ./dataset/alien_test/Cloud_3.jpeg       cloudy           shine\n",
       "15  ./dataset/alien_test/sunrise_7.jpg      sunrise         sunrise\n",
       "16    ./dataset/alien_test/foggy_4.jpg        foggy           foggy\n",
       "17    ./dataset/alien_test/Cloud_1.png       cloudy          cloudy\n",
       "18  ./dataset/alien_test/sunrise_3.jpg      sunrise         sunrise\n",
       "19     ./dataset/alien_test/rain_6.jpg        rainy           rainy\n",
       "20     ./dataset/alien_test/rain_4.jpg        rainy           rainy\n",
       "21  ./dataset/alien_test/sunrise_2.jpg      sunrise         sunrise\n",
       "22    ./dataset/alien_test/Cloud_2.jpg       cloudy          cloudy\n",
       "23     ./dataset/alien_test/rain_5.jpg        rainy           rainy\n",
       "24  ./dataset/alien_test/sunrise_4.jpg      sunrise         sunrise\n",
       "25    ./dataset/alien_test/foggy_9.jpg        foggy           foggy\n",
       "26  ./dataset/alien_test/sunrise_6.jpg      sunrise         sunrise\n",
       "27    ./dataset/alien_test/foggy_2.jpg        foggy          cloudy\n",
       "28    ./dataset/alien_test/shine_2.jpg        shine           shine\n",
       "29     ./dataset/alien_test/rain_3.jpg        rainy           rainy"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "test_df[\"type_label_encoded\"] = enc.transform(test_df[\"type_label\"].values)\n",
    "y_pred = predict(my_model, test_df)\n",
    "y_pred = [np.argmax(pred) for pred in y_pred]\n",
    "\n",
    "y_pred = enc.inverse_transform(y_pred)\n",
    "\n",
    "comparison = pd.DataFrame(columns = [\"img_path\", \"actual_label\", \"predicted_label\"])\n",
    "comparison[\"img_path\"] = test_df[\"img_path\"]\n",
    "comparison[\"actual_label\"] = test_df[\"type_label\"]\n",
    "comparison[\"predicted_label\"] = y_pred\n",
    "\n",
    "display(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report The Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4\n",
       "0  2  0  0  2  0\n",
       "1  4  4  0  0  2\n",
       "2  0  0  6  0  0\n",
       "3  0  0  0  3  0\n",
       "4  0  0  0  0  7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      cloudy       0.33      0.50      0.40         4\n",
      "       foggy       1.00      0.40      0.57        10\n",
      "       rainy       1.00      1.00      1.00         6\n",
      "       shine       0.60      1.00      0.75         3\n",
      "     sunrise       0.78      1.00      0.88         7\n",
      "\n",
      "    accuracy                           0.73        30\n",
      "   macro avg       0.74      0.78      0.72        30\n",
      "weighted avg       0.82      0.73      0.72        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "display(pd.DataFrame(confusion_matrix(test_df[\"type_label\"].values, y_pred)))\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_df[\"type_label\"].values, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
