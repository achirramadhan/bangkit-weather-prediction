{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Used Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported modules.\n"
     ]
    }
   ],
   "source": [
    "#@title Import relevant modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Imported modules.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_images_features.csv\")\n",
    "train_df = train_df.reindex(np.random.permutation(train_df.index)) # shuffle the examples\n",
    "test_df = pd.read_csv(\"test_images_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_path</th>\n",
       "      <th>avg_r</th>\n",
       "      <th>avg_g</th>\n",
       "      <th>avg_b</th>\n",
       "      <th>avg_s</th>\n",
       "      <th>contrast</th>\n",
       "      <th>ASM</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>type_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>236</td>\n",
       "      <td>./dataset/rainy/rain51.jpg</td>\n",
       "      <td>133.065645</td>\n",
       "      <td>133.383952</td>\n",
       "      <td>138.089039</td>\n",
       "      <td>0.093650</td>\n",
       "      <td>122.575392</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.200064</td>\n",
       "      <td>rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>219</td>\n",
       "      <td>./dataset/cloudy/cloudy253.jpg</td>\n",
       "      <td>155.695204</td>\n",
       "      <td>153.485312</td>\n",
       "      <td>151.244775</td>\n",
       "      <td>0.106825</td>\n",
       "      <td>201.977291</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.278524</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>219</td>\n",
       "      <td>./dataset/rainy/rain67.jpg</td>\n",
       "      <td>49.299053</td>\n",
       "      <td>74.302596</td>\n",
       "      <td>84.152962</td>\n",
       "      <td>0.452036</td>\n",
       "      <td>38.546264</td>\n",
       "      <td>0.000768</td>\n",
       "      <td>0.338270</td>\n",
       "      <td>rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>./dataset/cloudy/cloudy201.jpg</td>\n",
       "      <td>139.645288</td>\n",
       "      <td>143.419779</td>\n",
       "      <td>143.543101</td>\n",
       "      <td>0.161326</td>\n",
       "      <td>20.916097</td>\n",
       "      <td>0.002227</td>\n",
       "      <td>0.576406</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>./dataset/cloudy/cloudy43.jpg</td>\n",
       "      <td>88.556642</td>\n",
       "      <td>88.022958</td>\n",
       "      <td>95.898810</td>\n",
       "      <td>0.238895</td>\n",
       "      <td>53.622975</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.357476</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                        img_path       avg_r       avg_g       avg_b  \\\n",
       "836  236      ./dataset/rainy/rain51.jpg  133.065645  133.383952  138.089039   \n",
       "219  219  ./dataset/cloudy/cloudy253.jpg  155.695204  153.485312  151.244775   \n",
       "819  219      ./dataset/rainy/rain67.jpg   49.299053   74.302596   84.152962   \n",
       "10    10  ./dataset/cloudy/cloudy201.jpg  139.645288  143.419779  143.543101   \n",
       "64    64   ./dataset/cloudy/cloudy43.jpg   88.556642   88.022958   95.898810   \n",
       "\n",
       "        avg_s    contrast       ASM  homogeneity type_label  \n",
       "836  0.093650  122.575392  0.000211     0.200064      rainy  \n",
       "219  0.106825  201.977291  0.000465     0.278524     cloudy  \n",
       "819  0.452036   38.546264  0.000768     0.338270      rainy  \n",
       "10   0.161326   20.916097  0.002227     0.576406     cloudy  \n",
       "64   0.238895   53.622975  0.000856     0.357476     cloudy  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_path</th>\n",
       "      <th>avg_r</th>\n",
       "      <th>avg_g</th>\n",
       "      <th>avg_b</th>\n",
       "      <th>avg_s</th>\n",
       "      <th>contrast</th>\n",
       "      <th>ASM</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>type_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>./dataset/alien_test/rain_1.jpg</td>\n",
       "      <td>89.380456</td>\n",
       "      <td>108.331348</td>\n",
       "      <td>92.704043</td>\n",
       "      <td>0.340140</td>\n",
       "      <td>104.245269</td>\n",
       "      <td>0.001284</td>\n",
       "      <td>0.284216</td>\n",
       "      <td>rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>./dataset/alien_test/shine_1.jpg</td>\n",
       "      <td>84.179988</td>\n",
       "      <td>145.610668</td>\n",
       "      <td>202.758774</td>\n",
       "      <td>0.650524</td>\n",
       "      <td>25.325296</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.637173</td>\n",
       "      <td>shine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>./dataset/alien_test/foggy_5.jpg</td>\n",
       "      <td>111.901819</td>\n",
       "      <td>122.010252</td>\n",
       "      <td>123.489308</td>\n",
       "      <td>0.122873</td>\n",
       "      <td>11.677350</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.705304</td>\n",
       "      <td>foggy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>./dataset/alien_test/Cloud_4.jpg</td>\n",
       "      <td>88.340293</td>\n",
       "      <td>151.776627</td>\n",
       "      <td>193.868678</td>\n",
       "      <td>0.557622</td>\n",
       "      <td>17.755358</td>\n",
       "      <td>0.002650</td>\n",
       "      <td>0.506353</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>./dataset/alien_test/foggy_7.jpg</td>\n",
       "      <td>122.728178</td>\n",
       "      <td>73.513052</td>\n",
       "      <td>36.486659</td>\n",
       "      <td>0.714519</td>\n",
       "      <td>8.337532</td>\n",
       "      <td>0.003289</td>\n",
       "      <td>0.732819</td>\n",
       "      <td>foggy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                          img_path       avg_r       avg_g       avg_b  \\\n",
       "0   0   ./dataset/alien_test/rain_1.jpg   89.380456  108.331348   92.704043   \n",
       "1   1  ./dataset/alien_test/shine_1.jpg   84.179988  145.610668  202.758774   \n",
       "2   2  ./dataset/alien_test/foggy_5.jpg  111.901819  122.010252  123.489308   \n",
       "3   3  ./dataset/alien_test/Cloud_4.jpg   88.340293  151.776627  193.868678   \n",
       "4   4  ./dataset/alien_test/foggy_7.jpg  122.728178   73.513052   36.486659   \n",
       "\n",
       "      avg_s    contrast       ASM  homogeneity type_label  \n",
       "0  0.340140  104.245269  0.001284     0.284216      rainy  \n",
       "1  0.650524   25.325296  0.003029     0.637173      shine  \n",
       "2  0.122873   11.677350  0.002500     0.705304      foggy  \n",
       "3  0.557622   17.755358  0.002650     0.506353     cloudy  \n",
       "4  0.714519    8.337532  0.003289     0.732819      foggy  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_df.head())\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Numeric Values to Their Z-Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized the values.\n"
     ]
    }
   ],
   "source": [
    "#@title Convert raw values to their Z-scores \n",
    "\n",
    "numeric_columns = [\"avg_r\", \"avg_g\", \"avg_b\", \"contrast\", \"ASM\", \"homogeneity\"]\n",
    "\n",
    "for col in numeric_columns:\n",
    "    # Calculate the Z-scores of each column in the training set:\n",
    "    train_df_mean = train_df[col].mean()\n",
    "    train_df_std = train_df[col].std()\n",
    "    train_df[col] = (train_df[col] - train_df_mean)/train_df_std\n",
    "\n",
    "    # Calculate the Z-scores of each column in the test set.\n",
    "    test_df[col] = (test_df[col] - train_df_mean)/train_df_std\n",
    "\n",
    "print(\"Normalized the values.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_path</th>\n",
       "      <th>avg_r</th>\n",
       "      <th>avg_g</th>\n",
       "      <th>avg_b</th>\n",
       "      <th>avg_s</th>\n",
       "      <th>contrast</th>\n",
       "      <th>ASM</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>type_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>236</td>\n",
       "      <td>./dataset/rainy/rain51.jpg</td>\n",
       "      <td>0.410731</td>\n",
       "      <td>0.413857</td>\n",
       "      <td>0.432631</td>\n",
       "      <td>0.093650</td>\n",
       "      <td>0.037082</td>\n",
       "      <td>-0.267265</td>\n",
       "      <td>-1.391272</td>\n",
       "      <td>rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>219</td>\n",
       "      <td>./dataset/cloudy/cloudy253.jpg</td>\n",
       "      <td>1.061717</td>\n",
       "      <td>0.943858</td>\n",
       "      <td>0.685209</td>\n",
       "      <td>0.106825</td>\n",
       "      <td>0.442497</td>\n",
       "      <td>-0.252540</td>\n",
       "      <td>-0.979389</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>219</td>\n",
       "      <td>./dataset/rainy/rain67.jpg</td>\n",
       "      <td>-1.998985</td>\n",
       "      <td>-1.143907</td>\n",
       "      <td>-0.602893</td>\n",
       "      <td>0.452036</td>\n",
       "      <td>-0.391959</td>\n",
       "      <td>-0.234940</td>\n",
       "      <td>-0.665750</td>\n",
       "      <td>rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>./dataset/cloudy/cloudy201.jpg</td>\n",
       "      <td>0.600008</td>\n",
       "      <td>0.678466</td>\n",
       "      <td>0.537344</td>\n",
       "      <td>0.161326</td>\n",
       "      <td>-0.481976</td>\n",
       "      <td>-0.150335</td>\n",
       "      <td>0.584369</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>./dataset/cloudy/cloudy43.jpg</td>\n",
       "      <td>-0.869661</td>\n",
       "      <td>-0.782150</td>\n",
       "      <td>-0.377383</td>\n",
       "      <td>0.238895</td>\n",
       "      <td>-0.314980</td>\n",
       "      <td>-0.229821</td>\n",
       "      <td>-0.564923</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                        img_path     avg_r     avg_g     avg_b  \\\n",
       "836  236      ./dataset/rainy/rain51.jpg  0.410731  0.413857  0.432631   \n",
       "219  219  ./dataset/cloudy/cloudy253.jpg  1.061717  0.943858  0.685209   \n",
       "819  219      ./dataset/rainy/rain67.jpg -1.998985 -1.143907 -0.602893   \n",
       "10    10  ./dataset/cloudy/cloudy201.jpg  0.600008  0.678466  0.537344   \n",
       "64    64   ./dataset/cloudy/cloudy43.jpg -0.869661 -0.782150 -0.377383   \n",
       "\n",
       "        avg_s  contrast       ASM  homogeneity type_label  \n",
       "836  0.093650  0.037082 -0.267265    -1.391272      rainy  \n",
       "219  0.106825  0.442497 -0.252540    -0.979389     cloudy  \n",
       "819  0.452036 -0.391959 -0.234940    -0.665750      rainy  \n",
       "10   0.161326 -0.481976 -0.150335     0.584369     cloudy  \n",
       "64   0.238895 -0.314980 -0.229821    -0.564923     cloudy  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_path</th>\n",
       "      <th>avg_r</th>\n",
       "      <th>avg_g</th>\n",
       "      <th>avg_b</th>\n",
       "      <th>avg_s</th>\n",
       "      <th>contrast</th>\n",
       "      <th>ASM</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>type_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>./dataset/alien_test/rain_1.jpg</td>\n",
       "      <td>-0.845962</td>\n",
       "      <td>-0.246691</td>\n",
       "      <td>-0.438720</td>\n",
       "      <td>0.340140</td>\n",
       "      <td>-0.056509</td>\n",
       "      <td>-0.205015</td>\n",
       "      <td>-0.949509</td>\n",
       "      <td>rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>./dataset/alien_test/shine_1.jpg</td>\n",
       "      <td>-0.995564</td>\n",
       "      <td>0.736231</td>\n",
       "      <td>1.674231</td>\n",
       "      <td>0.650524</td>\n",
       "      <td>-0.459464</td>\n",
       "      <td>-0.103800</td>\n",
       "      <td>0.903370</td>\n",
       "      <td>shine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>./dataset/alien_test/foggy_5.jpg</td>\n",
       "      <td>-0.198089</td>\n",
       "      <td>0.113973</td>\n",
       "      <td>0.152329</td>\n",
       "      <td>0.122873</td>\n",
       "      <td>-0.529148</td>\n",
       "      <td>-0.134466</td>\n",
       "      <td>1.261028</td>\n",
       "      <td>foggy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>./dataset/alien_test/Cloud_4.jpg</td>\n",
       "      <td>-0.875884</td>\n",
       "      <td>0.898806</td>\n",
       "      <td>1.503549</td>\n",
       "      <td>0.557622</td>\n",
       "      <td>-0.498115</td>\n",
       "      <td>-0.125769</td>\n",
       "      <td>0.216616</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>./dataset/alien_test/foggy_7.jpg</td>\n",
       "      <td>0.113353</td>\n",
       "      <td>-1.164724</td>\n",
       "      <td>-1.518043</td>\n",
       "      <td>0.714519</td>\n",
       "      <td>-0.546201</td>\n",
       "      <td>-0.088691</td>\n",
       "      <td>1.405474</td>\n",
       "      <td>foggy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                          img_path     avg_r     avg_g     avg_b  \\\n",
       "0   0   ./dataset/alien_test/rain_1.jpg -0.845962 -0.246691 -0.438720   \n",
       "1   1  ./dataset/alien_test/shine_1.jpg -0.995564  0.736231  1.674231   \n",
       "2   2  ./dataset/alien_test/foggy_5.jpg -0.198089  0.113973  0.152329   \n",
       "3   3  ./dataset/alien_test/Cloud_4.jpg -0.875884  0.898806  1.503549   \n",
       "4   4  ./dataset/alien_test/foggy_7.jpg  0.113353 -1.164724 -1.518043   \n",
       "\n",
       "      avg_s  contrast       ASM  homogeneity type_label  \n",
       "0  0.340140 -0.056509 -0.205015    -0.949509      rainy  \n",
       "1  0.650524 -0.459464 -0.103800     0.903370      shine  \n",
       "2  0.122873 -0.529148 -0.134466     1.261028      foggy  \n",
       "3  0.557622 -0.498115 -0.125769     0.216616     cloudy  \n",
       "4  0.714519 -0.546201 -0.088691     1.405474      foggy  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_df.head())\n",
    "display(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Attribute Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>avg_r</th>\n",
       "      <th>avg_g</th>\n",
       "      <th>avg_b</th>\n",
       "      <th>avg_s</th>\n",
       "      <th>contrast</th>\n",
       "      <th>ASM</th>\n",
       "      <th>homogeneity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.010898</td>\n",
       "      <td>-0.114900</td>\n",
       "      <td>-0.137644</td>\n",
       "      <td>0.063076</td>\n",
       "      <td>-0.022180</td>\n",
       "      <td>0.025727</td>\n",
       "      <td>0.029405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_r</th>\n",
       "      <td>-0.010898</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.635598</td>\n",
       "      <td>0.270568</td>\n",
       "      <td>-0.050624</td>\n",
       "      <td>-0.049262</td>\n",
       "      <td>-0.069407</td>\n",
       "      <td>0.062067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_g</th>\n",
       "      <td>-0.114900</td>\n",
       "      <td>0.635598</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.874212</td>\n",
       "      <td>-0.324659</td>\n",
       "      <td>0.023166</td>\n",
       "      <td>-0.114200</td>\n",
       "      <td>-0.092685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_b</th>\n",
       "      <td>-0.137644</td>\n",
       "      <td>0.270568</td>\n",
       "      <td>0.874212</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.406487</td>\n",
       "      <td>0.024810</td>\n",
       "      <td>-0.099306</td>\n",
       "      <td>-0.097692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_s</th>\n",
       "      <td>0.063076</td>\n",
       "      <td>-0.050624</td>\n",
       "      <td>-0.324659</td>\n",
       "      <td>-0.406487</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.094517</td>\n",
       "      <td>-0.027932</td>\n",
       "      <td>0.148109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contrast</th>\n",
       "      <td>-0.022180</td>\n",
       "      <td>-0.049262</td>\n",
       "      <td>0.023166</td>\n",
       "      <td>0.024810</td>\n",
       "      <td>-0.094517</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.095333</td>\n",
       "      <td>-0.578588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ASM</th>\n",
       "      <td>0.025727</td>\n",
       "      <td>-0.069407</td>\n",
       "      <td>-0.114200</td>\n",
       "      <td>-0.099306</td>\n",
       "      <td>-0.027932</td>\n",
       "      <td>-0.095333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.305109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>homogeneity</th>\n",
       "      <td>0.029405</td>\n",
       "      <td>0.062067</td>\n",
       "      <td>-0.092685</td>\n",
       "      <td>-0.097692</td>\n",
       "      <td>0.148109</td>\n",
       "      <td>-0.578588</td>\n",
       "      <td>0.305109</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id     avg_r     avg_g     avg_b     avg_s  contrast  \\\n",
       "id           1.000000 -0.010898 -0.114900 -0.137644  0.063076 -0.022180   \n",
       "avg_r       -0.010898  1.000000  0.635598  0.270568 -0.050624 -0.049262   \n",
       "avg_g       -0.114900  0.635598  1.000000  0.874212 -0.324659  0.023166   \n",
       "avg_b       -0.137644  0.270568  0.874212  1.000000 -0.406487  0.024810   \n",
       "avg_s        0.063076 -0.050624 -0.324659 -0.406487  1.000000 -0.094517   \n",
       "contrast    -0.022180 -0.049262  0.023166  0.024810 -0.094517  1.000000   \n",
       "ASM          0.025727 -0.069407 -0.114200 -0.099306 -0.027932 -0.095333   \n",
       "homogeneity  0.029405  0.062067 -0.092685 -0.097692  0.148109 -0.578588   \n",
       "\n",
       "                  ASM  homogeneity  \n",
       "id           0.025727     0.029405  \n",
       "avg_r       -0.069407     0.062067  \n",
       "avg_g       -0.114200    -0.092685  \n",
       "avg_b       -0.099306    -0.097692  \n",
       "avg_s       -0.027932     0.148109  \n",
       "contrast    -0.095333    -0.578588  \n",
       "ASM          1.000000     0.305109  \n",
       "homogeneity  0.305109     1.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train_df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Feature Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_columns = [\"avg_r\", \"avg_g\", \"avg_b\", \"avg_s\", \"contrast\", \"ASM\", \"homogeneity\"]\n",
    "\n",
    "feature_columns = []\n",
    "for col in input_columns:\n",
    "    feature_columns.append(\n",
    "        tf.feature_column.numeric_column(col)\n",
    "    )\n",
    "    \n",
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Function to Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined the plot_the_loss_curve function.\n"
     ]
    }
   ],
   "source": [
    "#@title Define the plotting function.\n",
    "\n",
    "def plot_the_scc_curve(epochs, scc, acc, val_acc):\n",
    "    \"\"\"Plot a curve of SCC vs. epoch.\"\"\"\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Sparse Categorical Crossentropy\")\n",
    "\n",
    "    plt.plot(epochs, scc, label=\"loss\")\n",
    "    plt.legend()\n",
    "    plt.ylim([scc.min()*0.95, scc.max() * 1.03])\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "\n",
    "    plt.plot(epochs, acc, label=\"acc\")\n",
    "    plt.plot(epochs, val_acc, label=\"val acc\")\n",
    "    plt.legend()\n",
    "    plt.ylim([0, 1])\n",
    "    plt.show()  \n",
    "\n",
    "print(\"Defined the plot_the_loss_curve function.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Function to Create, Train, and Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined the create_model and train_model functions.\n"
     ]
    }
   ],
   "source": [
    "#@title Define functions to create and train a linear regression model\n",
    "def create_model(my_learning_rate, feature_layer):\n",
    "    \"\"\"Create and compile a multiclass classification neural network.\"\"\"\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Add the layer containing the feature columns to the model.\n",
    "    model.add(feature_layer)\n",
    "    \n",
    "    # Add hidden layer 1\n",
    "    model.add(tf.keras.layers.Dense(units=7, activation='relu'))\n",
    "    \n",
    "    # Add hidden layer 2\n",
    "    model.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
    "\n",
    "    # Classification layer\n",
    "    model.add(tf.keras.layers.Dense(units=5, activation='softmax'))\n",
    "\n",
    "    # Construct the layers into a model that TensorFlow can execute.\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(lr=my_learning_rate),\n",
    "                loss=\"sparse_categorical_crossentropy\",\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    return model           \n",
    "\n",
    "\n",
    "def train_model(model, x_train, y_train, x_val, y_val, epochs,\n",
    "                batch_size=None):\n",
    "    \"\"\"Train the model by feeding it data.\"\"\"\n",
    "\n",
    "    x_train = {name:np.array(value) for name, value in x_train.items()}\n",
    "    y_train = y_train.values\n",
    "    \n",
    "    x_val = {name:np.array(value) for name, value in x_val.items()}\n",
    "    y_val = y_val.values\n",
    "    \n",
    "    history = model.fit(x=x_train, y=y_train, batch_size=batch_size,\n",
    "                      epochs=epochs, shuffle=True,\n",
    "                       validation_data=(x_val, y_val))\n",
    "\n",
    "    # To track the progression of training, gather a snapshot\n",
    "    # of the model's metrics at each epoch. \n",
    "    epochs = history.epoch\n",
    "    hist = pd.DataFrame(history.history)\n",
    "\n",
    "    return epochs, hist\n",
    "\n",
    "def predict(model, x_test):\n",
    "    x_test = {name:np.array(value) for name, value in x_test.items()}\n",
    "    \n",
    "    return model.predict(x_test)\n",
    "\n",
    "print(\"Defined the create_model and train_model functions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode Label to Numeric Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create label encoder for \"type_label\"\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "enc.fit(train_df[\"type_label\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_path</th>\n",
       "      <th>avg_r</th>\n",
       "      <th>avg_g</th>\n",
       "      <th>avg_b</th>\n",
       "      <th>avg_s</th>\n",
       "      <th>contrast</th>\n",
       "      <th>ASM</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>type_label</th>\n",
       "      <th>type_label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>836</th>\n",
       "      <td>236</td>\n",
       "      <td>./dataset/rainy/rain51.jpg</td>\n",
       "      <td>0.410731</td>\n",
       "      <td>0.413857</td>\n",
       "      <td>0.432631</td>\n",
       "      <td>0.093650</td>\n",
       "      <td>0.037082</td>\n",
       "      <td>-0.267265</td>\n",
       "      <td>-1.391272</td>\n",
       "      <td>rainy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>219</td>\n",
       "      <td>./dataset/cloudy/cloudy253.jpg</td>\n",
       "      <td>1.061717</td>\n",
       "      <td>0.943858</td>\n",
       "      <td>0.685209</td>\n",
       "      <td>0.106825</td>\n",
       "      <td>0.442497</td>\n",
       "      <td>-0.252540</td>\n",
       "      <td>-0.979389</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>219</td>\n",
       "      <td>./dataset/rainy/rain67.jpg</td>\n",
       "      <td>-1.998985</td>\n",
       "      <td>-1.143907</td>\n",
       "      <td>-0.602893</td>\n",
       "      <td>0.452036</td>\n",
       "      <td>-0.391959</td>\n",
       "      <td>-0.234940</td>\n",
       "      <td>-0.665750</td>\n",
       "      <td>rainy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>./dataset/cloudy/cloudy201.jpg</td>\n",
       "      <td>0.600008</td>\n",
       "      <td>0.678466</td>\n",
       "      <td>0.537344</td>\n",
       "      <td>0.161326</td>\n",
       "      <td>-0.481976</td>\n",
       "      <td>-0.150335</td>\n",
       "      <td>0.584369</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>64</td>\n",
       "      <td>./dataset/cloudy/cloudy43.jpg</td>\n",
       "      <td>-0.869661</td>\n",
       "      <td>-0.782150</td>\n",
       "      <td>-0.377383</td>\n",
       "      <td>0.238895</td>\n",
       "      <td>-0.314980</td>\n",
       "      <td>-0.229821</td>\n",
       "      <td>-0.564923</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                        img_path     avg_r     avg_g     avg_b  \\\n",
       "836  236      ./dataset/rainy/rain51.jpg  0.410731  0.413857  0.432631   \n",
       "219  219  ./dataset/cloudy/cloudy253.jpg  1.061717  0.943858  0.685209   \n",
       "819  219      ./dataset/rainy/rain67.jpg -1.998985 -1.143907 -0.602893   \n",
       "10    10  ./dataset/cloudy/cloudy201.jpg  0.600008  0.678466  0.537344   \n",
       "64    64   ./dataset/cloudy/cloudy43.jpg -0.869661 -0.782150 -0.377383   \n",
       "\n",
       "        avg_s  contrast       ASM  homogeneity type_label  type_label_encoded  \n",
       "836  0.093650  0.037082 -0.267265    -1.391272      rainy                   2  \n",
       "219  0.106825  0.442497 -0.252540    -0.979389     cloudy                   0  \n",
       "819  0.452036 -0.391959 -0.234940    -0.665750      rainy                   2  \n",
       "10   0.161326 -0.481976 -0.150335     0.584369     cloudy                   0  \n",
       "64   0.238895 -0.314980 -0.229821    -0.564923     cloudy                   0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df[\"type_label_encoded\"] = enc.transform(train_df[\"type_label\"].values)\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train : validation = 0.7 : 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_path</th>\n",
       "      <th>avg_r</th>\n",
       "      <th>avg_g</th>\n",
       "      <th>avg_b</th>\n",
       "      <th>avg_s</th>\n",
       "      <th>contrast</th>\n",
       "      <th>ASM</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>type_label</th>\n",
       "      <th>type_label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>257</td>\n",
       "      <td>./dataset/sunrise/sunrise44.jpg</td>\n",
       "      <td>0.291810</td>\n",
       "      <td>0.581448</td>\n",
       "      <td>0.398442</td>\n",
       "      <td>0.336671</td>\n",
       "      <td>-0.513558</td>\n",
       "      <td>-0.201778</td>\n",
       "      <td>0.895708</td>\n",
       "      <td>sunrise</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>201</td>\n",
       "      <td>./dataset/shine/shine156.jpg</td>\n",
       "      <td>-0.739868</td>\n",
       "      <td>0.871666</td>\n",
       "      <td>0.231890</td>\n",
       "      <td>0.571403</td>\n",
       "      <td>1.716378</td>\n",
       "      <td>-0.265751</td>\n",
       "      <td>-1.532766</td>\n",
       "      <td>shine</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>114</td>\n",
       "      <td>./dataset/shine/shine222.jpg</td>\n",
       "      <td>0.802073</td>\n",
       "      <td>1.138149</td>\n",
       "      <td>1.309384</td>\n",
       "      <td>0.227457</td>\n",
       "      <td>2.249867</td>\n",
       "      <td>-0.253282</td>\n",
       "      <td>-0.723525</td>\n",
       "      <td>shine</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>170</td>\n",
       "      <td>./dataset/foggy/foggy35.jpg</td>\n",
       "      <td>-0.934573</td>\n",
       "      <td>-0.827574</td>\n",
       "      <td>-0.561668</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.512850</td>\n",
       "      <td>-0.072186</td>\n",
       "      <td>1.230724</td>\n",
       "      <td>foggy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>./dataset/cloudy/cloudy52.jpg</td>\n",
       "      <td>-1.567960</td>\n",
       "      <td>-0.981091</td>\n",
       "      <td>-0.439574</td>\n",
       "      <td>0.333399</td>\n",
       "      <td>-0.414422</td>\n",
       "      <td>-0.220669</td>\n",
       "      <td>-0.113699</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                         img_path     avg_r     avg_g     avg_b  \\\n",
       "1407  257  ./dataset/sunrise/sunrise44.jpg  0.291810  0.581448  0.398442   \n",
       "1101  201     ./dataset/shine/shine156.jpg -0.739868  0.871666  0.231890   \n",
       "1014  114     ./dataset/shine/shine222.jpg  0.802073  1.138149  1.309384   \n",
       "470   170      ./dataset/foggy/foggy35.jpg -0.934573 -0.827574 -0.561668   \n",
       "14     14    ./dataset/cloudy/cloudy52.jpg -1.567960 -0.981091 -0.439574   \n",
       "\n",
       "         avg_s  contrast       ASM  homogeneity type_label  type_label_encoded  \n",
       "1407  0.336671 -0.513558 -0.201778     0.895708    sunrise                   4  \n",
       "1101  0.571403  1.716378 -0.265751    -1.532766      shine                   3  \n",
       "1014  0.227457  2.249867 -0.253282    -0.723525      shine                   3  \n",
       "470   0.000000 -0.512850 -0.072186     1.230724      foggy                   1  \n",
       "14    0.333399 -0.414422 -0.220669    -0.113699     cloudy                   0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_path</th>\n",
       "      <th>avg_r</th>\n",
       "      <th>avg_g</th>\n",
       "      <th>avg_b</th>\n",
       "      <th>avg_s</th>\n",
       "      <th>contrast</th>\n",
       "      <th>ASM</th>\n",
       "      <th>homogeneity</th>\n",
       "      <th>type_label</th>\n",
       "      <th>type_label_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>219</td>\n",
       "      <td>./dataset/cloudy/cloudy253.jpg</td>\n",
       "      <td>1.061717</td>\n",
       "      <td>0.943858</td>\n",
       "      <td>0.685209</td>\n",
       "      <td>0.106825</td>\n",
       "      <td>0.442497</td>\n",
       "      <td>-0.252540</td>\n",
       "      <td>-0.979389</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>258</td>\n",
       "      <td>./dataset/rainy/rain224.jpg</td>\n",
       "      <td>1.228042</td>\n",
       "      <td>1.075471</td>\n",
       "      <td>0.837545</td>\n",
       "      <td>0.122713</td>\n",
       "      <td>-0.188307</td>\n",
       "      <td>-0.251967</td>\n",
       "      <td>-0.937774</td>\n",
       "      <td>rainy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>79</td>\n",
       "      <td>./dataset/rainy/rain87.jpg</td>\n",
       "      <td>-0.296609</td>\n",
       "      <td>-0.145905</td>\n",
       "      <td>0.094005</td>\n",
       "      <td>0.105588</td>\n",
       "      <td>0.087872</td>\n",
       "      <td>-0.101863</td>\n",
       "      <td>0.013227</td>\n",
       "      <td>rainy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>130</td>\n",
       "      <td>./dataset/rainy/rain72.jpg</td>\n",
       "      <td>0.113654</td>\n",
       "      <td>0.429937</td>\n",
       "      <td>0.723947</td>\n",
       "      <td>0.234190</td>\n",
       "      <td>-0.320204</td>\n",
       "      <td>-0.261286</td>\n",
       "      <td>-1.371499</td>\n",
       "      <td>rainy</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>107</td>\n",
       "      <td>./dataset/sunrise/sunrise234.jpg</td>\n",
       "      <td>1.142296</td>\n",
       "      <td>0.160556</td>\n",
       "      <td>-0.685945</td>\n",
       "      <td>0.528345</td>\n",
       "      <td>-0.444193</td>\n",
       "      <td>-0.206027</td>\n",
       "      <td>0.240270</td>\n",
       "      <td>sunrise</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                          img_path     avg_r     avg_g     avg_b  \\\n",
       "219   219    ./dataset/cloudy/cloudy253.jpg  1.061717  0.943858  0.685209   \n",
       "858   258       ./dataset/rainy/rain224.jpg  1.228042  1.075471  0.837545   \n",
       "679    79        ./dataset/rainy/rain87.jpg -0.296609 -0.145905  0.094005   \n",
       "730   130        ./dataset/rainy/rain72.jpg  0.113654  0.429937  0.723947   \n",
       "1257  107  ./dataset/sunrise/sunrise234.jpg  1.142296  0.160556 -0.685945   \n",
       "\n",
       "         avg_s  contrast       ASM  homogeneity type_label  type_label_encoded  \n",
       "219   0.106825  0.442497 -0.252540    -0.979389     cloudy                   0  \n",
       "858   0.122713 -0.188307 -0.251967    -0.937774      rainy                   2  \n",
       "679   0.105588  0.087872 -0.101863     0.013227      rainy                   2  \n",
       "730   0.234190 -0.320204 -0.261286    -1.371499      rainy                   2  \n",
       "1257  0.528345 -0.444193 -0.206027     0.240270    sunrise                   4  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split train dataset into train and validation\n",
    "train_set = train_df.sample(frac=0.7)\n",
    "val_set = train_df.drop(train_set.index)\n",
    "\n",
    "display(train_set.head())\n",
    "display(val_set.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1050 samples, validate on 450 samples\n",
      "Epoch 1/600\n",
      "1050/1050 [==============================] - 1s 660us/sample - loss: 1.6012 - accuracy: 0.2533 - val_loss: 1.5587 - val_accuracy: 0.2956\n",
      "Epoch 2/600\n",
      "1050/1050 [==============================] - 0s 124us/sample - loss: 1.5449 - accuracy: 0.2952 - val_loss: 1.5110 - val_accuracy: 0.3111\n",
      "Epoch 3/600\n",
      "1050/1050 [==============================] - 0s 145us/sample - loss: 1.4970 - accuracy: 0.3524 - val_loss: 1.4631 - val_accuracy: 0.3556\n",
      "Epoch 4/600\n",
      "1050/1050 [==============================] - 0s 107us/sample - loss: 1.4442 - accuracy: 0.4181 - val_loss: 1.4079 - val_accuracy: 0.4267\n",
      "Epoch 5/600\n",
      "1050/1050 [==============================] - 0s 103us/sample - loss: 1.3820 - accuracy: 0.4571 - val_loss: 1.3442 - val_accuracy: 0.4644\n",
      "Epoch 6/600\n",
      "1050/1050 [==============================] - 0s 115us/sample - loss: 1.3105 - accuracy: 0.4838 - val_loss: 1.2809 - val_accuracy: 0.4800\n",
      "Epoch 7/600\n",
      "1050/1050 [==============================] - 0s 104us/sample - loss: 1.2383 - accuracy: 0.4962 - val_loss: 1.2220 - val_accuracy: 0.4844\n",
      "Epoch 8/600\n",
      "1050/1050 [==============================] - 0s 104us/sample - loss: 1.1727 - accuracy: 0.5029 - val_loss: 1.1721 - val_accuracy: 0.5000\n",
      "Epoch 9/600\n",
      "1050/1050 [==============================] - 0s 99us/sample - loss: 1.1102 - accuracy: 0.5286 - val_loss: 1.1274 - val_accuracy: 0.5489\n",
      "Epoch 10/600\n",
      "1050/1050 [==============================] - 0s 116us/sample - loss: 1.0540 - accuracy: 0.5857 - val_loss: 1.0864 - val_accuracy: 0.5667\n",
      "Epoch 11/600\n",
      "1050/1050 [==============================] - 0s 117us/sample - loss: 1.0046 - accuracy: 0.6019 - val_loss: 1.0523 - val_accuracy: 0.5756\n",
      "Epoch 12/600\n",
      "1050/1050 [==============================] - 0s 117us/sample - loss: 0.9663 - accuracy: 0.6181 - val_loss: 1.0229 - val_accuracy: 0.5822\n",
      "Epoch 13/600\n",
      "1050/1050 [==============================] - 0s 117us/sample - loss: 0.9359 - accuracy: 0.6324 - val_loss: 0.9924 - val_accuracy: 0.5933\n",
      "Epoch 14/600\n",
      "1050/1050 [==============================] - 0s 149us/sample - loss: 0.9101 - accuracy: 0.6343 - val_loss: 0.9603 - val_accuracy: 0.6133\n",
      "Epoch 15/600\n",
      "1050/1050 [==============================] - 0s 153us/sample - loss: 0.8836 - accuracy: 0.6610 - val_loss: 0.9316 - val_accuracy: 0.6244\n",
      "Epoch 16/600\n",
      "1050/1050 [==============================] - 0s 103us/sample - loss: 0.8557 - accuracy: 0.6705 - val_loss: 0.8948 - val_accuracy: 0.6489\n",
      "Epoch 17/600\n",
      "1050/1050 [==============================] - 0s 109us/sample - loss: 0.8272 - accuracy: 0.6886 - val_loss: 0.8696 - val_accuracy: 0.6644\n",
      "Epoch 18/600\n",
      "1050/1050 [==============================] - 0s 131us/sample - loss: 0.8034 - accuracy: 0.7000 - val_loss: 0.8492 - val_accuracy: 0.6600\n",
      "Epoch 19/600\n",
      "1050/1050 [==============================] - 0s 113us/sample - loss: 0.7845 - accuracy: 0.7095 - val_loss: 0.8384 - val_accuracy: 0.6733\n",
      "Epoch 20/600\n",
      "1050/1050 [==============================] - 0s 105us/sample - loss: 0.7711 - accuracy: 0.7152 - val_loss: 0.8280 - val_accuracy: 0.6822\n",
      "Epoch 21/600\n",
      "1050/1050 [==============================] - 0s 116us/sample - loss: 0.7609 - accuracy: 0.7162 - val_loss: 0.8203 - val_accuracy: 0.6889\n",
      "Epoch 22/600\n",
      "1050/1050 [==============================] - 0s 122us/sample - loss: 0.7531 - accuracy: 0.7257 - val_loss: 0.8131 - val_accuracy: 0.7000\n",
      "Epoch 23/600\n",
      "1050/1050 [==============================] - 0s 123us/sample - loss: 0.7446 - accuracy: 0.7257 - val_loss: 0.8061 - val_accuracy: 0.7089\n",
      "Epoch 24/600\n",
      "1050/1050 [==============================] - 0s 125us/sample - loss: 0.7380 - accuracy: 0.7295 - val_loss: 0.8023 - val_accuracy: 0.7133\n",
      "Epoch 25/600\n",
      "1050/1050 [==============================] - 0s 155us/sample - loss: 0.7334 - accuracy: 0.7362 - val_loss: 0.7985 - val_accuracy: 0.7089\n",
      "Epoch 26/600\n",
      "1050/1050 [==============================] - 0s 131us/sample - loss: 0.7268 - accuracy: 0.7381 - val_loss: 0.7942 - val_accuracy: 0.7133\n",
      "Epoch 27/600\n",
      "1050/1050 [==============================] - 0s 199us/sample - loss: 0.7216 - accuracy: 0.7381 - val_loss: 0.7903 - val_accuracy: 0.7156\n",
      "Epoch 28/600\n",
      "1050/1050 [==============================] - 0s 234us/sample - loss: 0.7180 - accuracy: 0.7390 - val_loss: 0.7866 - val_accuracy: 0.7267\n",
      "Epoch 29/600\n",
      "1050/1050 [==============================] - 0s 220us/sample - loss: 0.7125 - accuracy: 0.7429 - val_loss: 0.7826 - val_accuracy: 0.7156\n",
      "Epoch 30/600\n",
      "1050/1050 [==============================] - 0s 221us/sample - loss: 0.7103 - accuracy: 0.7457 - val_loss: 0.7797 - val_accuracy: 0.7222\n",
      "Epoch 31/600\n",
      "1050/1050 [==============================] - 0s 251us/sample - loss: 0.7051 - accuracy: 0.7457 - val_loss: 0.7761 - val_accuracy: 0.7178\n",
      "Epoch 32/600\n",
      "1050/1050 [==============================] - 0s 280us/sample - loss: 0.7016 - accuracy: 0.7476 - val_loss: 0.7728 - val_accuracy: 0.7267\n",
      "Epoch 33/600\n",
      "1050/1050 [==============================] - 0s 256us/sample - loss: 0.6989 - accuracy: 0.7467 - val_loss: 0.7703 - val_accuracy: 0.7267\n",
      "Epoch 34/600\n",
      "1050/1050 [==============================] - 0s 210us/sample - loss: 0.6967 - accuracy: 0.7514 - val_loss: 0.7688 - val_accuracy: 0.7333\n",
      "Epoch 35/600\n",
      "1050/1050 [==============================] - 0s 294us/sample - loss: 0.6921 - accuracy: 0.7543 - val_loss: 0.7658 - val_accuracy: 0.7244\n",
      "Epoch 36/600\n",
      "1050/1050 [==============================] - 0s 273us/sample - loss: 0.6890 - accuracy: 0.7552 - val_loss: 0.7629 - val_accuracy: 0.7311\n",
      "Epoch 37/600\n",
      "1050/1050 [==============================] - 0s 254us/sample - loss: 0.6866 - accuracy: 0.7524 - val_loss: 0.7602 - val_accuracy: 0.7378\n",
      "Epoch 38/600\n",
      "1050/1050 [==============================] - 0s 280us/sample - loss: 0.6842 - accuracy: 0.7543 - val_loss: 0.7587 - val_accuracy: 0.7244\n",
      "Epoch 39/600\n",
      "1050/1050 [==============================] - 0s 249us/sample - loss: 0.6827 - accuracy: 0.7562 - val_loss: 0.7579 - val_accuracy: 0.7400\n",
      "Epoch 40/600\n",
      "1050/1050 [==============================] - 0s 315us/sample - loss: 0.6783 - accuracy: 0.7571 - val_loss: 0.7550 - val_accuracy: 0.7378\n",
      "Epoch 41/600\n",
      "1050/1050 [==============================] - 0s 238us/sample - loss: 0.6755 - accuracy: 0.7524 - val_loss: 0.7535 - val_accuracy: 0.7378\n",
      "Epoch 42/600\n",
      "1050/1050 [==============================] - 0s 282us/sample - loss: 0.6726 - accuracy: 0.7619 - val_loss: 0.7517 - val_accuracy: 0.7333\n",
      "Epoch 43/600\n",
      "1050/1050 [==============================] - 0s 229us/sample - loss: 0.6714 - accuracy: 0.7629 - val_loss: 0.7504 - val_accuracy: 0.7444\n",
      "Epoch 44/600\n",
      "1050/1050 [==============================] - 0s 282us/sample - loss: 0.6690 - accuracy: 0.7581 - val_loss: 0.7496 - val_accuracy: 0.7244\n",
      "Epoch 45/600\n",
      "1050/1050 [==============================] - 0s 256us/sample - loss: 0.6651 - accuracy: 0.7610 - val_loss: 0.7466 - val_accuracy: 0.7422\n",
      "Epoch 46/600\n",
      "1050/1050 [==============================] - 0s 314us/sample - loss: 0.6628 - accuracy: 0.7648 - val_loss: 0.7455 - val_accuracy: 0.7378\n",
      "Epoch 47/600\n",
      "1050/1050 [==============================] - 0s 215us/sample - loss: 0.6598 - accuracy: 0.7724 - val_loss: 0.7453 - val_accuracy: 0.7444\n",
      "Epoch 48/600\n",
      "1050/1050 [==============================] - 0s 266us/sample - loss: 0.6603 - accuracy: 0.7686 - val_loss: 0.7437 - val_accuracy: 0.7467\n",
      "Epoch 49/600\n",
      "1050/1050 [==============================] - 0s 226us/sample - loss: 0.6560 - accuracy: 0.7667 - val_loss: 0.7426 - val_accuracy: 0.7378\n",
      "Epoch 50/600\n",
      "1050/1050 [==============================] - 0s 282us/sample - loss: 0.6538 - accuracy: 0.7686 - val_loss: 0.7422 - val_accuracy: 0.7422\n",
      "Epoch 51/600\n",
      "1050/1050 [==============================] - 0s 253us/sample - loss: 0.6522 - accuracy: 0.7724 - val_loss: 0.7410 - val_accuracy: 0.7400\n",
      "Epoch 52/600\n",
      "1050/1050 [==============================] - 0s 301us/sample - loss: 0.6514 - accuracy: 0.7686 - val_loss: 0.7406 - val_accuracy: 0.7400\n",
      "Epoch 53/600\n",
      "1050/1050 [==============================] - 0s 298us/sample - loss: 0.6496 - accuracy: 0.7714 - val_loss: 0.7379 - val_accuracy: 0.7378\n",
      "Epoch 54/600\n",
      "1050/1050 [==============================] - 0s 272us/sample - loss: 0.6463 - accuracy: 0.7714 - val_loss: 0.7365 - val_accuracy: 0.7444\n",
      "Epoch 55/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 0s 270us/sample - loss: 0.6450 - accuracy: 0.7667 - val_loss: 0.7365 - val_accuracy: 0.7356\n",
      "Epoch 56/600\n",
      "1050/1050 [==============================] - 0s 246us/sample - loss: 0.6425 - accuracy: 0.7676 - val_loss: 0.7358 - val_accuracy: 0.7378\n",
      "Epoch 57/600\n",
      "1050/1050 [==============================] - 0s 247us/sample - loss: 0.6405 - accuracy: 0.7714 - val_loss: 0.7361 - val_accuracy: 0.7333\n",
      "Epoch 58/600\n",
      "1050/1050 [==============================] - 0s 307us/sample - loss: 0.6377 - accuracy: 0.7676 - val_loss: 0.7342 - val_accuracy: 0.7378\n",
      "Epoch 59/600\n",
      "1050/1050 [==============================] - 0s 292us/sample - loss: 0.6367 - accuracy: 0.7667 - val_loss: 0.7336 - val_accuracy: 0.7311\n",
      "Epoch 60/600\n",
      "1050/1050 [==============================] - 0s 251us/sample - loss: 0.6372 - accuracy: 0.7724 - val_loss: 0.7344 - val_accuracy: 0.7311\n",
      "Epoch 61/600\n",
      "1050/1050 [==============================] - 0s 237us/sample - loss: 0.6348 - accuracy: 0.7629 - val_loss: 0.7344 - val_accuracy: 0.7400\n",
      "Epoch 62/600\n",
      "1050/1050 [==============================] - 0s 273us/sample - loss: 0.6305 - accuracy: 0.7657 - val_loss: 0.7318 - val_accuracy: 0.7378\n",
      "Epoch 63/600\n",
      "1050/1050 [==============================] - 0s 247us/sample - loss: 0.6304 - accuracy: 0.7752 - val_loss: 0.7314 - val_accuracy: 0.7356\n",
      "Epoch 64/600\n",
      "1050/1050 [==============================] - 0s 249us/sample - loss: 0.6278 - accuracy: 0.7724 - val_loss: 0.7337 - val_accuracy: 0.7378\n",
      "Epoch 65/600\n",
      "1050/1050 [==============================] - 0s 309us/sample - loss: 0.6274 - accuracy: 0.7743 - val_loss: 0.7305 - val_accuracy: 0.7378\n",
      "Epoch 66/600\n",
      "1050/1050 [==============================] - 0s 290us/sample - loss: 0.6227 - accuracy: 0.7771 - val_loss: 0.7302 - val_accuracy: 0.7333\n",
      "Epoch 67/600\n",
      "1050/1050 [==============================] - 0s 265us/sample - loss: 0.6216 - accuracy: 0.7714 - val_loss: 0.7287 - val_accuracy: 0.7289\n",
      "Epoch 68/600\n",
      "1050/1050 [==============================] - 0s 257us/sample - loss: 0.6195 - accuracy: 0.7733 - val_loss: 0.7272 - val_accuracy: 0.7244\n",
      "Epoch 69/600\n",
      "1050/1050 [==============================] - 0s 272us/sample - loss: 0.6192 - accuracy: 0.7733 - val_loss: 0.7276 - val_accuracy: 0.7222\n",
      "Epoch 70/600\n",
      "1050/1050 [==============================] - 0s 329us/sample - loss: 0.6175 - accuracy: 0.7781 - val_loss: 0.7272 - val_accuracy: 0.7289\n",
      "Epoch 71/600\n",
      "1050/1050 [==============================] - 0s 342us/sample - loss: 0.6148 - accuracy: 0.7790 - val_loss: 0.7275 - val_accuracy: 0.7222\n",
      "Epoch 72/600\n",
      "1050/1050 [==============================] - 0s 350us/sample - loss: 0.6148 - accuracy: 0.7771 - val_loss: 0.7273 - val_accuracy: 0.7267\n",
      "Epoch 73/600\n",
      "1050/1050 [==============================] - 0s 282us/sample - loss: 0.6125 - accuracy: 0.7781 - val_loss: 0.7255 - val_accuracy: 0.7289\n",
      "Epoch 74/600\n",
      "1050/1050 [==============================] - 0s 291us/sample - loss: 0.6129 - accuracy: 0.7819 - val_loss: 0.7262 - val_accuracy: 0.7267\n",
      "Epoch 75/600\n",
      "1050/1050 [==============================] - 0s 366us/sample - loss: 0.6113 - accuracy: 0.7771 - val_loss: 0.7239 - val_accuracy: 0.7289\n",
      "Epoch 76/600\n",
      "1050/1050 [==============================] - 0s 349us/sample - loss: 0.6094 - accuracy: 0.7762 - val_loss: 0.7234 - val_accuracy: 0.7333\n",
      "Epoch 77/600\n",
      "1050/1050 [==============================] - 0s 395us/sample - loss: 0.6070 - accuracy: 0.7848 - val_loss: 0.7244 - val_accuracy: 0.7267\n",
      "Epoch 78/600\n",
      "1050/1050 [==============================] - 0s 274us/sample - loss: 0.6056 - accuracy: 0.7886 - val_loss: 0.7233 - val_accuracy: 0.7267\n",
      "Epoch 79/600\n",
      "1050/1050 [==============================] - 0s 293us/sample - loss: 0.6035 - accuracy: 0.7829 - val_loss: 0.7211 - val_accuracy: 0.7289\n",
      "Epoch 80/600\n",
      "1050/1050 [==============================] - 0s 346us/sample - loss: 0.6019 - accuracy: 0.7857 - val_loss: 0.7213 - val_accuracy: 0.7356\n",
      "Epoch 81/600\n",
      "1050/1050 [==============================] - 0s 256us/sample - loss: 0.6022 - accuracy: 0.7895 - val_loss: 0.7195 - val_accuracy: 0.7311\n",
      "Epoch 82/600\n",
      "1050/1050 [==============================] - 0s 303us/sample - loss: 0.6000 - accuracy: 0.7857 - val_loss: 0.7187 - val_accuracy: 0.7378\n",
      "Epoch 83/600\n",
      "1050/1050 [==============================] - 0s 308us/sample - loss: 0.5983 - accuracy: 0.7895 - val_loss: 0.7170 - val_accuracy: 0.7378\n",
      "Epoch 84/600\n",
      "1050/1050 [==============================] - 0s 296us/sample - loss: 0.5964 - accuracy: 0.7876 - val_loss: 0.7165 - val_accuracy: 0.7356\n",
      "Epoch 85/600\n",
      "1050/1050 [==============================] - 0s 259us/sample - loss: 0.5958 - accuracy: 0.7867 - val_loss: 0.7155 - val_accuracy: 0.7333\n",
      "Epoch 86/600\n",
      "1050/1050 [==============================] - 0s 358us/sample - loss: 0.5939 - accuracy: 0.7857 - val_loss: 0.7156 - val_accuracy: 0.7289\n",
      "Epoch 87/600\n",
      "1050/1050 [==============================] - 0s 253us/sample - loss: 0.5928 - accuracy: 0.7886 - val_loss: 0.7143 - val_accuracy: 0.7378\n",
      "Epoch 88/600\n",
      "1050/1050 [==============================] - 0s 271us/sample - loss: 0.5906 - accuracy: 0.7876 - val_loss: 0.7140 - val_accuracy: 0.7378\n",
      "Epoch 89/600\n",
      "1050/1050 [==============================] - 0s 309us/sample - loss: 0.5899 - accuracy: 0.7905 - val_loss: 0.7128 - val_accuracy: 0.7311\n",
      "Epoch 90/600\n",
      "1050/1050 [==============================] - 0s 211us/sample - loss: 0.5876 - accuracy: 0.7895 - val_loss: 0.7123 - val_accuracy: 0.7333\n",
      "Epoch 91/600\n",
      "1050/1050 [==============================] - 0s 295us/sample - loss: 0.5869 - accuracy: 0.7886 - val_loss: 0.7105 - val_accuracy: 0.7333\n",
      "Epoch 92/600\n",
      "1050/1050 [==============================] - 0s 294us/sample - loss: 0.5883 - accuracy: 0.7924 - val_loss: 0.7100 - val_accuracy: 0.7378\n",
      "Epoch 93/600\n",
      "1050/1050 [==============================] - 0s 215us/sample - loss: 0.5848 - accuracy: 0.7914 - val_loss: 0.7107 - val_accuracy: 0.7378\n",
      "Epoch 94/600\n",
      "1050/1050 [==============================] - 0s 231us/sample - loss: 0.5829 - accuracy: 0.7895 - val_loss: 0.7078 - val_accuracy: 0.7356\n",
      "Epoch 95/600\n",
      "1050/1050 [==============================] - 0s 233us/sample - loss: 0.5819 - accuracy: 0.7905 - val_loss: 0.7080 - val_accuracy: 0.7378\n",
      "Epoch 96/600\n",
      "1050/1050 [==============================] - 0s 270us/sample - loss: 0.5806 - accuracy: 0.7943 - val_loss: 0.7092 - val_accuracy: 0.7333\n",
      "Epoch 97/600\n",
      "1050/1050 [==============================] - 0s 248us/sample - loss: 0.5792 - accuracy: 0.7933 - val_loss: 0.7076 - val_accuracy: 0.7356\n",
      "Epoch 98/600\n",
      "1050/1050 [==============================] - 0s 234us/sample - loss: 0.5768 - accuracy: 0.7952 - val_loss: 0.7077 - val_accuracy: 0.7356\n",
      "Epoch 99/600\n",
      "1050/1050 [==============================] - 0s 244us/sample - loss: 0.5783 - accuracy: 0.7943 - val_loss: 0.7077 - val_accuracy: 0.7400\n",
      "Epoch 100/600\n",
      "1050/1050 [==============================] - 0s 232us/sample - loss: 0.5763 - accuracy: 0.7886 - val_loss: 0.7091 - val_accuracy: 0.7311\n",
      "Epoch 101/600\n",
      "1050/1050 [==============================] - 0s 292us/sample - loss: 0.5759 - accuracy: 0.7905 - val_loss: 0.7079 - val_accuracy: 0.7311\n",
      "Epoch 102/600\n",
      "1050/1050 [==============================] - 0s 242us/sample - loss: 0.5749 - accuracy: 0.7914 - val_loss: 0.7062 - val_accuracy: 0.7333\n",
      "Epoch 103/600\n",
      "1050/1050 [==============================] - 0s 259us/sample - loss: 0.5732 - accuracy: 0.7924 - val_loss: 0.7055 - val_accuracy: 0.7311\n",
      "Epoch 104/600\n",
      "1050/1050 [==============================] - 0s 241us/sample - loss: 0.5717 - accuracy: 0.7952 - val_loss: 0.7048 - val_accuracy: 0.7378\n",
      "Epoch 105/600\n",
      "1050/1050 [==============================] - 0s 258us/sample - loss: 0.5714 - accuracy: 0.7886 - val_loss: 0.7049 - val_accuracy: 0.7422\n",
      "Epoch 106/600\n",
      "1050/1050 [==============================] - 0s 217us/sample - loss: 0.5702 - accuracy: 0.7933 - val_loss: 0.7040 - val_accuracy: 0.7311\n",
      "Epoch 107/600\n",
      "1050/1050 [==============================] - 0s 221us/sample - loss: 0.5706 - accuracy: 0.7905 - val_loss: 0.7046 - val_accuracy: 0.7400\n",
      "Epoch 108/600\n",
      "1050/1050 [==============================] - 0s 309us/sample - loss: 0.5680 - accuracy: 0.7933 - val_loss: 0.7079 - val_accuracy: 0.7289\n",
      "Epoch 109/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 0s 235us/sample - loss: 0.5679 - accuracy: 0.7914 - val_loss: 0.7040 - val_accuracy: 0.7422\n",
      "Epoch 110/600\n",
      "1050/1050 [==============================] - 0s 192us/sample - loss: 0.5661 - accuracy: 0.7962 - val_loss: 0.7048 - val_accuracy: 0.7422\n",
      "Epoch 111/600\n",
      "1050/1050 [==============================] - 0s 221us/sample - loss: 0.5649 - accuracy: 0.7971 - val_loss: 0.7022 - val_accuracy: 0.7311\n",
      "Epoch 112/600\n",
      "1050/1050 [==============================] - 0s 246us/sample - loss: 0.5659 - accuracy: 0.7943 - val_loss: 0.7029 - val_accuracy: 0.7378\n",
      "Epoch 113/600\n",
      "1050/1050 [==============================] - 0s 202us/sample - loss: 0.5644 - accuracy: 0.7952 - val_loss: 0.7006 - val_accuracy: 0.7400\n",
      "Epoch 114/600\n",
      "1050/1050 [==============================] - 0s 313us/sample - loss: 0.5628 - accuracy: 0.7933 - val_loss: 0.7018 - val_accuracy: 0.7378\n",
      "Epoch 115/600\n",
      "1050/1050 [==============================] - 0s 282us/sample - loss: 0.5624 - accuracy: 0.7914 - val_loss: 0.7006 - val_accuracy: 0.7444\n",
      "Epoch 116/600\n",
      "1050/1050 [==============================] - 0s 269us/sample - loss: 0.5615 - accuracy: 0.7933 - val_loss: 0.7014 - val_accuracy: 0.7356\n",
      "Epoch 117/600\n",
      "1050/1050 [==============================] - 0s 301us/sample - loss: 0.5617 - accuracy: 0.7933 - val_loss: 0.6999 - val_accuracy: 0.7400\n",
      "Epoch 118/600\n",
      "1050/1050 [==============================] - 0s 292us/sample - loss: 0.5605 - accuracy: 0.7876 - val_loss: 0.7008 - val_accuracy: 0.7378\n",
      "Epoch 119/600\n",
      "1050/1050 [==============================] - 0s 350us/sample - loss: 0.5614 - accuracy: 0.7933 - val_loss: 0.7011 - val_accuracy: 0.7444\n",
      "Epoch 120/600\n",
      "1050/1050 [==============================] - 0s 239us/sample - loss: 0.5588 - accuracy: 0.7962 - val_loss: 0.6998 - val_accuracy: 0.7378\n",
      "Epoch 121/600\n",
      "1050/1050 [==============================] - 0s 229us/sample - loss: 0.5602 - accuracy: 0.7924 - val_loss: 0.6991 - val_accuracy: 0.7444\n",
      "Epoch 122/600\n",
      "1050/1050 [==============================] - 0s 280us/sample - loss: 0.5585 - accuracy: 0.7914 - val_loss: 0.7014 - val_accuracy: 0.7422\n",
      "Epoch 123/600\n",
      "1050/1050 [==============================] - 0s 221us/sample - loss: 0.5558 - accuracy: 0.7971 - val_loss: 0.6992 - val_accuracy: 0.7400\n",
      "Epoch 124/600\n",
      "1050/1050 [==============================] - 0s 238us/sample - loss: 0.5567 - accuracy: 0.7981 - val_loss: 0.6967 - val_accuracy: 0.7467\n",
      "Epoch 125/600\n",
      "1050/1050 [==============================] - 0s 241us/sample - loss: 0.5574 - accuracy: 0.7886 - val_loss: 0.7003 - val_accuracy: 0.7400\n",
      "Epoch 126/600\n",
      "1050/1050 [==============================] - 0s 254us/sample - loss: 0.5551 - accuracy: 0.7905 - val_loss: 0.6986 - val_accuracy: 0.7511\n",
      "Epoch 127/600\n",
      "1050/1050 [==============================] - 0s 286us/sample - loss: 0.5551 - accuracy: 0.7952 - val_loss: 0.7000 - val_accuracy: 0.7356\n",
      "Epoch 128/600\n",
      "1050/1050 [==============================] - 0s 248us/sample - loss: 0.5527 - accuracy: 0.7962 - val_loss: 0.6980 - val_accuracy: 0.7422\n",
      "Epoch 129/600\n",
      "1050/1050 [==============================] - 0s 243us/sample - loss: 0.5521 - accuracy: 0.7933 - val_loss: 0.6983 - val_accuracy: 0.7378\n",
      "Epoch 130/600\n",
      "1050/1050 [==============================] - 0s 303us/sample - loss: 0.5518 - accuracy: 0.7990 - val_loss: 0.6979 - val_accuracy: 0.7422\n",
      "Epoch 131/600\n",
      "1050/1050 [==============================] - 0s 219us/sample - loss: 0.5504 - accuracy: 0.7933 - val_loss: 0.6986 - val_accuracy: 0.7356\n",
      "Epoch 132/600\n",
      "1050/1050 [==============================] - 0s 245us/sample - loss: 0.5493 - accuracy: 0.7981 - val_loss: 0.6957 - val_accuracy: 0.7400\n",
      "Epoch 133/600\n",
      "1050/1050 [==============================] - 0s 292us/sample - loss: 0.5495 - accuracy: 0.7990 - val_loss: 0.6978 - val_accuracy: 0.7444\n",
      "Epoch 134/600\n",
      "1050/1050 [==============================] - 0s 203us/sample - loss: 0.5485 - accuracy: 0.8010 - val_loss: 0.6997 - val_accuracy: 0.7333\n",
      "Epoch 135/600\n",
      "1050/1050 [==============================] - 0s 228us/sample - loss: 0.5489 - accuracy: 0.7952 - val_loss: 0.6962 - val_accuracy: 0.7333\n",
      "Epoch 136/600\n",
      "1050/1050 [==============================] - 0s 280us/sample - loss: 0.5457 - accuracy: 0.8000 - val_loss: 0.6957 - val_accuracy: 0.7333\n",
      "Epoch 137/600\n",
      "1050/1050 [==============================] - 0s 259us/sample - loss: 0.5472 - accuracy: 0.7981 - val_loss: 0.6964 - val_accuracy: 0.7400\n",
      "Epoch 138/600\n",
      "1050/1050 [==============================] - 0s 222us/sample - loss: 0.5457 - accuracy: 0.7990 - val_loss: 0.6948 - val_accuracy: 0.7311\n",
      "Epoch 139/600\n",
      "1050/1050 [==============================] - 0s 233us/sample - loss: 0.5452 - accuracy: 0.8000 - val_loss: 0.6954 - val_accuracy: 0.7333\n",
      "Epoch 140/600\n",
      "1050/1050 [==============================] - 0s 267us/sample - loss: 0.5445 - accuracy: 0.7981 - val_loss: 0.6968 - val_accuracy: 0.7378\n",
      "Epoch 141/600\n",
      "1050/1050 [==============================] - 0s 310us/sample - loss: 0.5440 - accuracy: 0.8019 - val_loss: 0.6963 - val_accuracy: 0.7333\n",
      "Epoch 142/600\n",
      "1050/1050 [==============================] - 0s 276us/sample - loss: 0.5434 - accuracy: 0.7962 - val_loss: 0.6962 - val_accuracy: 0.7333\n",
      "Epoch 143/600\n",
      "1050/1050 [==============================] - 0s 323us/sample - loss: 0.5434 - accuracy: 0.7990 - val_loss: 0.6967 - val_accuracy: 0.7356\n",
      "Epoch 144/600\n",
      "1050/1050 [==============================] - 0s 252us/sample - loss: 0.5442 - accuracy: 0.7952 - val_loss: 0.6958 - val_accuracy: 0.7378\n",
      "Epoch 145/600\n",
      "1050/1050 [==============================] - 0s 394us/sample - loss: 0.5415 - accuracy: 0.7990 - val_loss: 0.6950 - val_accuracy: 0.7311\n",
      "Epoch 146/600\n",
      "1050/1050 [==============================] - 0s 290us/sample - loss: 0.5410 - accuracy: 0.7981 - val_loss: 0.6943 - val_accuracy: 0.7378\n",
      "Epoch 147/600\n",
      "1050/1050 [==============================] - 0s 347us/sample - loss: 0.5415 - accuracy: 0.7962 - val_loss: 0.6982 - val_accuracy: 0.7333\n",
      "Epoch 148/600\n",
      "1050/1050 [==============================] - 0s 295us/sample - loss: 0.5402 - accuracy: 0.7981 - val_loss: 0.6944 - val_accuracy: 0.7333\n",
      "Epoch 149/600\n",
      "1050/1050 [==============================] - 0s 327us/sample - loss: 0.5407 - accuracy: 0.7971 - val_loss: 0.6953 - val_accuracy: 0.7333\n",
      "Epoch 150/600\n",
      "1050/1050 [==============================] - 0s 275us/sample - loss: 0.5385 - accuracy: 0.7990 - val_loss: 0.6939 - val_accuracy: 0.7400\n",
      "Epoch 151/600\n",
      "1050/1050 [==============================] - 0s 232us/sample - loss: 0.5396 - accuracy: 0.7971 - val_loss: 0.6948 - val_accuracy: 0.7333\n",
      "Epoch 152/600\n",
      "1050/1050 [==============================] - 0s 372us/sample - loss: 0.5377 - accuracy: 0.7943 - val_loss: 0.6950 - val_accuracy: 0.7333\n",
      "Epoch 153/600\n",
      "1050/1050 [==============================] - 0s 273us/sample - loss: 0.5389 - accuracy: 0.8029 - val_loss: 0.6965 - val_accuracy: 0.7356\n",
      "Epoch 154/600\n",
      "1050/1050 [==============================] - 0s 257us/sample - loss: 0.5397 - accuracy: 0.7990 - val_loss: 0.6943 - val_accuracy: 0.7311\n",
      "Epoch 155/600\n",
      "1050/1050 [==============================] - 0s 313us/sample - loss: 0.5375 - accuracy: 0.7981 - val_loss: 0.6928 - val_accuracy: 0.7333\n",
      "Epoch 156/600\n",
      "1050/1050 [==============================] - 0s 433us/sample - loss: 0.5377 - accuracy: 0.7990 - val_loss: 0.6933 - val_accuracy: 0.7356\n",
      "Epoch 157/600\n",
      "1050/1050 [==============================] - 0s 332us/sample - loss: 0.5368 - accuracy: 0.7990 - val_loss: 0.6943 - val_accuracy: 0.7356\n",
      "Epoch 158/600\n",
      "1050/1050 [==============================] - 0s 309us/sample - loss: 0.5344 - accuracy: 0.7981 - val_loss: 0.6931 - val_accuracy: 0.7378\n",
      "Epoch 159/600\n",
      "1050/1050 [==============================] - 0s 304us/sample - loss: 0.5354 - accuracy: 0.7971 - val_loss: 0.6925 - val_accuracy: 0.7378\n",
      "Epoch 160/600\n",
      "1050/1050 [==============================] - 0s 233us/sample - loss: 0.5352 - accuracy: 0.8019 - val_loss: 0.6946 - val_accuracy: 0.7289\n",
      "Epoch 161/600\n",
      "1050/1050 [==============================] - 0s 273us/sample - loss: 0.5364 - accuracy: 0.7990 - val_loss: 0.6927 - val_accuracy: 0.7333\n",
      "Epoch 162/600\n",
      "1050/1050 [==============================] - 0s 241us/sample - loss: 0.5320 - accuracy: 0.8010 - val_loss: 0.6936 - val_accuracy: 0.7289\n",
      "Epoch 163/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 0s 279us/sample - loss: 0.5325 - accuracy: 0.8067 - val_loss: 0.6915 - val_accuracy: 0.7333\n",
      "Epoch 164/600\n",
      "1050/1050 [==============================] - 0s 288us/sample - loss: 0.5320 - accuracy: 0.7990 - val_loss: 0.6902 - val_accuracy: 0.7378\n",
      "Epoch 165/600\n",
      "1050/1050 [==============================] - 0s 256us/sample - loss: 0.5357 - accuracy: 0.8000 - val_loss: 0.6977 - val_accuracy: 0.7311\n",
      "Epoch 166/600\n",
      "1050/1050 [==============================] - 0s 240us/sample - loss: 0.5326 - accuracy: 0.7962 - val_loss: 0.6896 - val_accuracy: 0.7356\n",
      "Epoch 167/600\n",
      "1050/1050 [==============================] - 0s 284us/sample - loss: 0.5313 - accuracy: 0.7981 - val_loss: 0.6930 - val_accuracy: 0.7378\n",
      "Epoch 168/600\n",
      "1050/1050 [==============================] - 0s 219us/sample - loss: 0.5336 - accuracy: 0.8057 - val_loss: 0.6928 - val_accuracy: 0.7356\n",
      "Epoch 169/600\n",
      "1050/1050 [==============================] - 0s 230us/sample - loss: 0.5297 - accuracy: 0.8010 - val_loss: 0.6936 - val_accuracy: 0.7378\n",
      "Epoch 170/600\n",
      "1050/1050 [==============================] - 0s 225us/sample - loss: 0.5313 - accuracy: 0.7962 - val_loss: 0.6900 - val_accuracy: 0.7356\n",
      "Epoch 171/600\n",
      "1050/1050 [==============================] - 0s 273us/sample - loss: 0.5291 - accuracy: 0.7971 - val_loss: 0.6931 - val_accuracy: 0.7378\n",
      "Epoch 172/600\n",
      "1050/1050 [==============================] - 0s 274us/sample - loss: 0.5276 - accuracy: 0.8029 - val_loss: 0.6907 - val_accuracy: 0.7333\n",
      "Epoch 173/600\n",
      "1050/1050 [==============================] - 0s 259us/sample - loss: 0.5278 - accuracy: 0.8038 - val_loss: 0.6919 - val_accuracy: 0.7356\n",
      "Epoch 174/600\n",
      "1050/1050 [==============================] - 0s 202us/sample - loss: 0.5278 - accuracy: 0.8038 - val_loss: 0.6933 - val_accuracy: 0.7311\n",
      "Epoch 175/600\n",
      "1050/1050 [==============================] - 0s 333us/sample - loss: 0.5290 - accuracy: 0.8019 - val_loss: 0.6898 - val_accuracy: 0.7378\n",
      "Epoch 176/600\n",
      "1050/1050 [==============================] - 0s 239us/sample - loss: 0.5258 - accuracy: 0.8000 - val_loss: 0.6942 - val_accuracy: 0.7400\n",
      "Epoch 177/600\n",
      "1050/1050 [==============================] - 0s 216us/sample - loss: 0.5246 - accuracy: 0.8038 - val_loss: 0.6902 - val_accuracy: 0.7311\n",
      "Epoch 178/600\n",
      "1050/1050 [==============================] - 0s 225us/sample - loss: 0.5265 - accuracy: 0.8067 - val_loss: 0.6902 - val_accuracy: 0.7311\n",
      "Epoch 179/600\n",
      "1050/1050 [==============================] - 0s 216us/sample - loss: 0.5244 - accuracy: 0.8057 - val_loss: 0.6920 - val_accuracy: 0.7422\n",
      "Epoch 180/600\n",
      "1050/1050 [==============================] - 0s 253us/sample - loss: 0.5252 - accuracy: 0.7971 - val_loss: 0.6881 - val_accuracy: 0.7378\n",
      "Epoch 181/600\n",
      "1050/1050 [==============================] - 0s 262us/sample - loss: 0.5240 - accuracy: 0.8019 - val_loss: 0.6906 - val_accuracy: 0.7378\n",
      "Epoch 182/600\n",
      "1050/1050 [==============================] - 0s 234us/sample - loss: 0.5246 - accuracy: 0.8048 - val_loss: 0.6919 - val_accuracy: 0.7333\n",
      "Epoch 183/600\n",
      "1050/1050 [==============================] - 0s 234us/sample - loss: 0.5239 - accuracy: 0.8019 - val_loss: 0.6893 - val_accuracy: 0.7333\n",
      "Epoch 184/600\n",
      "1050/1050 [==============================] - 0s 226us/sample - loss: 0.5248 - accuracy: 0.7990 - val_loss: 0.6894 - val_accuracy: 0.7356\n",
      "Epoch 185/600\n",
      "1050/1050 [==============================] - 0s 230us/sample - loss: 0.5209 - accuracy: 0.7990 - val_loss: 0.6906 - val_accuracy: 0.7333\n",
      "Epoch 186/600\n",
      "1050/1050 [==============================] - 0s 262us/sample - loss: 0.5227 - accuracy: 0.8057 - val_loss: 0.6887 - val_accuracy: 0.7356\n",
      "Epoch 187/600\n",
      "1050/1050 [==============================] - 0s 235us/sample - loss: 0.5233 - accuracy: 0.8057 - val_loss: 0.6877 - val_accuracy: 0.7356\n",
      "Epoch 188/600\n",
      "1050/1050 [==============================] - 0s 277us/sample - loss: 0.5203 - accuracy: 0.8029 - val_loss: 0.6900 - val_accuracy: 0.7356\n",
      "Epoch 189/600\n",
      "1050/1050 [==============================] - 0s 256us/sample - loss: 0.5208 - accuracy: 0.8048 - val_loss: 0.6902 - val_accuracy: 0.7333\n",
      "Epoch 190/600\n",
      "1050/1050 [==============================] - 0s 250us/sample - loss: 0.5198 - accuracy: 0.8010 - val_loss: 0.6855 - val_accuracy: 0.7378\n",
      "Epoch 191/600\n",
      "1050/1050 [==============================] - 0s 236us/sample - loss: 0.5186 - accuracy: 0.8038 - val_loss: 0.6872 - val_accuracy: 0.7333\n",
      "Epoch 192/600\n",
      "1050/1050 [==============================] - 0s 237us/sample - loss: 0.5181 - accuracy: 0.8038 - val_loss: 0.6892 - val_accuracy: 0.7378\n",
      "Epoch 193/600\n",
      "1050/1050 [==============================] - 0s 244us/sample - loss: 0.5186 - accuracy: 0.8038 - val_loss: 0.6874 - val_accuracy: 0.7333\n",
      "Epoch 194/600\n",
      "1050/1050 [==============================] - 0s 273us/sample - loss: 0.5200 - accuracy: 0.8057 - val_loss: 0.6858 - val_accuracy: 0.7378\n",
      "Epoch 195/600\n",
      "1050/1050 [==============================] - 0s 296us/sample - loss: 0.5183 - accuracy: 0.8057 - val_loss: 0.6888 - val_accuracy: 0.7333\n",
      "Epoch 196/600\n",
      "1050/1050 [==============================] - 0s 285us/sample - loss: 0.5176 - accuracy: 0.8019 - val_loss: 0.6841 - val_accuracy: 0.7378\n",
      "Epoch 197/600\n",
      "1050/1050 [==============================] - 0s 237us/sample - loss: 0.5173 - accuracy: 0.8038 - val_loss: 0.6852 - val_accuracy: 0.7356\n",
      "Epoch 198/600\n",
      "1050/1050 [==============================] - 0s 243us/sample - loss: 0.5179 - accuracy: 0.8000 - val_loss: 0.6838 - val_accuracy: 0.7333\n",
      "Epoch 199/600\n",
      "1050/1050 [==============================] - 0s 266us/sample - loss: 0.5178 - accuracy: 0.8010 - val_loss: 0.6854 - val_accuracy: 0.7333\n",
      "Epoch 200/600\n",
      "1050/1050 [==============================] - 0s 257us/sample - loss: 0.5142 - accuracy: 0.8048 - val_loss: 0.6829 - val_accuracy: 0.7422\n",
      "Epoch 201/600\n",
      "1050/1050 [==============================] - 0s 238us/sample - loss: 0.5132 - accuracy: 0.8019 - val_loss: 0.6842 - val_accuracy: 0.7378\n",
      "Epoch 202/600\n",
      "1050/1050 [==============================] - 0s 234us/sample - loss: 0.5144 - accuracy: 0.8029 - val_loss: 0.6839 - val_accuracy: 0.7333\n",
      "Epoch 203/600\n",
      "1050/1050 [==============================] - 0s 221us/sample - loss: 0.5132 - accuracy: 0.8067 - val_loss: 0.6824 - val_accuracy: 0.7378\n",
      "Epoch 204/600\n",
      "1050/1050 [==============================] - 0s 241us/sample - loss: 0.5129 - accuracy: 0.8019 - val_loss: 0.6828 - val_accuracy: 0.7356\n",
      "Epoch 205/600\n",
      "1050/1050 [==============================] - 0s 168us/sample - loss: 0.5131 - accuracy: 0.8029 - val_loss: 0.6843 - val_accuracy: 0.7333\n",
      "Epoch 206/600\n",
      "1050/1050 [==============================] - 0s 251us/sample - loss: 0.5117 - accuracy: 0.8029 - val_loss: 0.6843 - val_accuracy: 0.7378\n",
      "Epoch 207/600\n",
      "1050/1050 [==============================] - 0s 291us/sample - loss: 0.5116 - accuracy: 0.8067 - val_loss: 0.6841 - val_accuracy: 0.7378\n",
      "Epoch 208/600\n",
      "1050/1050 [==============================] - 0s 246us/sample - loss: 0.5110 - accuracy: 0.8057 - val_loss: 0.6806 - val_accuracy: 0.7400\n",
      "Epoch 209/600\n",
      "1050/1050 [==============================] - 0s 263us/sample - loss: 0.5096 - accuracy: 0.8038 - val_loss: 0.6807 - val_accuracy: 0.7356\n",
      "Epoch 210/600\n",
      "1050/1050 [==============================] - 0s 269us/sample - loss: 0.5093 - accuracy: 0.8095 - val_loss: 0.6821 - val_accuracy: 0.7422\n",
      "Epoch 211/600\n",
      "1050/1050 [==============================] - 0s 231us/sample - loss: 0.5107 - accuracy: 0.8067 - val_loss: 0.6822 - val_accuracy: 0.7400\n",
      "Epoch 212/600\n",
      "1050/1050 [==============================] - 0s 231us/sample - loss: 0.5085 - accuracy: 0.8067 - val_loss: 0.6815 - val_accuracy: 0.7356\n",
      "Epoch 213/600\n",
      "1050/1050 [==============================] - 0s 290us/sample - loss: 0.5098 - accuracy: 0.8048 - val_loss: 0.6800 - val_accuracy: 0.7333\n",
      "Epoch 214/600\n",
      "1050/1050 [==============================] - 0s 279us/sample - loss: 0.5087 - accuracy: 0.8048 - val_loss: 0.6812 - val_accuracy: 0.7400\n",
      "Epoch 215/600\n",
      "1050/1050 [==============================] - 0s 262us/sample - loss: 0.5090 - accuracy: 0.8029 - val_loss: 0.6843 - val_accuracy: 0.7333\n",
      "Epoch 216/600\n",
      "1050/1050 [==============================] - 0s 247us/sample - loss: 0.5080 - accuracy: 0.8038 - val_loss: 0.6818 - val_accuracy: 0.7422\n",
      "Epoch 217/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 0s 210us/sample - loss: 0.5082 - accuracy: 0.8019 - val_loss: 0.6823 - val_accuracy: 0.7356\n",
      "Epoch 218/600\n",
      "1050/1050 [==============================] - 0s 242us/sample - loss: 0.5077 - accuracy: 0.8038 - val_loss: 0.6807 - val_accuracy: 0.7378\n",
      "Epoch 219/600\n",
      "1050/1050 [==============================] - 0s 287us/sample - loss: 0.5078 - accuracy: 0.8048 - val_loss: 0.6827 - val_accuracy: 0.7356\n",
      "Epoch 220/600\n",
      "1050/1050 [==============================] - 0s 307us/sample - loss: 0.5063 - accuracy: 0.8076 - val_loss: 0.6820 - val_accuracy: 0.7378\n",
      "Epoch 221/600\n",
      "1050/1050 [==============================] - 0s 275us/sample - loss: 0.5078 - accuracy: 0.8076 - val_loss: 0.6814 - val_accuracy: 0.7378\n",
      "Epoch 222/600\n",
      "1050/1050 [==============================] - 0s 282us/sample - loss: 0.5069 - accuracy: 0.8086 - val_loss: 0.6817 - val_accuracy: 0.7422\n",
      "Epoch 223/600\n",
      "1050/1050 [==============================] - 0s 248us/sample - loss: 0.5069 - accuracy: 0.8076 - val_loss: 0.6815 - val_accuracy: 0.7378\n",
      "Epoch 224/600\n",
      "1050/1050 [==============================] - 0s 251us/sample - loss: 0.5047 - accuracy: 0.8076 - val_loss: 0.6818 - val_accuracy: 0.7333\n",
      "Epoch 225/600\n",
      "1050/1050 [==============================] - 0s 303us/sample - loss: 0.5057 - accuracy: 0.8067 - val_loss: 0.6819 - val_accuracy: 0.7422\n",
      "Epoch 226/600\n",
      "1050/1050 [==============================] - 0s 328us/sample - loss: 0.5067 - accuracy: 0.8038 - val_loss: 0.6834 - val_accuracy: 0.7333\n",
      "Epoch 227/600\n",
      "1050/1050 [==============================] - 0s 344us/sample - loss: 0.5052 - accuracy: 0.8048 - val_loss: 0.6813 - val_accuracy: 0.7422\n",
      "Epoch 228/600\n",
      "1050/1050 [==============================] - 0s 466us/sample - loss: 0.5051 - accuracy: 0.8067 - val_loss: 0.6823 - val_accuracy: 0.7378\n",
      "Epoch 229/600\n",
      "1050/1050 [==============================] - 0s 389us/sample - loss: 0.5043 - accuracy: 0.8067 - val_loss: 0.6817 - val_accuracy: 0.7378\n",
      "Epoch 230/600\n",
      "1050/1050 [==============================] - 0s 349us/sample - loss: 0.5051 - accuracy: 0.8019 - val_loss: 0.6809 - val_accuracy: 0.7422\n",
      "Epoch 231/600\n",
      "1050/1050 [==============================] - 0s 298us/sample - loss: 0.5046 - accuracy: 0.8067 - val_loss: 0.6815 - val_accuracy: 0.7378\n",
      "Epoch 232/600\n",
      "1050/1050 [==============================] - 0s 349us/sample - loss: 0.5054 - accuracy: 0.8048 - val_loss: 0.6832 - val_accuracy: 0.7333\n",
      "Epoch 233/600\n",
      "1050/1050 [==============================] - 0s 212us/sample - loss: 0.5053 - accuracy: 0.8048 - val_loss: 0.6843 - val_accuracy: 0.7444\n",
      "Epoch 234/600\n",
      "1050/1050 [==============================] - 0s 263us/sample - loss: 0.5026 - accuracy: 0.8000 - val_loss: 0.6834 - val_accuracy: 0.7333\n",
      "Epoch 235/600\n",
      "1050/1050 [==============================] - 0s 253us/sample - loss: 0.5038 - accuracy: 0.8048 - val_loss: 0.6824 - val_accuracy: 0.7400\n",
      "Epoch 236/600\n",
      "1050/1050 [==============================] - 0s 326us/sample - loss: 0.5039 - accuracy: 0.8048 - val_loss: 0.6817 - val_accuracy: 0.7311\n",
      "Epoch 237/600\n",
      "1050/1050 [==============================] - 0s 290us/sample - loss: 0.5062 - accuracy: 0.8010 - val_loss: 0.6823 - val_accuracy: 0.7444\n",
      "Epoch 238/600\n",
      "1050/1050 [==============================] - 0s 348us/sample - loss: 0.5026 - accuracy: 0.8095 - val_loss: 0.6848 - val_accuracy: 0.7244\n",
      "Epoch 239/600\n",
      "1050/1050 [==============================] - 0s 236us/sample - loss: 0.5024 - accuracy: 0.8029 - val_loss: 0.6806 - val_accuracy: 0.7422\n",
      "Epoch 240/600\n",
      "1050/1050 [==============================] - 0s 313us/sample - loss: 0.5040 - accuracy: 0.7990 - val_loss: 0.6831 - val_accuracy: 0.7378\n",
      "Epoch 241/600\n",
      "1050/1050 [==============================] - 0s 281us/sample - loss: 0.5038 - accuracy: 0.8029 - val_loss: 0.6861 - val_accuracy: 0.7356\n",
      "Epoch 242/600\n",
      "1050/1050 [==============================] - 0s 274us/sample - loss: 0.5026 - accuracy: 0.8076 - val_loss: 0.6832 - val_accuracy: 0.7311\n",
      "Epoch 243/600\n",
      "1050/1050 [==============================] - 0s 321us/sample - loss: 0.5009 - accuracy: 0.8057 - val_loss: 0.6801 - val_accuracy: 0.7356\n",
      "Epoch 244/600\n",
      "1050/1050 [==============================] - 0s 215us/sample - loss: 0.5005 - accuracy: 0.8038 - val_loss: 0.6836 - val_accuracy: 0.7444\n",
      "Epoch 245/600\n",
      "1050/1050 [==============================] - 0s 267us/sample - loss: 0.4994 - accuracy: 0.8010 - val_loss: 0.6854 - val_accuracy: 0.7333\n",
      "Epoch 246/600\n",
      "1050/1050 [==============================] - 0s 404us/sample - loss: 0.5005 - accuracy: 0.8076 - val_loss: 0.6816 - val_accuracy: 0.7311\n",
      "Epoch 247/600\n",
      "1050/1050 [==============================] - 0s 394us/sample - loss: 0.5024 - accuracy: 0.8067 - val_loss: 0.6847 - val_accuracy: 0.7333\n",
      "Epoch 248/600\n",
      "1050/1050 [==============================] - 1s 498us/sample - loss: 0.5016 - accuracy: 0.8029 - val_loss: 0.6839 - val_accuracy: 0.7400\n",
      "Epoch 249/600\n",
      "1050/1050 [==============================] - 0s 306us/sample - loss: 0.4999 - accuracy: 0.8019 - val_loss: 0.6866 - val_accuracy: 0.7400\n",
      "Epoch 250/600\n",
      "1050/1050 [==============================] - 0s 296us/sample - loss: 0.5011 - accuracy: 0.8057 - val_loss: 0.6830 - val_accuracy: 0.7400\n",
      "Epoch 251/600\n",
      "1050/1050 [==============================] - 0s 372us/sample - loss: 0.4993 - accuracy: 0.8067 - val_loss: 0.6839 - val_accuracy: 0.7311\n",
      "Epoch 252/600\n",
      "1050/1050 [==============================] - 0s 309us/sample - loss: 0.5000 - accuracy: 0.8076 - val_loss: 0.6835 - val_accuracy: 0.7333\n",
      "Epoch 253/600\n",
      "1050/1050 [==============================] - 0s 396us/sample - loss: 0.5000 - accuracy: 0.8029 - val_loss: 0.6831 - val_accuracy: 0.7467\n",
      "Epoch 254/600\n",
      "1050/1050 [==============================] - 1s 499us/sample - loss: 0.5001 - accuracy: 0.8048 - val_loss: 0.6860 - val_accuracy: 0.7333\n",
      "Epoch 255/600\n",
      "1050/1050 [==============================] - 0s 335us/sample - loss: 0.4992 - accuracy: 0.8095 - val_loss: 0.6837 - val_accuracy: 0.7356\n",
      "Epoch 256/600\n",
      "1050/1050 [==============================] - 0s 247us/sample - loss: 0.4993 - accuracy: 0.8048 - val_loss: 0.6836 - val_accuracy: 0.7400\n",
      "Epoch 257/600\n",
      "1050/1050 [==============================] - 0s 280us/sample - loss: 0.4990 - accuracy: 0.8086 - val_loss: 0.6859 - val_accuracy: 0.7244\n",
      "Epoch 258/600\n",
      "1050/1050 [==============================] - 0s 261us/sample - loss: 0.4984 - accuracy: 0.8038 - val_loss: 0.6823 - val_accuracy: 0.7444\n",
      "Epoch 259/600\n",
      "1050/1050 [==============================] - 0s 259us/sample - loss: 0.4972 - accuracy: 0.8067 - val_loss: 0.6826 - val_accuracy: 0.7333\n",
      "Epoch 260/600\n",
      "1050/1050 [==============================] - 0s 285us/sample - loss: 0.4993 - accuracy: 0.8086 - val_loss: 0.6863 - val_accuracy: 0.7356\n",
      "Epoch 261/600\n",
      "1050/1050 [==============================] - 0s 345us/sample - loss: 0.4966 - accuracy: 0.8019 - val_loss: 0.6842 - val_accuracy: 0.7533\n",
      "Epoch 262/600\n",
      "1050/1050 [==============================] - 0s 339us/sample - loss: 0.4977 - accuracy: 0.8076 - val_loss: 0.6853 - val_accuracy: 0.7311\n",
      "Epoch 263/600\n",
      "1050/1050 [==============================] - ETA: 0s - loss: 0.4950 - accuracy: 0.80 - 0s 388us/sample - loss: 0.4987 - accuracy: 0.8038 - val_loss: 0.6864 - val_accuracy: 0.7400\n",
      "Epoch 264/600\n",
      "1050/1050 [==============================] - 0s 356us/sample - loss: 0.4974 - accuracy: 0.8038 - val_loss: 0.6838 - val_accuracy: 0.7400\n",
      "Epoch 265/600\n",
      "1050/1050 [==============================] - 1s 500us/sample - loss: 0.4963 - accuracy: 0.8038 - val_loss: 0.6853 - val_accuracy: 0.7356\n",
      "Epoch 266/600\n",
      "1050/1050 [==============================] - 0s 266us/sample - loss: 0.4957 - accuracy: 0.8105 - val_loss: 0.6833 - val_accuracy: 0.7333\n",
      "Epoch 267/600\n",
      "1050/1050 [==============================] - 0s 387us/sample - loss: 0.4970 - accuracy: 0.8076 - val_loss: 0.6862 - val_accuracy: 0.7356\n",
      "Epoch 268/600\n",
      "1050/1050 [==============================] - 0s 306us/sample - loss: 0.4958 - accuracy: 0.8057 - val_loss: 0.6848 - val_accuracy: 0.7333\n",
      "Epoch 269/600\n",
      "1050/1050 [==============================] - 0s 403us/sample - loss: 0.4973 - accuracy: 0.8076 - val_loss: 0.6836 - val_accuracy: 0.7356\n",
      "Epoch 270/600\n",
      "1050/1050 [==============================] - 0s 351us/sample - loss: 0.4965 - accuracy: 0.8048 - val_loss: 0.6860 - val_accuracy: 0.7422\n",
      "Epoch 271/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 0s 289us/sample - loss: 0.4971 - accuracy: 0.8067 - val_loss: 0.6882 - val_accuracy: 0.7311\n",
      "Epoch 272/600\n",
      "1050/1050 [==============================] - 0s 338us/sample - loss: 0.4960 - accuracy: 0.8038 - val_loss: 0.6847 - val_accuracy: 0.7422\n",
      "Epoch 273/600\n",
      "1050/1050 [==============================] - 0s 234us/sample - loss: 0.4975 - accuracy: 0.8105 - val_loss: 0.6856 - val_accuracy: 0.7311\n",
      "Epoch 274/600\n",
      "1050/1050 [==============================] - 0s 308us/sample - loss: 0.4951 - accuracy: 0.8076 - val_loss: 0.6849 - val_accuracy: 0.7511\n",
      "Epoch 275/600\n",
      "1050/1050 [==============================] - 0s 298us/sample - loss: 0.4952 - accuracy: 0.8029 - val_loss: 0.6875 - val_accuracy: 0.7378\n",
      "Epoch 276/600\n",
      "1050/1050 [==============================] - 0s 242us/sample - loss: 0.4954 - accuracy: 0.8086 - val_loss: 0.6861 - val_accuracy: 0.7378\n",
      "Epoch 277/600\n",
      "1050/1050 [==============================] - 0s 204us/sample - loss: 0.4954 - accuracy: 0.8057 - val_loss: 0.6863 - val_accuracy: 0.7378\n",
      "Epoch 278/600\n",
      "1050/1050 [==============================] - 0s 283us/sample - loss: 0.4964 - accuracy: 0.8076 - val_loss: 0.6856 - val_accuracy: 0.7356\n",
      "Epoch 279/600\n",
      "1050/1050 [==============================] - 0s 362us/sample - loss: 0.4957 - accuracy: 0.8010 - val_loss: 0.6881 - val_accuracy: 0.7444\n",
      "Epoch 280/600\n",
      "1050/1050 [==============================] - 0s 343us/sample - loss: 0.4955 - accuracy: 0.8057 - val_loss: 0.6867 - val_accuracy: 0.7333\n",
      "Epoch 281/600\n",
      "1050/1050 [==============================] - 0s 327us/sample - loss: 0.4941 - accuracy: 0.8114 - val_loss: 0.6848 - val_accuracy: 0.7356\n",
      "Epoch 282/600\n",
      "1050/1050 [==============================] - 0s 253us/sample - loss: 0.4967 - accuracy: 0.8010 - val_loss: 0.6903 - val_accuracy: 0.7444\n",
      "Epoch 283/600\n",
      "1050/1050 [==============================] - 0s 417us/sample - loss: 0.4945 - accuracy: 0.8038 - val_loss: 0.6868 - val_accuracy: 0.7400\n",
      "Epoch 284/600\n",
      "1050/1050 [==============================] - 0s 367us/sample - loss: 0.4932 - accuracy: 0.8086 - val_loss: 0.6874 - val_accuracy: 0.7333\n",
      "Epoch 285/600\n",
      "1050/1050 [==============================] - 0s 332us/sample - loss: 0.4937 - accuracy: 0.8124 - val_loss: 0.6871 - val_accuracy: 0.7400\n",
      "Epoch 286/600\n",
      "1050/1050 [==============================] - 0s 252us/sample - loss: 0.4930 - accuracy: 0.8038 - val_loss: 0.6846 - val_accuracy: 0.7467\n",
      "Epoch 287/600\n",
      "1050/1050 [==============================] - 0s 237us/sample - loss: 0.4944 - accuracy: 0.8029 - val_loss: 0.6859 - val_accuracy: 0.7400\n",
      "Epoch 288/600\n",
      "1050/1050 [==============================] - 0s 199us/sample - loss: 0.4949 - accuracy: 0.8105 - val_loss: 0.6885 - val_accuracy: 0.7289\n",
      "Epoch 289/600\n",
      "1050/1050 [==============================] - 0s 274us/sample - loss: 0.4936 - accuracy: 0.8095 - val_loss: 0.6872 - val_accuracy: 0.7422\n",
      "Epoch 290/600\n",
      "1050/1050 [==============================] - 0s 323us/sample - loss: 0.4944 - accuracy: 0.8048 - val_loss: 0.6866 - val_accuracy: 0.7378\n",
      "Epoch 291/600\n",
      "1050/1050 [==============================] - 0s 347us/sample - loss: 0.4928 - accuracy: 0.8057 - val_loss: 0.6876 - val_accuracy: 0.7400\n",
      "Epoch 292/600\n",
      "1050/1050 [==============================] - 0s 331us/sample - loss: 0.4947 - accuracy: 0.8048 - val_loss: 0.6893 - val_accuracy: 0.7378\n",
      "Epoch 293/600\n",
      "1050/1050 [==============================] - 0s 357us/sample - loss: 0.4948 - accuracy: 0.8086 - val_loss: 0.6902 - val_accuracy: 0.7356\n",
      "Epoch 294/600\n",
      "1050/1050 [==============================] - 0s 356us/sample - loss: 0.4946 - accuracy: 0.8067 - val_loss: 0.6894 - val_accuracy: 0.7378\n",
      "Epoch 295/600\n",
      "1050/1050 [==============================] - 0s 242us/sample - loss: 0.4922 - accuracy: 0.8048 - val_loss: 0.6896 - val_accuracy: 0.7356\n",
      "Epoch 296/600\n",
      "1050/1050 [==============================] - 0s 277us/sample - loss: 0.4939 - accuracy: 0.8019 - val_loss: 0.6916 - val_accuracy: 0.7356\n",
      "Epoch 297/600\n",
      "1050/1050 [==============================] - ETA: 0s - loss: 0.5031 - accuracy: 0.81 - 0s 385us/sample - loss: 0.4942 - accuracy: 0.8114 - val_loss: 0.6883 - val_accuracy: 0.7333\n",
      "Epoch 298/600\n",
      "1050/1050 [==============================] - 0s 304us/sample - loss: 0.4918 - accuracy: 0.8048 - val_loss: 0.6884 - val_accuracy: 0.7444\n",
      "Epoch 299/600\n",
      "1050/1050 [==============================] - 0s 302us/sample - loss: 0.4937 - accuracy: 0.8010 - val_loss: 0.6937 - val_accuracy: 0.7400\n",
      "Epoch 300/600\n",
      "1050/1050 [==============================] - 0s 268us/sample - loss: 0.4932 - accuracy: 0.8152 - val_loss: 0.6881 - val_accuracy: 0.7333\n",
      "Epoch 301/600\n",
      "1050/1050 [==============================] - 0s 239us/sample - loss: 0.4945 - accuracy: 0.8029 - val_loss: 0.6883 - val_accuracy: 0.7444\n",
      "Epoch 302/600\n",
      "1050/1050 [==============================] - 0s 215us/sample - loss: 0.4925 - accuracy: 0.8086 - val_loss: 0.6869 - val_accuracy: 0.7333\n",
      "Epoch 303/600\n",
      "1050/1050 [==============================] - 0s 278us/sample - loss: 0.4921 - accuracy: 0.8095 - val_loss: 0.6885 - val_accuracy: 0.7400\n",
      "Epoch 304/600\n",
      "1050/1050 [==============================] - 0s 201us/sample - loss: 0.4913 - accuracy: 0.8029 - val_loss: 0.6875 - val_accuracy: 0.7378\n",
      "Epoch 305/600\n",
      "1050/1050 [==============================] - 0s 258us/sample - loss: 0.4925 - accuracy: 0.8095 - val_loss: 0.6897 - val_accuracy: 0.7356\n",
      "Epoch 306/600\n",
      "1050/1050 [==============================] - 0s 275us/sample - loss: 0.4920 - accuracy: 0.8019 - val_loss: 0.6871 - val_accuracy: 0.7444\n",
      "Epoch 307/600\n",
      "1050/1050 [==============================] - 0s 237us/sample - loss: 0.4924 - accuracy: 0.8076 - val_loss: 0.6879 - val_accuracy: 0.7378\n",
      "Epoch 308/600\n",
      "1050/1050 [==============================] - 0s 273us/sample - loss: 0.4913 - accuracy: 0.8076 - val_loss: 0.6861 - val_accuracy: 0.7400\n",
      "Epoch 309/600\n",
      "1050/1050 [==============================] - 0s 252us/sample - loss: 0.4921 - accuracy: 0.8019 - val_loss: 0.6887 - val_accuracy: 0.7333\n",
      "Epoch 310/600\n",
      "1050/1050 [==============================] - 0s 199us/sample - loss: 0.4897 - accuracy: 0.8067 - val_loss: 0.6912 - val_accuracy: 0.7400\n",
      "Epoch 311/600\n",
      "1050/1050 [==============================] - 0s 239us/sample - loss: 0.4903 - accuracy: 0.8067 - val_loss: 0.6882 - val_accuracy: 0.7400\n",
      "Epoch 312/600\n",
      "1050/1050 [==============================] - 0s 315us/sample - loss: 0.4914 - accuracy: 0.8010 - val_loss: 0.6889 - val_accuracy: 0.7289\n",
      "Epoch 313/600\n",
      "1050/1050 [==============================] - 0s 299us/sample - loss: 0.4908 - accuracy: 0.8105 - val_loss: 0.6896 - val_accuracy: 0.7311\n",
      "Epoch 314/600\n",
      "1050/1050 [==============================] - 0s 348us/sample - loss: 0.4913 - accuracy: 0.8067 - val_loss: 0.6870 - val_accuracy: 0.7400\n",
      "Epoch 315/600\n",
      "1050/1050 [==============================] - 0s 248us/sample - loss: 0.4906 - accuracy: 0.8105 - val_loss: 0.6896 - val_accuracy: 0.7378\n",
      "Epoch 316/600\n",
      "1050/1050 [==============================] - 0s 224us/sample - loss: 0.4915 - accuracy: 0.8067 - val_loss: 0.6889 - val_accuracy: 0.7400\n",
      "Epoch 317/600\n",
      "1050/1050 [==============================] - 0s 224us/sample - loss: 0.4933 - accuracy: 0.8019 - val_loss: 0.6901 - val_accuracy: 0.7378\n",
      "Epoch 318/600\n",
      "1050/1050 [==============================] - 0s 267us/sample - loss: 0.4904 - accuracy: 0.8095 - val_loss: 0.6907 - val_accuracy: 0.7356\n",
      "Epoch 319/600\n",
      "1050/1050 [==============================] - 0s 285us/sample - loss: 0.4919 - accuracy: 0.8038 - val_loss: 0.6848 - val_accuracy: 0.7422\n",
      "Epoch 320/600\n",
      "1050/1050 [==============================] - 0s 379us/sample - loss: 0.4903 - accuracy: 0.8010 - val_loss: 0.6869 - val_accuracy: 0.7378\n",
      "Epoch 321/600\n",
      "1050/1050 [==============================] - 0s 280us/sample - loss: 0.4895 - accuracy: 0.8086 - val_loss: 0.6905 - val_accuracy: 0.7400\n",
      "Epoch 322/600\n",
      "1050/1050 [==============================] - 0s 264us/sample - loss: 0.4924 - accuracy: 0.8019 - val_loss: 0.6891 - val_accuracy: 0.7422\n",
      "Epoch 323/600\n",
      "1050/1050 [==============================] - 0s 285us/sample - loss: 0.4876 - accuracy: 0.8095 - val_loss: 0.6886 - val_accuracy: 0.7378\n",
      "Epoch 324/600\n",
      "1050/1050 [==============================] - 0s 297us/sample - loss: 0.4898 - accuracy: 0.8038 - val_loss: 0.6915 - val_accuracy: 0.7356\n",
      "Epoch 325/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 0s 246us/sample - loss: 0.4877 - accuracy: 0.8095 - val_loss: 0.6898 - val_accuracy: 0.7400\n",
      "Epoch 326/600\n",
      "1050/1050 [==============================] - 0s 229us/sample - loss: 0.4894 - accuracy: 0.8086 - val_loss: 0.6875 - val_accuracy: 0.7378\n",
      "Epoch 327/600\n",
      "1050/1050 [==============================] - 0s 241us/sample - loss: 0.4877 - accuracy: 0.8086 - val_loss: 0.6876 - val_accuracy: 0.7333\n",
      "Epoch 328/600\n",
      "1050/1050 [==============================] - 0s 275us/sample - loss: 0.4887 - accuracy: 0.8000 - val_loss: 0.6888 - val_accuracy: 0.7400\n",
      "Epoch 329/600\n",
      "1050/1050 [==============================] - 0s 227us/sample - loss: 0.4893 - accuracy: 0.8057 - val_loss: 0.6912 - val_accuracy: 0.7422\n",
      "Epoch 330/600\n",
      "1050/1050 [==============================] - 0s 242us/sample - loss: 0.4869 - accuracy: 0.8076 - val_loss: 0.6899 - val_accuracy: 0.7333\n",
      "Epoch 331/600\n",
      "1050/1050 [==============================] - 0s 274us/sample - loss: 0.4873 - accuracy: 0.8019 - val_loss: 0.6927 - val_accuracy: 0.7333\n",
      "Epoch 332/600\n",
      "1050/1050 [==============================] - 0s 297us/sample - loss: 0.4878 - accuracy: 0.8095 - val_loss: 0.6943 - val_accuracy: 0.7400\n",
      "Epoch 333/600\n",
      "1050/1050 [==============================] - 0s 227us/sample - loss: 0.4883 - accuracy: 0.8076 - val_loss: 0.6916 - val_accuracy: 0.7400\n",
      "Epoch 334/600\n",
      "1050/1050 [==============================] - 0s 291us/sample - loss: 0.4886 - accuracy: 0.8076 - val_loss: 0.6899 - val_accuracy: 0.7378\n",
      "Epoch 335/600\n",
      "1050/1050 [==============================] - 0s 236us/sample - loss: 0.4858 - accuracy: 0.8057 - val_loss: 0.6905 - val_accuracy: 0.7356\n",
      "Epoch 336/600\n",
      "1050/1050 [==============================] - 0s 218us/sample - loss: 0.4894 - accuracy: 0.8038 - val_loss: 0.6916 - val_accuracy: 0.7400\n",
      "Epoch 337/600\n",
      "1050/1050 [==============================] - 0s 279us/sample - loss: 0.4871 - accuracy: 0.8048 - val_loss: 0.6898 - val_accuracy: 0.7400\n",
      "Epoch 338/600\n",
      "1050/1050 [==============================] - 0s 256us/sample - loss: 0.4875 - accuracy: 0.8076 - val_loss: 0.6911 - val_accuracy: 0.7356\n",
      "Epoch 339/600\n",
      "1050/1050 [==============================] - 0s 210us/sample - loss: 0.4876 - accuracy: 0.8067 - val_loss: 0.6922 - val_accuracy: 0.7422\n",
      "Epoch 340/600\n",
      "1050/1050 [==============================] - 0s 234us/sample - loss: 0.4866 - accuracy: 0.8086 - val_loss: 0.6946 - val_accuracy: 0.7378\n",
      "Epoch 341/600\n",
      "1050/1050 [==============================] - 0s 304us/sample - loss: 0.4875 - accuracy: 0.8029 - val_loss: 0.6942 - val_accuracy: 0.7378\n",
      "Epoch 342/600\n",
      "1050/1050 [==============================] - 0s 246us/sample - loss: 0.4874 - accuracy: 0.8076 - val_loss: 0.6941 - val_accuracy: 0.7422\n",
      "Epoch 343/600\n",
      "1050/1050 [==============================] - 0s 250us/sample - loss: 0.4859 - accuracy: 0.8105 - val_loss: 0.6905 - val_accuracy: 0.7400\n",
      "Epoch 344/600\n",
      "1050/1050 [==============================] - 0s 292us/sample - loss: 0.4853 - accuracy: 0.8076 - val_loss: 0.6936 - val_accuracy: 0.7378\n",
      "Epoch 345/600\n",
      "1050/1050 [==============================] - 0s 244us/sample - loss: 0.4858 - accuracy: 0.8048 - val_loss: 0.6954 - val_accuracy: 0.7422\n",
      "Epoch 346/600\n",
      "1050/1050 [==============================] - 0s 228us/sample - loss: 0.4866 - accuracy: 0.8038 - val_loss: 0.6922 - val_accuracy: 0.7356\n",
      "Epoch 347/600\n",
      "1050/1050 [==============================] - 0s 277us/sample - loss: 0.4865 - accuracy: 0.8105 - val_loss: 0.6933 - val_accuracy: 0.7378\n",
      "Epoch 348/600\n",
      "1050/1050 [==============================] - 0s 270us/sample - loss: 0.4852 - accuracy: 0.8000 - val_loss: 0.6963 - val_accuracy: 0.7467\n",
      "Epoch 349/600\n",
      "1050/1050 [==============================] - 0s 297us/sample - loss: 0.4861 - accuracy: 0.8010 - val_loss: 0.6952 - val_accuracy: 0.7400\n",
      "Epoch 350/600\n",
      "1050/1050 [==============================] - 0s 291us/sample - loss: 0.4875 - accuracy: 0.8067 - val_loss: 0.6988 - val_accuracy: 0.7400\n",
      "Epoch 351/600\n",
      "1050/1050 [==============================] - 0s 259us/sample - loss: 0.4854 - accuracy: 0.8057 - val_loss: 0.6976 - val_accuracy: 0.7444\n",
      "Epoch 352/600\n",
      "1050/1050 [==============================] - 0s 248us/sample - loss: 0.4881 - accuracy: 0.8038 - val_loss: 0.7003 - val_accuracy: 0.7356\n",
      "Epoch 353/600\n",
      "1050/1050 [==============================] - 0s 244us/sample - loss: 0.4871 - accuracy: 0.8038 - val_loss: 0.6945 - val_accuracy: 0.7378\n",
      "Epoch 354/600\n",
      "1050/1050 [==============================] - 0s 274us/sample - loss: 0.4886 - accuracy: 0.8105 - val_loss: 0.6996 - val_accuracy: 0.7444\n",
      "Epoch 355/600\n",
      "1050/1050 [==============================] - 0s 248us/sample - loss: 0.4864 - accuracy: 0.8038 - val_loss: 0.6939 - val_accuracy: 0.7400\n",
      "Epoch 356/600\n",
      "1050/1050 [==============================] - 0s 210us/sample - loss: 0.4846 - accuracy: 0.8038 - val_loss: 0.6950 - val_accuracy: 0.7400\n",
      "Epoch 357/600\n",
      "1050/1050 [==============================] - 0s 275us/sample - loss: 0.4871 - accuracy: 0.8095 - val_loss: 0.7012 - val_accuracy: 0.7400\n",
      "Epoch 358/600\n",
      "1050/1050 [==============================] - 0s 203us/sample - loss: 0.4835 - accuracy: 0.8057 - val_loss: 0.6975 - val_accuracy: 0.7422\n",
      "Epoch 359/600\n",
      "1050/1050 [==============================] - 0s 228us/sample - loss: 0.4849 - accuracy: 0.7962 - val_loss: 0.6964 - val_accuracy: 0.7333\n",
      "Epoch 360/600\n",
      "1050/1050 [==============================] - 0s 269us/sample - loss: 0.4847 - accuracy: 0.8038 - val_loss: 0.6980 - val_accuracy: 0.7400\n",
      "Epoch 361/600\n",
      "1050/1050 [==============================] - 0s 253us/sample - loss: 0.4843 - accuracy: 0.8029 - val_loss: 0.6969 - val_accuracy: 0.7356\n",
      "Epoch 362/600\n",
      "1050/1050 [==============================] - 0s 220us/sample - loss: 0.4838 - accuracy: 0.8057 - val_loss: 0.6961 - val_accuracy: 0.7422\n",
      "Epoch 363/600\n",
      "1050/1050 [==============================] - 0s 263us/sample - loss: 0.4837 - accuracy: 0.8067 - val_loss: 0.6974 - val_accuracy: 0.7378\n",
      "Epoch 364/600\n",
      "1050/1050 [==============================] - 0s 262us/sample - loss: 0.4857 - accuracy: 0.8010 - val_loss: 0.6979 - val_accuracy: 0.7356\n",
      "Epoch 365/600\n",
      "1050/1050 [==============================] - 0s 242us/sample - loss: 0.4846 - accuracy: 0.8019 - val_loss: 0.7034 - val_accuracy: 0.7356\n",
      "Epoch 366/600\n",
      "1050/1050 [==============================] - 0s 240us/sample - loss: 0.4867 - accuracy: 0.8057 - val_loss: 0.6992 - val_accuracy: 0.7400\n",
      "Epoch 367/600\n",
      "1050/1050 [==============================] - 0s 218us/sample - loss: 0.4856 - accuracy: 0.8048 - val_loss: 0.7012 - val_accuracy: 0.7333\n",
      "Epoch 368/600\n",
      "1050/1050 [==============================] - 0s 236us/sample - loss: 0.4835 - accuracy: 0.8067 - val_loss: 0.6956 - val_accuracy: 0.7400\n",
      "Epoch 369/600\n",
      "1050/1050 [==============================] - 0s 209us/sample - loss: 0.4845 - accuracy: 0.8057 - val_loss: 0.6982 - val_accuracy: 0.7422\n",
      "Epoch 370/600\n",
      "1050/1050 [==============================] - 0s 200us/sample - loss: 0.4825 - accuracy: 0.8076 - val_loss: 0.6982 - val_accuracy: 0.7444\n",
      "Epoch 371/600\n",
      "1050/1050 [==============================] - 0s 279us/sample - loss: 0.4841 - accuracy: 0.8048 - val_loss: 0.7003 - val_accuracy: 0.7400\n",
      "Epoch 372/600\n",
      "1050/1050 [==============================] - 0s 264us/sample - loss: 0.4824 - accuracy: 0.8067 - val_loss: 0.6969 - val_accuracy: 0.7444\n",
      "Epoch 373/600\n",
      "1050/1050 [==============================] - 0s 241us/sample - loss: 0.4819 - accuracy: 0.8048 - val_loss: 0.6977 - val_accuracy: 0.7333\n",
      "Epoch 374/600\n",
      "1050/1050 [==============================] - 0s 260us/sample - loss: 0.4827 - accuracy: 0.8067 - val_loss: 0.6978 - val_accuracy: 0.7400\n",
      "Epoch 375/600\n",
      "1050/1050 [==============================] - 0s 243us/sample - loss: 0.4826 - accuracy: 0.8105 - val_loss: 0.6992 - val_accuracy: 0.7378\n",
      "Epoch 376/600\n",
      "1050/1050 [==============================] - 0s 279us/sample - loss: 0.4818 - accuracy: 0.8057 - val_loss: 0.6970 - val_accuracy: 0.7400\n",
      "Epoch 377/600\n",
      "1050/1050 [==============================] - 0s 282us/sample - loss: 0.4822 - accuracy: 0.8038 - val_loss: 0.6974 - val_accuracy: 0.7378\n",
      "Epoch 378/600\n",
      "1050/1050 [==============================] - 0s 222us/sample - loss: 0.4839 - accuracy: 0.8076 - val_loss: 0.6987 - val_accuracy: 0.7333\n",
      "Epoch 379/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 0s 240us/sample - loss: 0.4825 - accuracy: 0.8076 - val_loss: 0.6960 - val_accuracy: 0.7400\n",
      "Epoch 380/600\n",
      "1050/1050 [==============================] - 0s 257us/sample - loss: 0.4811 - accuracy: 0.8086 - val_loss: 0.6991 - val_accuracy: 0.7400\n",
      "Epoch 381/600\n",
      "1050/1050 [==============================] - 0s 224us/sample - loss: 0.4835 - accuracy: 0.8114 - val_loss: 0.6971 - val_accuracy: 0.7356\n",
      "Epoch 382/600\n",
      "1050/1050 [==============================] - 0s 238us/sample - loss: 0.4825 - accuracy: 0.8038 - val_loss: 0.6970 - val_accuracy: 0.7400\n",
      "Epoch 383/600\n",
      "1050/1050 [==============================] - 0s 259us/sample - loss: 0.4810 - accuracy: 0.8057 - val_loss: 0.6992 - val_accuracy: 0.7400\n",
      "Epoch 384/600\n",
      "1050/1050 [==============================] - 0s 278us/sample - loss: 0.4814 - accuracy: 0.8076 - val_loss: 0.6998 - val_accuracy: 0.7311\n",
      "Epoch 385/600\n",
      "1050/1050 [==============================] - 0s 330us/sample - loss: 0.4814 - accuracy: 0.8095 - val_loss: 0.6972 - val_accuracy: 0.7378\n",
      "Epoch 386/600\n",
      "1050/1050 [==============================] - 0s 295us/sample - loss: 0.4841 - accuracy: 0.7990 - val_loss: 0.6972 - val_accuracy: 0.7356\n",
      "Epoch 387/600\n",
      "1050/1050 [==============================] - 0s 210us/sample - loss: 0.4818 - accuracy: 0.8124 - val_loss: 0.7003 - val_accuracy: 0.7333\n",
      "Epoch 388/600\n",
      "1050/1050 [==============================] - 0s 225us/sample - loss: 0.4803 - accuracy: 0.8067 - val_loss: 0.6996 - val_accuracy: 0.7400\n",
      "Epoch 389/600\n",
      "1050/1050 [==============================] - 0s 237us/sample - loss: 0.4806 - accuracy: 0.8095 - val_loss: 0.6989 - val_accuracy: 0.7356\n",
      "Epoch 390/600\n",
      "1050/1050 [==============================] - 0s 254us/sample - loss: 0.4806 - accuracy: 0.8114 - val_loss: 0.6992 - val_accuracy: 0.7378\n",
      "Epoch 391/600\n",
      "1050/1050 [==============================] - 0s 274us/sample - loss: 0.4804 - accuracy: 0.8095 - val_loss: 0.6982 - val_accuracy: 0.7333\n",
      "Epoch 392/600\n",
      "1050/1050 [==============================] - 0s 234us/sample - loss: 0.4824 - accuracy: 0.8076 - val_loss: 0.6990 - val_accuracy: 0.7378\n",
      "Epoch 393/600\n",
      "1050/1050 [==============================] - 0s 270us/sample - loss: 0.4820 - accuracy: 0.8057 - val_loss: 0.6949 - val_accuracy: 0.7378\n",
      "Epoch 394/600\n",
      "1050/1050 [==============================] - 0s 240us/sample - loss: 0.4797 - accuracy: 0.8076 - val_loss: 0.6963 - val_accuracy: 0.7422\n",
      "Epoch 395/600\n",
      "1050/1050 [==============================] - 0s 249us/sample - loss: 0.4818 - accuracy: 0.8067 - val_loss: 0.6960 - val_accuracy: 0.7356\n",
      "Epoch 396/600\n",
      "1050/1050 [==============================] - 0s 235us/sample - loss: 0.4840 - accuracy: 0.8105 - val_loss: 0.7008 - val_accuracy: 0.7333\n",
      "Epoch 397/600\n",
      "1050/1050 [==============================] - 0s 235us/sample - loss: 0.4828 - accuracy: 0.8067 - val_loss: 0.7000 - val_accuracy: 0.7333\n",
      "Epoch 398/600\n",
      "1050/1050 [==============================] - 0s 241us/sample - loss: 0.4825 - accuracy: 0.8000 - val_loss: 0.6983 - val_accuracy: 0.7378\n",
      "Epoch 399/600\n",
      "1050/1050 [==============================] - 0s 273us/sample - loss: 0.4809 - accuracy: 0.8076 - val_loss: 0.6983 - val_accuracy: 0.7356\n",
      "Epoch 400/600\n",
      "1050/1050 [==============================] - 0s 239us/sample - loss: 0.4803 - accuracy: 0.8105 - val_loss: 0.6999 - val_accuracy: 0.7444\n",
      "Epoch 401/600\n",
      "1050/1050 [==============================] - 0s 214us/sample - loss: 0.4790 - accuracy: 0.8086 - val_loss: 0.6979 - val_accuracy: 0.7333\n",
      "Epoch 402/600\n",
      "1050/1050 [==============================] - 0s 242us/sample - loss: 0.4796 - accuracy: 0.8086 - val_loss: 0.6968 - val_accuracy: 0.7422\n",
      "Epoch 403/600\n",
      "1050/1050 [==============================] - 0s 235us/sample - loss: 0.4805 - accuracy: 0.8086 - val_loss: 0.6999 - val_accuracy: 0.7444\n",
      "Epoch 404/600\n",
      "1050/1050 [==============================] - 0s 347us/sample - loss: 0.4789 - accuracy: 0.8076 - val_loss: 0.6994 - val_accuracy: 0.7400\n",
      "Epoch 405/600\n",
      "1050/1050 [==============================] - 0s 162us/sample - loss: 0.4791 - accuracy: 0.8048 - val_loss: 0.6984 - val_accuracy: 0.7378\n",
      "Epoch 406/600\n",
      "1050/1050 [==============================] - 0s 244us/sample - loss: 0.4804 - accuracy: 0.8114 - val_loss: 0.6974 - val_accuracy: 0.7311\n",
      "Epoch 407/600\n",
      "1050/1050 [==============================] - 0s 185us/sample - loss: 0.4792 - accuracy: 0.8105 - val_loss: 0.6973 - val_accuracy: 0.7356\n",
      "Epoch 408/600\n",
      "1050/1050 [==============================] - 0s 204us/sample - loss: 0.4807 - accuracy: 0.7990 - val_loss: 0.7004 - val_accuracy: 0.7378\n",
      "Epoch 409/600\n",
      "1050/1050 [==============================] - 0s 245us/sample - loss: 0.4791 - accuracy: 0.8029 - val_loss: 0.7030 - val_accuracy: 0.7400\n",
      "Epoch 410/600\n",
      "1050/1050 [==============================] - 0s 259us/sample - loss: 0.4792 - accuracy: 0.8086 - val_loss: 0.6967 - val_accuracy: 0.7378\n",
      "Epoch 411/600\n",
      "1050/1050 [==============================] - 0s 204us/sample - loss: 0.4794 - accuracy: 0.8057 - val_loss: 0.6986 - val_accuracy: 0.7356\n",
      "Epoch 412/600\n",
      "1050/1050 [==============================] - 0s 212us/sample - loss: 0.4780 - accuracy: 0.8086 - val_loss: 0.7004 - val_accuracy: 0.7356\n",
      "Epoch 413/600\n",
      "1050/1050 [==============================] - 0s 294us/sample - loss: 0.4789 - accuracy: 0.8095 - val_loss: 0.6991 - val_accuracy: 0.7378\n",
      "Epoch 414/600\n",
      "1050/1050 [==============================] - 0s 241us/sample - loss: 0.4785 - accuracy: 0.8105 - val_loss: 0.7008 - val_accuracy: 0.7378\n",
      "Epoch 415/600\n",
      "1050/1050 [==============================] - 0s 241us/sample - loss: 0.4788 - accuracy: 0.8076 - val_loss: 0.6998 - val_accuracy: 0.7356\n",
      "Epoch 416/600\n",
      "1050/1050 [==============================] - 0s 239us/sample - loss: 0.4800 - accuracy: 0.8000 - val_loss: 0.6989 - val_accuracy: 0.7422\n",
      "Epoch 417/600\n",
      "1050/1050 [==============================] - 0s 234us/sample - loss: 0.4788 - accuracy: 0.8048 - val_loss: 0.7016 - val_accuracy: 0.7444\n",
      "Epoch 418/600\n",
      "1050/1050 [==============================] - 0s 241us/sample - loss: 0.4810 - accuracy: 0.8133 - val_loss: 0.7014 - val_accuracy: 0.7289\n",
      "Epoch 419/600\n",
      "1050/1050 [==============================] - 0s 245us/sample - loss: 0.4787 - accuracy: 0.8095 - val_loss: 0.6972 - val_accuracy: 0.7400\n",
      "Epoch 420/600\n",
      "1050/1050 [==============================] - 0s 269us/sample - loss: 0.4806 - accuracy: 0.8010 - val_loss: 0.7017 - val_accuracy: 0.7400\n",
      "Epoch 421/600\n",
      "1050/1050 [==============================] - 0s 209us/sample - loss: 0.4842 - accuracy: 0.8048 - val_loss: 0.7073 - val_accuracy: 0.7356\n",
      "Epoch 422/600\n",
      "1050/1050 [==============================] - 0s 181us/sample - loss: 0.4786 - accuracy: 0.8086 - val_loss: 0.6991 - val_accuracy: 0.7400\n",
      "Epoch 423/600\n",
      "1050/1050 [==============================] - 0s 184us/sample - loss: 0.4795 - accuracy: 0.8048 - val_loss: 0.6988 - val_accuracy: 0.7422\n",
      "Epoch 424/600\n",
      "1050/1050 [==============================] - 0s 223us/sample - loss: 0.4784 - accuracy: 0.8038 - val_loss: 0.6999 - val_accuracy: 0.7333\n",
      "Epoch 425/600\n",
      "1050/1050 [==============================] - 0s 215us/sample - loss: 0.4770 - accuracy: 0.8038 - val_loss: 0.6992 - val_accuracy: 0.7333\n",
      "Epoch 426/600\n",
      "1050/1050 [==============================] - 0s 232us/sample - loss: 0.4791 - accuracy: 0.8067 - val_loss: 0.7001 - val_accuracy: 0.7400\n",
      "Epoch 427/600\n",
      "1050/1050 [==============================] - 0s 241us/sample - loss: 0.4775 - accuracy: 0.8143 - val_loss: 0.7008 - val_accuracy: 0.7289\n",
      "Epoch 428/600\n",
      "1050/1050 [==============================] - 0s 308us/sample - loss: 0.4781 - accuracy: 0.8038 - val_loss: 0.7035 - val_accuracy: 0.7378\n",
      "Epoch 429/600\n",
      "1050/1050 [==============================] - 0s 231us/sample - loss: 0.4775 - accuracy: 0.8105 - val_loss: 0.7019 - val_accuracy: 0.7400\n",
      "Epoch 430/600\n",
      "1050/1050 [==============================] - 0s 190us/sample - loss: 0.4770 - accuracy: 0.8124 - val_loss: 0.6999 - val_accuracy: 0.7267\n",
      "Epoch 431/600\n",
      "1050/1050 [==============================] - 0s 209us/sample - loss: 0.4772 - accuracy: 0.8048 - val_loss: 0.7018 - val_accuracy: 0.7311\n",
      "Epoch 432/600\n",
      "1050/1050 [==============================] - 0s 318us/sample - loss: 0.4769 - accuracy: 0.8086 - val_loss: 0.7014 - val_accuracy: 0.7333\n",
      "Epoch 433/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 0s 226us/sample - loss: 0.4766 - accuracy: 0.8133 - val_loss: 0.7030 - val_accuracy: 0.7289\n",
      "Epoch 434/600\n",
      "1050/1050 [==============================] - 0s 248us/sample - loss: 0.4805 - accuracy: 0.8038 - val_loss: 0.7027 - val_accuracy: 0.7311\n",
      "Epoch 435/600\n",
      "1050/1050 [==============================] - 0s 244us/sample - loss: 0.4767 - accuracy: 0.8076 - val_loss: 0.6976 - val_accuracy: 0.7333\n",
      "Epoch 436/600\n",
      "1050/1050 [==============================] - 0s 223us/sample - loss: 0.4772 - accuracy: 0.8076 - val_loss: 0.7029 - val_accuracy: 0.7400\n",
      "Epoch 437/600\n",
      "1050/1050 [==============================] - 0s 257us/sample - loss: 0.4765 - accuracy: 0.8114 - val_loss: 0.7016 - val_accuracy: 0.7311\n",
      "Epoch 438/600\n",
      "1050/1050 [==============================] - 0s 249us/sample - loss: 0.4777 - accuracy: 0.8057 - val_loss: 0.7003 - val_accuracy: 0.7444\n",
      "Epoch 439/600\n",
      "1050/1050 [==============================] - 0s 258us/sample - loss: 0.4764 - accuracy: 0.8133 - val_loss: 0.7022 - val_accuracy: 0.7311\n",
      "Epoch 440/600\n",
      "1050/1050 [==============================] - 0s 303us/sample - loss: 0.4750 - accuracy: 0.8095 - val_loss: 0.7009 - val_accuracy: 0.7333\n",
      "Epoch 441/600\n",
      "1050/1050 [==============================] - 0s 284us/sample - loss: 0.4756 - accuracy: 0.8048 - val_loss: 0.7027 - val_accuracy: 0.7311\n",
      "Epoch 442/600\n",
      "1050/1050 [==============================] - 0s 244us/sample - loss: 0.4762 - accuracy: 0.8124 - val_loss: 0.7007 - val_accuracy: 0.7311\n",
      "Epoch 443/600\n",
      "1050/1050 [==============================] - 0s 252us/sample - loss: 0.4762 - accuracy: 0.8095 - val_loss: 0.7029 - val_accuracy: 0.7311\n",
      "Epoch 444/600\n",
      "1050/1050 [==============================] - 0s 253us/sample - loss: 0.4754 - accuracy: 0.8105 - val_loss: 0.7030 - val_accuracy: 0.7378\n",
      "Epoch 445/600\n",
      "1050/1050 [==============================] - 0s 234us/sample - loss: 0.4761 - accuracy: 0.8067 - val_loss: 0.7014 - val_accuracy: 0.7356\n",
      "Epoch 446/600\n",
      "1050/1050 [==============================] - 0s 251us/sample - loss: 0.4771 - accuracy: 0.8076 - val_loss: 0.7011 - val_accuracy: 0.7311\n",
      "Epoch 447/600\n",
      "1050/1050 [==============================] - 0s 270us/sample - loss: 0.4765 - accuracy: 0.8114 - val_loss: 0.7022 - val_accuracy: 0.7311\n",
      "Epoch 448/600\n",
      "1050/1050 [==============================] - 0s 272us/sample - loss: 0.4769 - accuracy: 0.8076 - val_loss: 0.7041 - val_accuracy: 0.7289\n",
      "Epoch 449/600\n",
      "1050/1050 [==============================] - ETA: 0s - loss: 0.4798 - accuracy: 0.81 - 0s 222us/sample - loss: 0.4752 - accuracy: 0.8114 - val_loss: 0.7035 - val_accuracy: 0.7356\n",
      "Epoch 450/600\n",
      "1050/1050 [==============================] - 0s 243us/sample - loss: 0.4778 - accuracy: 0.8048 - val_loss: 0.7007 - val_accuracy: 0.7356\n",
      "Epoch 451/600\n",
      "1050/1050 [==============================] - 0s 225us/sample - loss: 0.4739 - accuracy: 0.8086 - val_loss: 0.7058 - val_accuracy: 0.7333\n",
      "Epoch 452/600\n",
      "1050/1050 [==============================] - 0s 210us/sample - loss: 0.4759 - accuracy: 0.8124 - val_loss: 0.7035 - val_accuracy: 0.7333\n",
      "Epoch 453/600\n",
      "1050/1050 [==============================] - 0s 194us/sample - loss: 0.4774 - accuracy: 0.8076 - val_loss: 0.7025 - val_accuracy: 0.7400\n",
      "Epoch 454/600\n",
      "1050/1050 [==============================] - 0s 234us/sample - loss: 0.4770 - accuracy: 0.8114 - val_loss: 0.7002 - val_accuracy: 0.7378\n",
      "Epoch 455/600\n",
      "1050/1050 [==============================] - 0s 242us/sample - loss: 0.4751 - accuracy: 0.8086 - val_loss: 0.7032 - val_accuracy: 0.7333\n",
      "Epoch 456/600\n",
      "1050/1050 [==============================] - 0s 227us/sample - loss: 0.4759 - accuracy: 0.8124 - val_loss: 0.7058 - val_accuracy: 0.7289\n",
      "Epoch 457/600\n",
      "1050/1050 [==============================] - 0s 194us/sample - loss: 0.4761 - accuracy: 0.8114 - val_loss: 0.7050 - val_accuracy: 0.7378\n",
      "Epoch 458/600\n",
      "1050/1050 [==============================] - 0s 223us/sample - loss: 0.4751 - accuracy: 0.8114 - val_loss: 0.7024 - val_accuracy: 0.7422\n",
      "Epoch 459/600\n",
      "1050/1050 [==============================] - 0s 273us/sample - loss: 0.4777 - accuracy: 0.8057 - val_loss: 0.7052 - val_accuracy: 0.7422\n",
      "Epoch 460/600\n",
      "1050/1050 [==============================] - 0s 228us/sample - loss: 0.4736 - accuracy: 0.8095 - val_loss: 0.7065 - val_accuracy: 0.7378\n",
      "Epoch 461/600\n",
      "1050/1050 [==============================] - 0s 279us/sample - loss: 0.4746 - accuracy: 0.8143 - val_loss: 0.7021 - val_accuracy: 0.7356\n",
      "Epoch 462/600\n",
      "1050/1050 [==============================] - 0s 237us/sample - loss: 0.4739 - accuracy: 0.8067 - val_loss: 0.7026 - val_accuracy: 0.7333\n",
      "Epoch 463/600\n",
      "1050/1050 [==============================] - 0s 235us/sample - loss: 0.4741 - accuracy: 0.8105 - val_loss: 0.7043 - val_accuracy: 0.7311\n",
      "Epoch 464/600\n",
      "1050/1050 [==============================] - 0s 231us/sample - loss: 0.4731 - accuracy: 0.8095 - val_loss: 0.7016 - val_accuracy: 0.7311\n",
      "Epoch 465/600\n",
      "1050/1050 [==============================] - 0s 275us/sample - loss: 0.4755 - accuracy: 0.8095 - val_loss: 0.7040 - val_accuracy: 0.7356\n",
      "Epoch 466/600\n",
      "1050/1050 [==============================] - 0s 264us/sample - loss: 0.4760 - accuracy: 0.8095 - val_loss: 0.7061 - val_accuracy: 0.7356\n",
      "Epoch 467/600\n",
      "1050/1050 [==============================] - 0s 290us/sample - loss: 0.4783 - accuracy: 0.8057 - val_loss: 0.7041 - val_accuracy: 0.7422\n",
      "Epoch 468/600\n",
      "1050/1050 [==============================] - 0s 243us/sample - loss: 0.4758 - accuracy: 0.8114 - val_loss: 0.7068 - val_accuracy: 0.7289\n",
      "Epoch 469/600\n",
      "1050/1050 [==============================] - 0s 241us/sample - loss: 0.4738 - accuracy: 0.8105 - val_loss: 0.7065 - val_accuracy: 0.7311\n",
      "Epoch 470/600\n",
      "1050/1050 [==============================] - 0s 324us/sample - loss: 0.4743 - accuracy: 0.8067 - val_loss: 0.7037 - val_accuracy: 0.7444\n",
      "Epoch 471/600\n",
      "1050/1050 [==============================] - 0s 209us/sample - loss: 0.4736 - accuracy: 0.8124 - val_loss: 0.7044 - val_accuracy: 0.7378\n",
      "Epoch 472/600\n",
      "1050/1050 [==============================] - 0s 239us/sample - loss: 0.4748 - accuracy: 0.8105 - val_loss: 0.7072 - val_accuracy: 0.7400\n",
      "Epoch 473/600\n",
      "1050/1050 [==============================] - 0s 230us/sample - loss: 0.4743 - accuracy: 0.8105 - val_loss: 0.7050 - val_accuracy: 0.7311\n",
      "Epoch 474/600\n",
      "1050/1050 [==============================] - 0s 222us/sample - loss: 0.4741 - accuracy: 0.8067 - val_loss: 0.7028 - val_accuracy: 0.7356\n",
      "Epoch 475/600\n",
      "1050/1050 [==============================] - 0s 250us/sample - loss: 0.4743 - accuracy: 0.8086 - val_loss: 0.7071 - val_accuracy: 0.7356\n",
      "Epoch 476/600\n",
      "1050/1050 [==============================] - 0s 250us/sample - loss: 0.4747 - accuracy: 0.8095 - val_loss: 0.7061 - val_accuracy: 0.7333\n",
      "Epoch 477/600\n",
      "1050/1050 [==============================] - 0s 243us/sample - loss: 0.4746 - accuracy: 0.8095 - val_loss: 0.7050 - val_accuracy: 0.7378\n",
      "Epoch 478/600\n",
      "1050/1050 [==============================] - 0s 231us/sample - loss: 0.4752 - accuracy: 0.8095 - val_loss: 0.7028 - val_accuracy: 0.7356\n",
      "Epoch 479/600\n",
      "1050/1050 [==============================] - 0s 248us/sample - loss: 0.4736 - accuracy: 0.8057 - val_loss: 0.7075 - val_accuracy: 0.7422\n",
      "Epoch 480/600\n",
      "1050/1050 [==============================] - 0s 321us/sample - loss: 0.4757 - accuracy: 0.8048 - val_loss: 0.7071 - val_accuracy: 0.7333\n",
      "Epoch 481/600\n",
      "1050/1050 [==============================] - 0s 212us/sample - loss: 0.4727 - accuracy: 0.8095 - val_loss: 0.7041 - val_accuracy: 0.7356\n",
      "Epoch 482/600\n",
      "1050/1050 [==============================] - 0s 234us/sample - loss: 0.4732 - accuracy: 0.8133 - val_loss: 0.7082 - val_accuracy: 0.7356\n",
      "Epoch 483/600\n",
      "1050/1050 [==============================] - 0s 263us/sample - loss: 0.4739 - accuracy: 0.8086 - val_loss: 0.7072 - val_accuracy: 0.7356\n",
      "Epoch 484/600\n",
      "1050/1050 [==============================] - 0s 236us/sample - loss: 0.4752 - accuracy: 0.8086 - val_loss: 0.7099 - val_accuracy: 0.7333\n",
      "Epoch 485/600\n",
      "1050/1050 [==============================] - 0s 226us/sample - loss: 0.4744 - accuracy: 0.8105 - val_loss: 0.7057 - val_accuracy: 0.7467\n",
      "Epoch 486/600\n",
      "1050/1050 [==============================] - 0s 241us/sample - loss: 0.4736 - accuracy: 0.8038 - val_loss: 0.7042 - val_accuracy: 0.7400\n",
      "Epoch 487/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 0s 291us/sample - loss: 0.4736 - accuracy: 0.8124 - val_loss: 0.7044 - val_accuracy: 0.7356\n",
      "Epoch 488/600\n",
      "1050/1050 [==============================] - 0s 226us/sample - loss: 0.4743 - accuracy: 0.8095 - val_loss: 0.7064 - val_accuracy: 0.7422\n",
      "Epoch 489/600\n",
      "1050/1050 [==============================] - 0s 255us/sample - loss: 0.4722 - accuracy: 0.8076 - val_loss: 0.7072 - val_accuracy: 0.7400\n",
      "Epoch 490/600\n",
      "1050/1050 [==============================] - 0s 317us/sample - loss: 0.4748 - accuracy: 0.8095 - val_loss: 0.7058 - val_accuracy: 0.7422\n",
      "Epoch 491/600\n",
      "1050/1050 [==============================] - 0s 242us/sample - loss: 0.4751 - accuracy: 0.8133 - val_loss: 0.7062 - val_accuracy: 0.7311\n",
      "Epoch 492/600\n",
      "1050/1050 [==============================] - 0s 236us/sample - loss: 0.4738 - accuracy: 0.8114 - val_loss: 0.7055 - val_accuracy: 0.7311\n",
      "Epoch 493/600\n",
      "1050/1050 [==============================] - 0s 274us/sample - loss: 0.4726 - accuracy: 0.8152 - val_loss: 0.7095 - val_accuracy: 0.7378\n",
      "Epoch 494/600\n",
      "1050/1050 [==============================] - 0s 277us/sample - loss: 0.4734 - accuracy: 0.8086 - val_loss: 0.7080 - val_accuracy: 0.7400\n",
      "Epoch 495/600\n",
      "1050/1050 [==============================] - 0s 242us/sample - loss: 0.4772 - accuracy: 0.8133 - val_loss: 0.7063 - val_accuracy: 0.7333\n",
      "Epoch 496/600\n",
      "1050/1050 [==============================] - 0s 225us/sample - loss: 0.4724 - accuracy: 0.8086 - val_loss: 0.7055 - val_accuracy: 0.7400\n",
      "Epoch 497/600\n",
      "1050/1050 [==============================] - 0s 283us/sample - loss: 0.4737 - accuracy: 0.8076 - val_loss: 0.7081 - val_accuracy: 0.7356\n",
      "Epoch 498/600\n",
      "1050/1050 [==============================] - 0s 264us/sample - loss: 0.4725 - accuracy: 0.8114 - val_loss: 0.7053 - val_accuracy: 0.7378\n",
      "Epoch 499/600\n",
      "1050/1050 [==============================] - 0s 250us/sample - loss: 0.4733 - accuracy: 0.8048 - val_loss: 0.7038 - val_accuracy: 0.7400\n",
      "Epoch 500/600\n",
      "1050/1050 [==============================] - 0s 269us/sample - loss: 0.4724 - accuracy: 0.8086 - val_loss: 0.7071 - val_accuracy: 0.7333\n",
      "Epoch 501/600\n",
      "1050/1050 [==============================] - 0s 224us/sample - loss: 0.4732 - accuracy: 0.8124 - val_loss: 0.7083 - val_accuracy: 0.7444\n",
      "Epoch 502/600\n",
      "1050/1050 [==============================] - 0s 227us/sample - loss: 0.4718 - accuracy: 0.8133 - val_loss: 0.7054 - val_accuracy: 0.7444\n",
      "Epoch 503/600\n",
      "1050/1050 [==============================] - 0s 245us/sample - loss: 0.4730 - accuracy: 0.8086 - val_loss: 0.7070 - val_accuracy: 0.7311\n",
      "Epoch 504/600\n",
      "1050/1050 [==============================] - 0s 237us/sample - loss: 0.4735 - accuracy: 0.8133 - val_loss: 0.7079 - val_accuracy: 0.7333\n",
      "Epoch 505/600\n",
      "1050/1050 [==============================] - 0s 219us/sample - loss: 0.4726 - accuracy: 0.8124 - val_loss: 0.7049 - val_accuracy: 0.7333\n",
      "Epoch 506/600\n",
      "1050/1050 [==============================] - 0s 224us/sample - loss: 0.4736 - accuracy: 0.8086 - val_loss: 0.7087 - val_accuracy: 0.7422\n",
      "Epoch 507/600\n",
      "1050/1050 [==============================] - 0s 230us/sample - loss: 0.4726 - accuracy: 0.8086 - val_loss: 0.7043 - val_accuracy: 0.7311\n",
      "Epoch 508/600\n",
      "1050/1050 [==============================] - 0s 287us/sample - loss: 0.4740 - accuracy: 0.8086 - val_loss: 0.7084 - val_accuracy: 0.7378\n",
      "Epoch 509/600\n",
      "1050/1050 [==============================] - 0s 243us/sample - loss: 0.4730 - accuracy: 0.8114 - val_loss: 0.7076 - val_accuracy: 0.7400\n",
      "Epoch 510/600\n",
      "1050/1050 [==============================] - 0s 211us/sample - loss: 0.4726 - accuracy: 0.8086 - val_loss: 0.7062 - val_accuracy: 0.7422\n",
      "Epoch 511/600\n",
      "1050/1050 [==============================] - 0s 241us/sample - loss: 0.4719 - accuracy: 0.8105 - val_loss: 0.7077 - val_accuracy: 0.7400\n",
      "Epoch 512/600\n",
      "1050/1050 [==============================] - 0s 261us/sample - loss: 0.4743 - accuracy: 0.8076 - val_loss: 0.7086 - val_accuracy: 0.7400\n",
      "Epoch 513/600\n",
      "1050/1050 [==============================] - 0s 249us/sample - loss: 0.4719 - accuracy: 0.8143 - val_loss: 0.7085 - val_accuracy: 0.7378\n",
      "Epoch 514/600\n",
      "1050/1050 [==============================] - 0s 298us/sample - loss: 0.4761 - accuracy: 0.8057 - val_loss: 0.7071 - val_accuracy: 0.7444\n",
      "Epoch 515/600\n",
      "1050/1050 [==============================] - 0s 256us/sample - loss: 0.4724 - accuracy: 0.8086 - val_loss: 0.7103 - val_accuracy: 0.7333\n",
      "Epoch 516/600\n",
      "1050/1050 [==============================] - 0s 256us/sample - loss: 0.4725 - accuracy: 0.8171 - val_loss: 0.7110 - val_accuracy: 0.7333\n",
      "Epoch 517/600\n",
      "1050/1050 [==============================] - 0s 273us/sample - loss: 0.4721 - accuracy: 0.8124 - val_loss: 0.7049 - val_accuracy: 0.7400\n",
      "Epoch 518/600\n",
      "1050/1050 [==============================] - 0s 282us/sample - loss: 0.4727 - accuracy: 0.8086 - val_loss: 0.7070 - val_accuracy: 0.7400\n",
      "Epoch 519/600\n",
      "1050/1050 [==============================] - 0s 234us/sample - loss: 0.4730 - accuracy: 0.8095 - val_loss: 0.7076 - val_accuracy: 0.7400\n",
      "Epoch 520/600\n",
      "1050/1050 [==============================] - 0s 258us/sample - loss: 0.4719 - accuracy: 0.8143 - val_loss: 0.7116 - val_accuracy: 0.7400\n",
      "Epoch 521/600\n",
      "1050/1050 [==============================] - 0s 297us/sample - loss: 0.4750 - accuracy: 0.8076 - val_loss: 0.7077 - val_accuracy: 0.7333\n",
      "Epoch 522/600\n",
      "1050/1050 [==============================] - 0s 249us/sample - loss: 0.4717 - accuracy: 0.8095 - val_loss: 0.7087 - val_accuracy: 0.7356\n",
      "Epoch 523/600\n",
      "1050/1050 [==============================] - 0s 229us/sample - loss: 0.4713 - accuracy: 0.8133 - val_loss: 0.7070 - val_accuracy: 0.7422\n",
      "Epoch 524/600\n",
      "1050/1050 [==============================] - 0s 220us/sample - loss: 0.4738 - accuracy: 0.8114 - val_loss: 0.7091 - val_accuracy: 0.7333\n",
      "Epoch 525/600\n",
      "1050/1050 [==============================] - 0s 303us/sample - loss: 0.4708 - accuracy: 0.8124 - val_loss: 0.7073 - val_accuracy: 0.7356\n",
      "Epoch 526/600\n",
      "1050/1050 [==============================] - 0s 235us/sample - loss: 0.4728 - accuracy: 0.8124 - val_loss: 0.7107 - val_accuracy: 0.7333\n",
      "Epoch 527/600\n",
      "1050/1050 [==============================] - 0s 187us/sample - loss: 0.4738 - accuracy: 0.8086 - val_loss: 0.7099 - val_accuracy: 0.7333\n",
      "Epoch 528/600\n",
      "1050/1050 [==============================] - 0s 201us/sample - loss: 0.4724 - accuracy: 0.8124 - val_loss: 0.7160 - val_accuracy: 0.7333\n",
      "Epoch 529/600\n",
      "1050/1050 [==============================] - 0s 222us/sample - loss: 0.4719 - accuracy: 0.8105 - val_loss: 0.7068 - val_accuracy: 0.7400\n",
      "Epoch 530/600\n",
      "1050/1050 [==============================] - 0s 244us/sample - loss: 0.4730 - accuracy: 0.8133 - val_loss: 0.7077 - val_accuracy: 0.7356\n",
      "Epoch 531/600\n",
      "1050/1050 [==============================] - 0s 284us/sample - loss: 0.4709 - accuracy: 0.8076 - val_loss: 0.7081 - val_accuracy: 0.7400\n",
      "Epoch 532/600\n",
      "1050/1050 [==============================] - 0s 233us/sample - loss: 0.4731 - accuracy: 0.8143 - val_loss: 0.7103 - val_accuracy: 0.7356\n",
      "Epoch 533/600\n",
      "1050/1050 [==============================] - 0s 251us/sample - loss: 0.4709 - accuracy: 0.8124 - val_loss: 0.7090 - val_accuracy: 0.7422\n",
      "Epoch 534/600\n",
      "1050/1050 [==============================] - 0s 233us/sample - loss: 0.4709 - accuracy: 0.8124 - val_loss: 0.7072 - val_accuracy: 0.7356\n",
      "Epoch 535/600\n",
      "1050/1050 [==============================] - 0s 234us/sample - loss: 0.4724 - accuracy: 0.8124 - val_loss: 0.7108 - val_accuracy: 0.7400\n",
      "Epoch 536/600\n",
      "1050/1050 [==============================] - 0s 282us/sample - loss: 0.4707 - accuracy: 0.8095 - val_loss: 0.7084 - val_accuracy: 0.7333\n",
      "Epoch 537/600\n",
      "1050/1050 [==============================] - 0s 241us/sample - loss: 0.4702 - accuracy: 0.8143 - val_loss: 0.7103 - val_accuracy: 0.7378\n",
      "Epoch 538/600\n",
      "1050/1050 [==============================] - 0s 227us/sample - loss: 0.4718 - accuracy: 0.8114 - val_loss: 0.7100 - val_accuracy: 0.7422\n",
      "Epoch 539/600\n",
      "1050/1050 [==============================] - 0s 231us/sample - loss: 0.4715 - accuracy: 0.8124 - val_loss: 0.7064 - val_accuracy: 0.7444\n",
      "Epoch 540/600\n",
      "1050/1050 [==============================] - 0s 319us/sample - loss: 0.4720 - accuracy: 0.8086 - val_loss: 0.7094 - val_accuracy: 0.7356\n",
      "Epoch 541/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 0s 235us/sample - loss: 0.4720 - accuracy: 0.8143 - val_loss: 0.7147 - val_accuracy: 0.7289\n",
      "Epoch 542/600\n",
      "1050/1050 [==============================] - 0s 266us/sample - loss: 0.4721 - accuracy: 0.8124 - val_loss: 0.7062 - val_accuracy: 0.7422\n",
      "Epoch 543/600\n",
      "1050/1050 [==============================] - 0s 290us/sample - loss: 0.4705 - accuracy: 0.8067 - val_loss: 0.7076 - val_accuracy: 0.7356\n",
      "Epoch 544/600\n",
      "1050/1050 [==============================] - 0s 268us/sample - loss: 0.4706 - accuracy: 0.8095 - val_loss: 0.7078 - val_accuracy: 0.7422\n",
      "Epoch 545/600\n",
      "1050/1050 [==============================] - 0s 244us/sample - loss: 0.4712 - accuracy: 0.8095 - val_loss: 0.7106 - val_accuracy: 0.7333\n",
      "Epoch 546/600\n",
      "1050/1050 [==============================] - 0s 288us/sample - loss: 0.4714 - accuracy: 0.8114 - val_loss: 0.7098 - val_accuracy: 0.7400\n",
      "Epoch 547/600\n",
      "1050/1050 [==============================] - 0s 240us/sample - loss: 0.4734 - accuracy: 0.8076 - val_loss: 0.7044 - val_accuracy: 0.7400\n",
      "Epoch 548/600\n",
      "1050/1050 [==============================] - 0s 234us/sample - loss: 0.4704 - accuracy: 0.8133 - val_loss: 0.7104 - val_accuracy: 0.7400\n",
      "Epoch 549/600\n",
      "1050/1050 [==============================] - 0s 241us/sample - loss: 0.4700 - accuracy: 0.8114 - val_loss: 0.7068 - val_accuracy: 0.7444\n",
      "Epoch 550/600\n",
      "1050/1050 [==============================] - 0s 200us/sample - loss: 0.4706 - accuracy: 0.8105 - val_loss: 0.7080 - val_accuracy: 0.7400\n",
      "Epoch 551/600\n",
      "1050/1050 [==============================] - 0s 219us/sample - loss: 0.4707 - accuracy: 0.8105 - val_loss: 0.7103 - val_accuracy: 0.7400\n",
      "Epoch 552/600\n",
      "1050/1050 [==============================] - 0s 271us/sample - loss: 0.4693 - accuracy: 0.8086 - val_loss: 0.7066 - val_accuracy: 0.7444\n",
      "Epoch 553/600\n",
      "1050/1050 [==============================] - 0s 240us/sample - loss: 0.4709 - accuracy: 0.8143 - val_loss: 0.7096 - val_accuracy: 0.7378\n",
      "Epoch 554/600\n",
      "1050/1050 [==============================] - 0s 207us/sample - loss: 0.4737 - accuracy: 0.8086 - val_loss: 0.7037 - val_accuracy: 0.7400\n",
      "Epoch 555/600\n",
      "1050/1050 [==============================] - 0s 232us/sample - loss: 0.4749 - accuracy: 0.8133 - val_loss: 0.7112 - val_accuracy: 0.7333\n",
      "Epoch 556/600\n",
      "1050/1050 [==============================] - 0s 196us/sample - loss: 0.4716 - accuracy: 0.8086 - val_loss: 0.7075 - val_accuracy: 0.7467\n",
      "Epoch 557/600\n",
      "1050/1050 [==============================] - 0s 217us/sample - loss: 0.4703 - accuracy: 0.8114 - val_loss: 0.7068 - val_accuracy: 0.7400\n",
      "Epoch 558/600\n",
      "1050/1050 [==============================] - 0s 272us/sample - loss: 0.4746 - accuracy: 0.8133 - val_loss: 0.7075 - val_accuracy: 0.7400\n",
      "Epoch 559/600\n",
      "1050/1050 [==============================] - 0s 282us/sample - loss: 0.4718 - accuracy: 0.8086 - val_loss: 0.7059 - val_accuracy: 0.7422\n",
      "Epoch 560/600\n",
      "1050/1050 [==============================] - 0s 188us/sample - loss: 0.4692 - accuracy: 0.8095 - val_loss: 0.7088 - val_accuracy: 0.7422\n",
      "Epoch 561/600\n",
      "1050/1050 [==============================] - 0s 258us/sample - loss: 0.4698 - accuracy: 0.8095 - val_loss: 0.7060 - val_accuracy: 0.7422\n",
      "Epoch 562/600\n",
      "1050/1050 [==============================] - 0s 221us/sample - loss: 0.4689 - accuracy: 0.8105 - val_loss: 0.7066 - val_accuracy: 0.7400\n",
      "Epoch 563/600\n",
      "1050/1050 [==============================] - 0s 195us/sample - loss: 0.4705 - accuracy: 0.8143 - val_loss: 0.7067 - val_accuracy: 0.7400\n",
      "Epoch 564/600\n",
      "1050/1050 [==============================] - 0s 247us/sample - loss: 0.4696 - accuracy: 0.8162 - val_loss: 0.7051 - val_accuracy: 0.7444\n",
      "Epoch 565/600\n",
      "1050/1050 [==============================] - 0s 282us/sample - loss: 0.4736 - accuracy: 0.8133 - val_loss: 0.7082 - val_accuracy: 0.7356\n",
      "Epoch 566/600\n",
      "1050/1050 [==============================] - 0s 229us/sample - loss: 0.4706 - accuracy: 0.8095 - val_loss: 0.7057 - val_accuracy: 0.7467\n",
      "Epoch 567/600\n",
      "1050/1050 [==============================] - 0s 254us/sample - loss: 0.4701 - accuracy: 0.8143 - val_loss: 0.7096 - val_accuracy: 0.7422\n",
      "Epoch 568/600\n",
      "1050/1050 [==============================] - 0s 262us/sample - loss: 0.4702 - accuracy: 0.8133 - val_loss: 0.7039 - val_accuracy: 0.7467\n",
      "Epoch 569/600\n",
      "1050/1050 [==============================] - 0s 197us/sample - loss: 0.4676 - accuracy: 0.8105 - val_loss: 0.7061 - val_accuracy: 0.7444\n",
      "Epoch 570/600\n",
      "1050/1050 [==============================] - 0s 176us/sample - loss: 0.4681 - accuracy: 0.8133 - val_loss: 0.7048 - val_accuracy: 0.7467\n",
      "Epoch 571/600\n",
      "1050/1050 [==============================] - 0s 269us/sample - loss: 0.4690 - accuracy: 0.8162 - val_loss: 0.7061 - val_accuracy: 0.7467\n",
      "Epoch 572/600\n",
      "1050/1050 [==============================] - 0s 271us/sample - loss: 0.4682 - accuracy: 0.8133 - val_loss: 0.7051 - val_accuracy: 0.7422\n",
      "Epoch 573/600\n",
      "1050/1050 [==============================] - 0s 172us/sample - loss: 0.4683 - accuracy: 0.8133 - val_loss: 0.7027 - val_accuracy: 0.7400\n",
      "Epoch 574/600\n",
      "1050/1050 [==============================] - 0s 242us/sample - loss: 0.4696 - accuracy: 0.8133 - val_loss: 0.7038 - val_accuracy: 0.7444\n",
      "Epoch 575/600\n",
      "1050/1050 [==============================] - 0s 248us/sample - loss: 0.4690 - accuracy: 0.8067 - val_loss: 0.7058 - val_accuracy: 0.7400\n",
      "Epoch 576/600\n",
      "1050/1050 [==============================] - 0s 319us/sample - loss: 0.4678 - accuracy: 0.8152 - val_loss: 0.7066 - val_accuracy: 0.7378\n",
      "Epoch 577/600\n",
      "1050/1050 [==============================] - 0s 323us/sample - loss: 0.4689 - accuracy: 0.8095 - val_loss: 0.7058 - val_accuracy: 0.7400\n",
      "Epoch 578/600\n",
      "1050/1050 [==============================] - 0s 301us/sample - loss: 0.4681 - accuracy: 0.8143 - val_loss: 0.7053 - val_accuracy: 0.7511\n",
      "Epoch 579/600\n",
      "1050/1050 [==============================] - 0s 367us/sample - loss: 0.4689 - accuracy: 0.8133 - val_loss: 0.7041 - val_accuracy: 0.7444\n",
      "Epoch 580/600\n",
      "1050/1050 [==============================] - 0s 283us/sample - loss: 0.4682 - accuracy: 0.8114 - val_loss: 0.7058 - val_accuracy: 0.7400\n",
      "Epoch 581/600\n",
      "1050/1050 [==============================] - 0s 263us/sample - loss: 0.4675 - accuracy: 0.8105 - val_loss: 0.7069 - val_accuracy: 0.7511\n",
      "Epoch 582/600\n",
      "1050/1050 [==============================] - 0s 278us/sample - loss: 0.4680 - accuracy: 0.8162 - val_loss: 0.7074 - val_accuracy: 0.7422\n",
      "Epoch 583/600\n",
      "1050/1050 [==============================] - 0s 301us/sample - loss: 0.4689 - accuracy: 0.8105 - val_loss: 0.7036 - val_accuracy: 0.7444\n",
      "Epoch 584/600\n",
      "1050/1050 [==============================] - 0s 224us/sample - loss: 0.4680 - accuracy: 0.8124 - val_loss: 0.7048 - val_accuracy: 0.7489\n",
      "Epoch 585/600\n",
      "1050/1050 [==============================] - 0s 289us/sample - loss: 0.4680 - accuracy: 0.8095 - val_loss: 0.7059 - val_accuracy: 0.7378\n",
      "Epoch 586/600\n",
      "1050/1050 [==============================] - 0s 291us/sample - loss: 0.4701 - accuracy: 0.8133 - val_loss: 0.7059 - val_accuracy: 0.7444\n",
      "Epoch 587/600\n",
      "1050/1050 [==============================] - 0s 231us/sample - loss: 0.4696 - accuracy: 0.8095 - val_loss: 0.7029 - val_accuracy: 0.7400\n",
      "Epoch 588/600\n",
      "1050/1050 [==============================] - 0s 225us/sample - loss: 0.4688 - accuracy: 0.8133 - val_loss: 0.7070 - val_accuracy: 0.7400\n",
      "Epoch 589/600\n",
      "1050/1050 [==============================] - 0s 295us/sample - loss: 0.4688 - accuracy: 0.8124 - val_loss: 0.7065 - val_accuracy: 0.7422\n",
      "Epoch 590/600\n",
      "1050/1050 [==============================] - 0s 257us/sample - loss: 0.4684 - accuracy: 0.8105 - val_loss: 0.7064 - val_accuracy: 0.7467\n",
      "Epoch 591/600\n",
      "1050/1050 [==============================] - 0s 242us/sample - loss: 0.4687 - accuracy: 0.8057 - val_loss: 0.7071 - val_accuracy: 0.7422\n",
      "Epoch 592/600\n",
      "1050/1050 [==============================] - 0s 236us/sample - loss: 0.4684 - accuracy: 0.8133 - val_loss: 0.7093 - val_accuracy: 0.7422\n",
      "Epoch 593/600\n",
      "1050/1050 [==============================] - 0s 249us/sample - loss: 0.4706 - accuracy: 0.8114 - val_loss: 0.7075 - val_accuracy: 0.7333\n",
      "Epoch 594/600\n",
      "1050/1050 [==============================] - 0s 291us/sample - loss: 0.4694 - accuracy: 0.8181 - val_loss: 0.7042 - val_accuracy: 0.7533\n",
      "Epoch 595/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1050/1050 [==============================] - 0s 283us/sample - loss: 0.4697 - accuracy: 0.8086 - val_loss: 0.7068 - val_accuracy: 0.7467\n",
      "Epoch 596/600\n",
      "1050/1050 [==============================] - 0s 271us/sample - loss: 0.4689 - accuracy: 0.8162 - val_loss: 0.7076 - val_accuracy: 0.7400\n",
      "Epoch 597/600\n",
      "1050/1050 [==============================] - 0s 296us/sample - loss: 0.4677 - accuracy: 0.8133 - val_loss: 0.7052 - val_accuracy: 0.7422\n",
      "Epoch 598/600\n",
      "1050/1050 [==============================] - 0s 202us/sample - loss: 0.4696 - accuracy: 0.8133 - val_loss: 0.7052 - val_accuracy: 0.7422\n",
      "Epoch 599/600\n",
      "1050/1050 [==============================] - 0s 333us/sample - loss: 0.4688 - accuracy: 0.8114 - val_loss: 0.7078 - val_accuracy: 0.7378\n",
      "Epoch 600/600\n",
      "1050/1050 [==============================] - 0s 220us/sample - loss: 0.4668 - accuracy: 0.8105 - val_loss: 0.7091 - val_accuracy: 0.7400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.601224</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>1.558729</td>\n",
       "      <td>0.295556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.544933</td>\n",
       "      <td>0.295238</td>\n",
       "      <td>1.511003</td>\n",
       "      <td>0.311111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.496991</td>\n",
       "      <td>0.352381</td>\n",
       "      <td>1.463072</td>\n",
       "      <td>0.355556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.444225</td>\n",
       "      <td>0.418095</td>\n",
       "      <td>1.407857</td>\n",
       "      <td>0.426667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.381981</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>1.344153</td>\n",
       "      <td>0.464444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>0.468907</td>\n",
       "      <td>0.816190</td>\n",
       "      <td>0.707603</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>0.467697</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.705234</td>\n",
       "      <td>0.742222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>0.469571</td>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.705235</td>\n",
       "      <td>0.742222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>0.468793</td>\n",
       "      <td>0.811429</td>\n",
       "      <td>0.707770</td>\n",
       "      <td>0.737778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>0.466775</td>\n",
       "      <td>0.810476</td>\n",
       "      <td>0.709097</td>\n",
       "      <td>0.740000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         loss  accuracy  val_loss  val_accuracy\n",
       "0    1.601224  0.253333  1.558729      0.295556\n",
       "1    1.544933  0.295238  1.511003      0.311111\n",
       "2    1.496991  0.352381  1.463072      0.355556\n",
       "3    1.444225  0.418095  1.407857      0.426667\n",
       "4    1.381981  0.457143  1.344153      0.464444\n",
       "..        ...       ...       ...           ...\n",
       "595  0.468907  0.816190  0.707603      0.740000\n",
       "596  0.467697  0.813333  0.705234      0.742222\n",
       "597  0.469571  0.813333  0.705235      0.742222\n",
       "598  0.468793  0.811429  0.707770      0.737778\n",
       "599  0.466775  0.810476  0.709097      0.740000\n",
       "\n",
       "[600 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The following variables are the hyperparameters.\n",
    "learning_rate = 0.003\n",
    "epochs = 600\n",
    "batch_size = round(train_df.shape[0] * 0.05)\n",
    "validation_split = 0.2\n",
    "\n",
    "# Establish the model's topography.\n",
    "my_model = create_model(learning_rate, feature_layer)\n",
    "\n",
    "x_train = train_set\n",
    "y_train = train_set[\"type_label_encoded\"]\n",
    "x_val = val_set\n",
    "y_val = val_set[\"type_label_encoded\"]\n",
    "\n",
    "epochs, hist = train_model(my_model, x_train, y_train, x_val, y_val, \n",
    "                           epochs, batch_size)\n",
    "\n",
    "# Plot a graph of the metric vs. Sparse Categorical Crossentropy\n",
    "display(hist)\n",
    "plot_the_scc_curve(epochs, hist[\"loss\"], hist[\"accuracy\"], hist[\"val_accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test The Model Using Test Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_label</th>\n",
       "      <th>predicted_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rainy</td>\n",
       "      <td>rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shine</td>\n",
       "      <td>shine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>foggy</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>shine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>foggy</td>\n",
       "      <td>sunrise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sunrise</td>\n",
       "      <td>sunrise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>foggy</td>\n",
       "      <td>sunrise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>shine</td>\n",
       "      <td>shine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>foggy</td>\n",
       "      <td>foggy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>foggy</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>foggy</td>\n",
       "      <td>shine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>foggy</td>\n",
       "      <td>foggy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rainy</td>\n",
       "      <td>rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sunrise</td>\n",
       "      <td>sunrise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sunrise</td>\n",
       "      <td>sunrise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>foggy</td>\n",
       "      <td>foggy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sunrise</td>\n",
       "      <td>sunrise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rainy</td>\n",
       "      <td>rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>rainy</td>\n",
       "      <td>rainy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>sunrise</td>\n",
       "      <td>sunrise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cloudy</td>\n",
       "      <td>foggy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>rainy</td>\n",
       "      <td>foggy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sunrise</td>\n",
       "      <td>sunrise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>foggy</td>\n",
       "      <td>foggy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sunrise</td>\n",
       "      <td>sunrise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>foggy</td>\n",
       "      <td>cloudy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>shine</td>\n",
       "      <td>shine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>rainy</td>\n",
       "      <td>rainy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actual_label predicted_label\n",
       "0         rainy           rainy\n",
       "1         shine           shine\n",
       "2         foggy          cloudy\n",
       "3        cloudy           shine\n",
       "4         foggy         sunrise\n",
       "5       sunrise         sunrise\n",
       "6         foggy         sunrise\n",
       "7         shine           shine\n",
       "8         foggy           foggy\n",
       "9         foggy          cloudy\n",
       "10        foggy           shine\n",
       "11        foggy           foggy\n",
       "12        rainy           rainy\n",
       "13      sunrise         sunrise\n",
       "14       cloudy          cloudy\n",
       "15      sunrise         sunrise\n",
       "16        foggy           foggy\n",
       "17       cloudy          cloudy\n",
       "18      sunrise         sunrise\n",
       "19        rainy           rainy\n",
       "20        rainy           rainy\n",
       "21      sunrise         sunrise\n",
       "22       cloudy           foggy\n",
       "23        rainy           foggy\n",
       "24      sunrise         sunrise\n",
       "25        foggy           foggy\n",
       "26      sunrise         sunrise\n",
       "27        foggy          cloudy\n",
       "28        shine           shine\n",
       "29        rainy           rainy"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "test_df[\"type_label_encoded\"] = enc.transform(test_df[\"type_label\"].values)\n",
    "y_pred = predict(my_model, test_df)\n",
    "y_pred = [np.argmax(pred) for pred in y_pred]\n",
    "\n",
    "y_pred = enc.inverse_transform(y_pred)\n",
    "\n",
    "comparison = pd.DataFrame(columns = [\"actual_label\", \"predicted_label\"])\n",
    "comparison[\"actual_label\"] = test_df[\"type_label\"]\n",
    "comparison[\"predicted_label\"] = y_pred\n",
    "\n",
    "display(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report The Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4\n",
       "0  2  1  0  1  0\n",
       "1  3  4  0  1  2\n",
       "2  0  1  5  0  0\n",
       "3  0  0  0  3  0\n",
       "4  0  0  0  0  7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      cloudy       0.40      0.50      0.44         4\n",
      "       foggy       0.67      0.40      0.50        10\n",
      "       rainy       1.00      0.83      0.91         6\n",
      "       shine       0.60      1.00      0.75         3\n",
      "     sunrise       0.78      1.00      0.88         7\n",
      "\n",
      "    accuracy                           0.70        30\n",
      "   macro avg       0.69      0.75      0.70        30\n",
      "weighted avg       0.72      0.70      0.69        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "display(pd.DataFrame(confusion_matrix(test_df[\"type_label\"].values, y_pred)))\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(test_df[\"type_label\"].values, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
